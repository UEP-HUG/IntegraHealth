{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage as rl\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import maskmypy\n",
    "from recordlinkage.preprocessing import clean, phonetic\n",
    "from shapely.geometry import Point, Polygon\n",
    "from pathlib import Path\n",
    "from difflib import SequenceMatcher\n",
    "from maskmypy import Donut\n",
    "import pickle\n",
    "from geopandas import GeoDataFrame, sjoin\n",
    "from random import random, gauss, uniform\n",
    "from shapely.affinity import translate\n",
    "from math import sqrt\n",
    "from maskmypy import Donut_MaxK\n",
    "from maskmypy import Street\n",
    "import pandarallel\n",
    "import contextily as ctx\n",
    "data_folder = Path('../Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame(np.array([[523,523,523, 982, 982, 982],['LAMAL','LAMAL','LAMAL','LCA','LCA','LCA'], [1,2,3,1,2,3], [46.1,45.1,44.1, 46.11, 45.11, 44.11],[6.1, 6.2, 6.3, 6.11,6.12,6.13]])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.columns = ['ID','category','address_id','lon','lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df_LCA = sim_df[sim_df.category == 'LCA']\n",
    "sim_df_LAMAL = sim_df[sim_df.category == 'LAMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df_LCA['matching_ID'] = '523-982'\n",
    "sim_df_LAMAL['matching_ID'] = '523-982'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(sim_df_LAMAL,sim_df_LCA, on = 'matching_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(sim_df_LAMAL,sim_df_LCA, on = ['matching_ID','address_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gdf(df,crs,x,y):\n",
    "    geometry = [Point(xy) for xy in zip(df[x], df[y])]\n",
    "    crs ='epsg:{}'.format(crs)\n",
    "    gdf = gpd.GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_geo = gpd.read_file(data_folder/'raw'/\"/g2l15.shp\").to_crs(2056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "communes = gpd.read_file(data_folder/'raw/swissBOUNDARIES3D_1_3_TLM_HOHEITSGEBIET.shp')\n",
    "communes = communes.to_crs(2056)\n",
    "communes = communes[~communes.geometry.isnull()]\n",
    "communes = communes.rename(columns={'geom': 'geometry'})\n",
    "communes = communes[communes.NAME != 'Lac Léman (VD)']\n",
    "communes = communes[communes.NAME != 'Lac de Neuchâtel (VD)']\n",
    "communes = communes[communes.NAME != 'Lac de Morat (VD)']\n",
    "communes = communes.reset_index(drop=True)\n",
    "communes = gpd.GeoDataFrame(communes, crs = 2056,geometry=communes['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_3D_2D(geometry):\n",
    "    '''\n",
    "    Takes a GeoSeries of 3D Multi/Polygons (has_z) and returns a list of 2D Multi/Polygons\n",
    "    '''\n",
    "    new_geo = []\n",
    "    for p in geometry:\n",
    "        if p.has_z:\n",
    "            if p.geom_type == 'Polygon':\n",
    "                lines = [xy[:2] for xy in list(p.exterior.coords)]\n",
    "                new_p = Polygon(lines)\n",
    "                new_geo.append(new_p)\n",
    "            elif p.geom_type == 'MultiPolygon':\n",
    "                new_multi_p = []\n",
    "                for ap in p:\n",
    "                    lines = [xy[:2] for xy in list(ap.exterior.coords)]\n",
    "                    new_p = Polygon(lines)\n",
    "                    new_multi_p.append(new_p)\n",
    "                new_geo.append(MultiPolygon(new_multi_p))\n",
    "    return new_geo\n",
    "\n",
    "communes['geometry'] = convert_3D_2D(communes['geometry'])\n",
    "\n",
    "communes.crs = 2056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "regbl_address = pd.read_feather(data_folder/'Clean_data/regbl_address.feather')\n",
    "regbl_address[['gkode','gkodn']] = regbl_address[['gkode','gkodn']].astype(float)\n",
    "regbl_address = make_gdf(regbl_address,'2056','gkode','gkodn')\n",
    "regbl_address['address'] = regbl_address['address'].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_address = regbl_address.sort_values(['gdekt','gdename','strname']).head(100000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "statpop = pd.read_csv(data_folder/'OFS/ag-b-00.03-vz2020statpop/STATPOP2020.csv',sep = ';')\n",
    "statpop_ha = statpop.copy()\n",
    "geometry = [Point(xy) for xy in zip(statpop['E_KOORD'], statpop['N_KOORD'])]\n",
    "statpop_point = gpd.GeoDataFrame(statpop, crs=2056, geometry=geometry)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Polygon(zip([xy[0],xy[0],xy[0]+100,xy[0]+100],[xy[1],xy[1]+100,xy[1]+100,xy[1]])) for xy in zip(statpop_ha.E_KOORD, statpop_ha.N_KOORD)]\n",
    "statpop_ha = gpd.GeoDataFrame(statpop_ha, crs=2056, geometry=geometry)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_gdf = statpop_ha[['B20BTOT','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rivers = gpd.read_file(data_folder/'raw'/'Lacs'/'Typisierung_LV95'/'typisierung.gpkg').to_crs(2056)\n",
    "df_lakes = gpd.read_file(data_folder/'raw'/'Lacs'/\"g2s15.shp\").to_crs(2056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rivers_polygons = df_rivers.copy()\n",
    "df_rivers_polygons.loc[df_rivers_polygons.GROSSERFLUSS != 'NA','geometry'] = df_rivers_polygons['geometry'].buffer(30)\n",
    "df_rivers_polygons.loc[df_rivers_polygons.GROSSERFLUSS == 'NA','geometry'] = df_rivers_polygons['geometry'].buffer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lakes_and_rivers = pd.concat([df_rivers_polygons[['geometry']], df_lakes[['geometry']]])\n",
    "df_lakes_and_rivers_union = df_lakes_and_rivers['geometry'].unary_union\n",
    "country_geo_wo_rivers_lakes = country_geo.difference(df_lakes_and_rivers_union)\n",
    "country_geo_wo_rivers_lakes = gpd.GeoDataFrame(country_geo_wo_rivers_lakes, columns = ['geometry'])\n",
    "df_lakes_and_rivers.plot(figsize = (12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Geomasking - LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lca = pd.read_csv('df_lca.csv')\n",
    "df_lca_nonull = df_lca[df_lca.comment.str.contains('Ok')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "donutmask = Donut_MaxK(\n",
    "    df_lca_nonull, # Name of the sensitive geodataframe\n",
    "    population_gdf=communes[communes.EINWOHNERZ.isnull()==False], # Name of the census geodataframe\n",
    "    population_column='EINWOHNERZ', # Name of the column containing the population field\n",
    "    max_k_anonymity=100, # The maximum possible k-anonymity value\n",
    "    donut_ratio=0.05, # The ratio used to define the minimum possible k-anonymity value.\n",
    "    distribution='uniform' # The distribution to use when displacing points. Other options include 'gaussian' and 'areal'. 'Areal' distribution means points are more likely to be displaced further within the range.\n",
    ") # Optional, a geodataframe used to ensure that points do not leave a particular area. \n",
    "\n",
    "donutmask.execute()\n",
    "\n",
    "masked_gdf_lca = donutmask.masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gdf.radius_max.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gdf_lca['lon_masked'] = masked_gdf_lca['geometry'].to_crs(4326).x\n",
    "masked_gdf_lca['lat_masked'] = masked_gdf_lca['geometry'].to_crs(4326).y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gdf_lca['address'] = masked_gdf_lca['full_address']\n",
    "masked_gdf_lca.loc[masked_gdf.new_address.isnull()==False, 'address'] = masked_gdf_lca.new_address\n",
    "masked_gdf_lca['address'] = pd.Categorical(masked_gdf_lca['address'])\n",
    "masked_gdf_lca['address_id'] = masked_gdf_lca['address'].cat.codes.astype(int)\n",
    "masked_gdf_lca['address'] = masked_gdf_lca['address'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "masked_gdf.to_csv(data_folder/'Clean_data'/'masked_lca_nonull.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of NATION duplicates by aggregating, CH if contains CH, otherwise max\n",
    "agg_nation = df_lca.groupby('ID_LCA')['NATION'].apply(lambda x: 'CH' if 'CH' in x else max(x))\n",
    "\n",
    "df_lca['NATION_NODUP'] = df_lca['ID_LCA'].map(agg_nation.to_dict())\n",
    "\n",
    "#Get rid of SEXE duplicates by aggregating, max\n",
    "agg_sexe = df_lca.groupby('ID_LCA')['SEXE'].apply(lambda x: max(x))\n",
    "\n",
    "df_lca['SEXE_NODUP'] = df_lca['ID_LCA'].map(agg_sexe.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_mask_link = pd.merge(lca[['ID_LCA','ANNEE_NAISSANCE','MOIS_NAISSANCE','SEXE_NODUP','NATION_NODUP']].drop_duplicates(), masked_gdf[['ID_LCA','lon_masked','lat_masked','zipcode','address_id']], on = 'ID_LCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_mask_link= lca_mask_link.sort_values('lon_masked').drop_duplicates(subset= ['ID_LCA','address_id'],keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Geomasking - LAMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lamal = pd.read_csv('df_lamal_80.csv')\n",
    "df_lamal_nonull = df_lamal[df_lamal.comment.str.contains('Ok')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "donutmask = Donut_MaxK(\n",
    "    df_lamal_nonull, # Name of the sensitive geodataframe\n",
    "    population_gdf=communes[communes.EINWOHNERZ.isnull()==False], # Name of the census geodataframe\n",
    "    population_column='EINWOHNERZ', # Name of the column containing the population field\n",
    "    max_k_anonymity=100, # The maximum possible k-anonymity value\n",
    "    donut_ratio=0.05, # The ratio used to define the minimum possible k-anonymity value.\n",
    "    distribution='uniform' # The distribution to use when displacing points. Other options include 'gaussian' and 'areal'. 'Areal' distribution means points are more likely to be displaced further within the range.\n",
    ") # Optional, a geodataframe used to ensure that points do not leave a particular area. \n",
    "\n",
    "donutmask.execute()\n",
    "\n",
    "masked_gdf_lamal = donutmask.masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gdf_lamal['lon_masked'] = masked_gdf_lamal['geometry'].to_crs(4326).x\n",
    "masked_gdf_lamal['lat_masked'] = masked_gdf_lamal['geometry'].to_crs(4326).y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_gdf_lamal['address'] = masked_gdf_lamal['full_address']\n",
    "masked_gdf_lamal.loc[masked_gdf_lamal.new_address.isnull()==False, 'address'] = masked_gdf_lamal.new_address\n",
    "masked_gdf_lamal['address_id'] = masked_gdf_lamal['address'].map(key_address_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_address_id = masked_gdf_lca[['address','address_id']].set_index('address').to_dict()['address_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lamal['NATION'] = df_lamal['NATION'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of NATION duplicates by aggregating, CH if contains CH, otherwise max\n",
    "agg_nation = df_lamal.groupby('ID_LAMAL')['NATION'].apply(lambda x: 'CH' if 'CH' in x else max(x))\n",
    "df_lamal['NATION_NODUP'] = df_lamal['ID_LAMAL'].map(agg_nation.to_dict())\n",
    "#Get rid of SEXE duplicates by aggregating, max\n",
    "agg_sexe = df_lamal.groupby('ID_LAMAL')['SEXE'].apply(lambda x: max(x))\n",
    "df_lamal['SEXE_NODUP'] = df_lamal['ID_LAMAL'].map(agg_sexe.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamal_mask_link = pd.merge(df_lamal[['ID_LAMAL','ANNEE_NAISSANCE','MOIS_NAISSANCE','SEXE_NODUP','NATION_NODUP']].drop_duplicates(), masked_gdf_lamal[['ID_LAMAL','lon_masked','lat_masked','zipcode','address_id']], on = 'ID_LAMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamal_mask_link = lamal_mask_link.sort_values('lon_masked').drop_duplicates(subset= ['ID_LAMAL','address_id'],keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lamal.ID_LAMAL.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_mask_link.ID_LCA.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamal_mask_link.ID_LAMAL.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_mask_link.to_csv(data_folder/'Clean_data'/'lca_masked_for_linkage.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamal_mask_link.to_csv(data_folder/'Clean_data'/'lamal_masked_for_linkage.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Record linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = rl.Index()\n",
    "#champ_dict = {'NOANNEE':'NOANNEE','ID_LCA':'ID_LCA','ANNEE_NAISSANCE':'ANNEE_NAISSANCE','mois_mod2':'MOIS_NAISSANCE','CDPHYSSEXE':'SEXE','CDPHYSNATIONALITE':'NATION','TXCOMPLEMENTDESTLEGALE':'COMP_DEST_LEGAL','TXRUELEGALE':'street','TXRUENUMEROLEGALE':'adr_num','TXNPALEGALE':'zipcode','TXLOCALITELEGALE':'city'}\n",
    "indexer.block(['ANNEE_NAISSANCE','MOIS_NAISSANCE','SEXE_NODUP','NATION_NODUP','zipcode'])\n",
    "pairs = indexer.index(lca_mask_link, lamal_mask_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(lca_mask_link), len(lamal_mask_link), len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpu = 10 #Set number of CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = rl.Compare(n_jobs=n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#250m (max geomasking) - 25min (min) / 2 (0.5 decay of the linear fct)\n",
    "#Because it is the min distance of geomasking\n",
    "# comparer.exact('given_name', 'given_name', label='given_name')\n",
    "# comparer.string('surname', 'surname', method='jarowinkler', threshold=0.85, label='surname')\n",
    "# comparer.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "comparer.string('NATION_NODUP', 'NATION_NODUP',method='jarowinkler', threshold=0.85, label='NATION')\n",
    "comparer.exact('ANNEE_NAISSANCE', 'ANNEE_NAISSANCE', label='ANNEE_NAISSANCE')\n",
    "comparer.exact('MOIS_NAISSANCE', 'MOIS_NAISSANCE', label='MOIS_NAISSANCE')\n",
    "comparer.exact('SEXE_NODUP', 'SEXE_NODUP', label='SEXE')\n",
    "comparer.exact('zipcode', 'zipcode', label='zipcode')\n",
    "comparer.geo(left_on_lat = 'lat_masked',left_on_lng = 'lon_masked',right_on_lat = 'lat_masked',right_on_lng = 'lon_masked',scale = 0.04, offset = 0.5, method = 'linear',label = 'distance')\n",
    "features = comparer.compute(pairs, lca_mask_link, lamal_mask_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(data_folder/'features_w_zipcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.set_index(['ID_LAMAL','ID_LCA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the comparison results\n",
    "features.sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[features.distance == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.distance.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "?rl.ECMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = rl.ECMClassifier(binarize = 0.5)\n",
    "cl.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the parameters that are trained (m, u and p). Note that the estimates\n",
    "# are very good.\n",
    "print(\"p probability P(Match):\", cl.p)\n",
    "print(\"m probabilities P(x_i=1|Match):\", cl.m_probs)\n",
    "print(\"u probabilities P(x_i=1|Non-Match):\", cl.u_probs)\n",
    "print(\"log m probabilities P(x_i=1|Match):\", cl.log_m_probs)\n",
    "print(\"log u probabilities P(x_i=1|Non-Match):\", cl.log_u_probs)\n",
    "print(\"log weights of features:\", cl.log_weights)\n",
    "print(\"weights of features:\", cl.weights)\n",
    "\n",
    "# evaluate the model\n",
    "links_pred = cl.predict(features)\n",
    "print(\"Predicted number of links:\", len(links_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the match probability for each pair in the dataset.\n",
    "probs = cl.prob(features)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.ID_LCA.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = features[features.sum(axis=1) > 5.999].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs = pd.DataFrame(probs).reset_index()\n",
    "df_probs.columns = ['id_lca','id_lamal','prob']\n",
    "\n",
    "key_id_index_lamal = lamal_mask_link['ID_LAMAL'].astype(int).to_dict()\n",
    "key_id_index_lca = lca_mask_link['ID_LCA'].astype(int).to_dict()\n",
    "\n",
    "df_probs['id_lca'] = df_probs['id_lca'].astype(int).map(key_id_index_lca)\n",
    "df_probs['id_lamal'] = df_probs['id_lamal'].astype(int).map(key_id_index_lamal)\n",
    "\n",
    "df_probs['id'] = df_probs['id_lca'].astype(str) + '-'+ df_probs['id_lamal'].astype(str)\n",
    "\n",
    "key_probs = df_probs.set_index('id')['prob'].to_dict()\n",
    "\n",
    "max_probs = df_probs.set_index('id_lamal').groupby(['id_lca'])['prob'].idxmax()\n",
    "\n",
    "max_probs_df = pd.DataFrame(max_probs).reset_index()\n",
    "max_probs_df.columns = ['id_lca','id_lamal']\n",
    "\n",
    "max_probs_df['id'] = max_probs_df['id_lca'].astype(str) + '-'+ max_probs_df['id_lamal'].astype(str)\n",
    "\n",
    "max_probs_df['prob'] = max_probs_df['id'].map(key_probs)\n",
    "\n",
    "# max_probs_df[['id_lca']].to_csv(data_folder/'Clean_data'/'lca_list_pour_christophe.csv')\n",
    "# max_probs_df[['id_lamal']].to_csv(data_folder/'Clean_data'/'lamal_list_pour_christophe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## Export end file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probs_df.to_csv(data_folder/'Clean_data'/'max_probs_w_zipcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probs_df = pd.read_csv(data_folder/'max_probs_w_zipcode_pour_david.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recordLinkage",
   "language": "python",
   "name": "recordlinkage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
