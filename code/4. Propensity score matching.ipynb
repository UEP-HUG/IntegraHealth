{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Propensity score matching\n",
    "\n",
    "This script does the following:\n",
    "\n",
    "1. Import the necessary libraries\n",
    "2. Loads the data into a Pandas DataFrame\n",
    "3. Define the treatment and control groups\n",
    "4. Define the features used to predict the treatment\n",
    "5. Create an instance of LRSRegressor to estimate propensity scores\n",
    "6. Fit the model to the data\n",
    "7. Compute the propensity scores\n",
    "8. Create an instance of PropensityScoreMatching\n",
    "9. Perform the matching\n",
    "10. Inspect the matched data\n",
    "\n",
    "It is important to note that propensity score matching is a powerful tool, but it should be used with caution. There is a lot of assumptions that needs to be met before applying the technique, and it is crucial to validate the assumptions and check the balance of the treated and control groups after the matching.\n",
    "\n",
    "Here's a script that demonstrates how you might perform propensity score matching in Python using the library \"causalml\":\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import sys\n",
    "import pandas as pd\n",
    "# from causalml.inference.meta import LRSRegressor\n",
    "# from causalml.propensity import PropensityScoreMatching\n",
    "# from causalml.propensity import ElasticNetPropensityModel\n",
    "# from causalml.match import NearestNeighborMatch, create_table_one\n",
    "import psmpy as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tableone import TableOne\n",
    "from utils import read_data, plot_covariate_distributions, plot_match, compare_balance, sizeof_fmt, optimize_memory_df, plot_categorical_proportional_diff, compute_mean_differences_and_proportions, love_plot, sensitivity_analysis_k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('../Data/')\n",
    "res_folder = Path('../Results/')\n",
    "model_folder = res_folder/'Models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a Pandas DataFrame\n",
    "data = read_data(\"../Data/processed/full_dataset_nonull.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('NOANNEE').uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.GeoDataFrame(data, crs = 4326, geometry=gpd.points_from_xy(data.lon_masked, data.lat_masked))\n",
    "data = data.to_crs(2056)\n",
    "data['E'], data['N'] = data['geometry'].x, data['geometry'].y\n",
    "data['E:N'] = data['E']*data['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_final = data[data.treatment.isnull()==False]\n",
    "data_final['DEDUCTIBLE_above_500'] = 1\n",
    "data_final.loc[data_final.MTFRANCHISECOUV < 500, 'DEDUCTIBLE_above_500'] = 0\n",
    "\n",
    "data_final['gp'] = data_final['gp'].astype(str)\n",
    "# data_final['CANTON'] = data_final.filter(regex='CANTON_ACRONU').idxmax(axis=1).str.replace('CANTON_NAME_', '')\n",
    "data_final['SEX'] = data_final.filter(regex='SEX_').idxmax(axis=1).str.replace('SEX_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final[data_final.gp.isin(['LCA & AOS','AOS only','LCA only'])].gp.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final[(data_final.A10A_ATC_N > 0)|(data_final.A10B_ATC_N > 0)].gp.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Evolution of groups over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_by_gp = pd.DataFrame(data_final.groupby(['NOANNEE','gp']).size(), columns = ['n']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_by_gp = cnt_by_gp.pivot(index = 'NOANNEE', values = 'n', columns = 'gp').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_by_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [cnt_by_gp['AOS only'],\n",
    "              cnt_by_gp['LCA & AOS'],\n",
    "              cnt_by_gp['LCA only'],\n",
    "              cnt_by_gp['No insurance'],\n",
    "              cnt_by_gp['No usage'],\n",
    "              cnt_by_gp['No usage - No AOS & not insured LCA'],\n",
    "              cnt_by_gp['No usage - No LCA & not insured AOS'],\n",
    "              cnt_by_gp['Not insured AOS, LCA'],\n",
    "              cnt_by_gp['Not insured LCA, AOS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create area chart\n",
    "plt.stackplot(cnt_by_gp.NOANNEE, y, labels =  cnt_by_gp.drop('NOANNEE', axis = 1).columns)\n",
    "plt.legend(loc='lower left', fontsize = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_2017.to_csv('../Data/processed/data_2017.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Question to consider : I am not including the individuals that didn't claim anything within a year. Should they be included in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treated = optimize_memory_df(data_final[data_final.treatment.isnull()==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treated.groupby('NOANNEE').uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Filter out individuals that do not belong to the treatment and control for the whole 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique years\n",
    "unique_years = set(df_treated['NOANNEE'])\n",
    "\n",
    "# Group by patient_id and filter\n",
    "df_treated_filtered = df_treated.groupby('uuid').filter(lambda x: set(x['NOANNEE']) == unique_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treated_filtered.groupby('NOANNEE').uuid.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Create yearly datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017 = df_treated[df_treated.NOANNEE == 2017]\n",
    "data_2018 = df_treated[df_treated.NOANNEE == 2018]\n",
    "data_2019 = df_treated[df_treated.NOANNEE == 2019]\n",
    "data_2020 = df_treated[df_treated.NOANNEE == 2020]\n",
    "data_2021 = df_treated[df_treated.NOANNEE == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All uuid present for 5 years\n",
    "data_2017_filtered = df_treated_filtered[df_treated_filtered.NOANNEE == 2017]\n",
    "data_2018_filtered = df_treated_filtered[df_treated_filtered.NOANNEE == 2018]\n",
    "data_2019_filtered = df_treated_filtered[df_treated_filtered.NOANNEE == 2019]\n",
    "data_2020_filtered = df_treated_filtered[df_treated_filtered.NOANNEE == 2020]\n",
    "data_2021_filtered = df_treated_filtered[df_treated_filtered.NOANNEE == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_atc_amount_treatment = data_2021.filter(regex = 'Diabetes|Epilespy|Rheumatologic conditions|Hyperlipidemia|Thyroid disorders|treatment').corr()['treatment'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Create subsample for tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the treatment variable and covariates\n",
    "id_var = 'uuid'\n",
    "treatment_var = 'treatment'\n",
    "outcome_var = 'PRESTATIONS_BRUTES_AOS'\n",
    "outcome_vars = ['DRUGAMOUNT_BRUT','PRESTATIONS_BRUTES_AOS','PRESTATIONS_NETTES_AOS','PRESTATIONS_BRUTES_LCA','PRESTATIONS_DISEASE','PRESTATIONS_BIRTH','PRESTATIONS_ACCIDENT','PRESTATIONS_TOTAL','n_atc','NBRE_FACTURES_LCA', 'NBRE_FACTURES_AOS', 'NBRE_FACTURES_TOTAL', 'n_inpatient_hosp',\n",
    " 'n_outpatient_hosp',\n",
    " 'n_month_outpatienthosp',\n",
    " 'n_month_inpatienthosp',\n",
    " 'time_to_rehosp_in',\n",
    " 'time_to_rehosp_out']\n",
    "categorical_columns = ['SEX_F','LANG_FR','LANG_DE','LANG_IT','LANG_EN','CANTON_ACRONYM_AG',\n",
    " 'CANTON_ACRONYM_AI',\n",
    " 'CANTON_ACRONYM_AR',\n",
    " 'CANTON_ACRONYM_BE',\n",
    " 'CANTON_ACRONYM_BL',\n",
    " 'CANTON_ACRONYM_BS',\n",
    " 'CANTON_ACRONYM_FR',\n",
    " 'CANTON_ACRONYM_GE',\n",
    " 'CANTON_ACRONYM_GL',\n",
    " 'CANTON_ACRONYM_GR',\n",
    " 'CANTON_ACRONYM_JU',\n",
    " 'CANTON_ACRONYM_LU',\n",
    " 'CANTON_ACRONYM_NE',\n",
    " 'CANTON_ACRONYM_NW',\n",
    " 'CANTON_ACRONYM_OW',\n",
    " 'CANTON_ACRONYM_SG',\n",
    " 'CANTON_ACRONYM_SH',\n",
    " 'CANTON_ACRONYM_SO',\n",
    " 'CANTON_ACRONYM_SZ',\n",
    " 'CANTON_ACRONYM_TG',\n",
    " 'CANTON_ACRONYM_TI',\n",
    " 'CANTON_ACRONYM_UR',\n",
    " 'CANTON_ACRONYM_VD',\n",
    " 'CANTON_ACRONYM_VS',\n",
    " 'CANTON_ACRONYM_ZG',\n",
    " 'CANTON_ACRONYM_ZH']\n",
    "continuous_columns = ['NBAGE','cds','ssep2','mean_ndvi','MTFRANCHISECOUV', 'mean_lst', 'mean_pm10', 'mean_pm25', 'mean_no2', 'mean_carnight', 'E', 'N', 'E:N', 'D_MEDIC_B', 'D_MEDIC_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_propensity_scores(df, treatment_var, outcome_vars, categorical_columns, continuous_columns):\n",
    "    \"\"\"\n",
    "    This function computes propensity scores and returns a copy of the original dataframe with an additional \n",
    "    column for the propensity scores.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataframe for which propensity scores are to be computed.\n",
    "        treatment_var (str): The name of the treatment variable in df.\n",
    "        outcome_vars (list of str): The names of the outcome variables in df.\n",
    "        categorical_columns (list of str): The names of the categorical variables in df.\n",
    "        continuous_columns (list of str): The names of the continuous variables in df.\n",
    "\n",
    "    Returns:\n",
    "        df_scaled (pd.DataFrame): A copy of the original dataframe with an additional 'propensity_score' column.\n",
    "    \"\"\"\n",
    "    # Initialize a StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Copy the dataframe\n",
    "    df_scaled = df[continuous_columns+categorical_columns+outcome_vars+[treatment_var]+[id_var]].copy()\n",
    "    \n",
    "    # Scale the continuous variables\n",
    "    if len(continuous_columns) > 0:\n",
    "        df_scaled[continuous_columns] = scaler.fit_transform(df_scaled[continuous_columns])\n",
    "    \n",
    "    # Fill NaN values in 'D_MEDIC_S' and 'D_MEDIC_B' with their respective mean\n",
    "    if 'D_MEDIC_S' in df_scaled.columns:\n",
    "        df_scaled['D_MEDIC_S'] = df_scaled['D_MEDIC_S'].fillna(df_scaled['D_MEDIC_S'].mean())\n",
    "    if 'D_MEDIC_B' in df_scaled.columns:\n",
    "        df_scaled['D_MEDIC_B'] = df_scaled['D_MEDIC_B'].fillna(df_scaled['D_MEDIC_B'].mean())\n",
    "    \n",
    "    # Fit a logistic regression model to estimate propensity scores\n",
    "    logistic_model = LogisticRegression(max_iter=1000)\n",
    "    logistic_model.fit(df_scaled[categorical_columns+continuous_columns], df_scaled[treatment_var])\n",
    "\n",
    "    formula = treatment_var + ' ~ ' + ' + '.join(categorical_columns + continuous_columns)\n",
    "    logit_model = smf.logit(formula, data=df_scaled).fit()\n",
    "    \n",
    "    # Store model results\n",
    "    params = logit_model.params\n",
    "    conf = logit_model.conf_int()\n",
    "    conf['Odds Ratio'] = params\n",
    "    conf.columns = ['2.5%', '97.5%', 'Odds Ratio']\n",
    "    # convert log odds to ORs\n",
    "    odds = pd.DataFrame(np.exp(conf))\n",
    "    # check if pvalues are significant\n",
    "    odds['pvalues'] = logit_model.pvalues\n",
    "    odds['significant?'] = ['significant' if pval <= 0.05 else 'not significant' for pval in logit_model.pvalues]\n",
    "    updated_odds = update_variable_names(odds, variable_names, 'odds')\n",
    "   \n",
    "    # Compute propensity scores\n",
    "    propensity_scores = logistic_model.predict_proba(df_scaled[categorical_columns+continuous_columns])[:, 1]\n",
    "    \n",
    "    # Calculate the c-statistic (area under the ROC curve)\n",
    "    c_statistic = roc_auc_score(df_scaled[treatment_var], propensity_scores)\n",
    "    print(\"C-statistic:\", c_statistic)\n",
    "    \n",
    "    # Add propensity scores to the dataset\n",
    "    df_scaled['propensity_score'] = propensity_scores\n",
    "    \n",
    "    return df_scaled, updated_odds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_names = pd.DataFrame({\"old\": ['NBAGE',\"NBAGE_std\", \"ssep2_std\",'ssep2', \"SEX_F\",'SEX','LANG', \"cds_std\",'cds','LANG_FR','D_MEDIC_B','D_MEDIC_S','D_MEDIC_B_std','D_MEDIC_S_std','DEDUCTIBLE_above_500','E_std','N_std','E_std:N_std','PRESTATIONS_TOTAL','PRESTATIONS_BRUTES_AOS','PRESTATIONS_BRUTES_LCA','AMBULATOIRE','STATIONNAIRE','PRESTATIONS_ACCIDENT','PRESTATIONS_DISEASE','PRESTATIONS_BIRTH','MTFRANCHISECOUV','mean_pm10','mean_no2','mean_pm25','mean_ndvi','mean_lst','mean_carnight'],\n",
    "                           \"new\": ['Age',\"Age\", \"SES index\",'SES index', \"Sex (Female)\",'Sex','Langage', \"CDS\",'CDS','French speaker','Access to prim. care med.','Access to spec. med.','Access to prim. care med.','Access to spec. med.','Franchise (>500)','E','N','E:N','Montant tot. prestations','Montant tot. prestations (AOS)','Montant tot. prestations (LCA)','Montant tot. ambulatoire','Montant tot. stationnaire','Montant tot. accident','Montant tot. maladie','Montant tot. maternité','Franchise','PM10','NO2','PM25','NDVI','LST','Nighttime car noise']})\n",
    "def update_variable_names(summary_table, variable_names, table_type):\n",
    "    name_mapper = variable_names.set_index('old')['new'].to_dict()\n",
    "    if table_type == 'summary':\n",
    "        name_mapper = {f\"{key}, mean (SD)\": f\"{value}, mean (SD)\" for key, value in name_mapper.items()}\n",
    "\n",
    "    summary_table = summary_table.rename(index=name_mapper)\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_2017, odds_2017 = compute_propensity_scores(data_2017, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2018, odds_2018 = compute_propensity_scores(data_2018, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2019, odds_2019 = compute_propensity_scores(data_2019, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2020, odds_2020 = compute_propensity_scores(data_2020, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2021, odds_2021 = compute_propensity_scores(data_2021, treatment_var, outcome_vars, categorical_columns, continuous_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_2017_filtered, odds_2017_filtered = compute_propensity_scores(data_2017_filtered, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2018_filtered, odds_2018_filtered = compute_propensity_scores(data_2018_filtered, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2019_filtered, odds_2019_filtered = compute_propensity_scores(data_2019_filtered, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2020_filtered, odds_2020_filtered = compute_propensity_scores(data_2020_filtered, treatment_var, outcome_vars, categorical_columns, continuous_columns)\n",
    "df_psm_2021_filtered, odds_2021_filtered = compute_propensity_scores(data_2021_filtered, treatment_var, outcome_vars, categorical_columns, continuous_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_plot(df_odds, folder, period):\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    fig, ax = plt.subplots(nrows=1, sharex=True, sharey=True, figsize=(6, 10))\n",
    "    for idx, row in df_odds.iloc[::-1].iterrows():\n",
    "        ci = [[row['Odds Ratio'] - row[::-1]['2.5%']], [row['97.5%'] - row['Odds Ratio']]]\n",
    "        if row['significant?'] == 'significant':\n",
    "            if row['Odds Ratio'] > 1:\n",
    "                plt.errorbar(x=[row['Odds Ratio']], y=[row.name], xerr=ci,\n",
    "                    ecolor='tab:red', capsize=3, linestyle='None', linewidth=1, marker=\"o\", \n",
    "                             markersize=5, mfc=\"tab:red\", mec=\"tab:red\")\n",
    "            else:\n",
    "                plt.errorbar(x=[row['Odds Ratio']], y=[row.name], xerr=ci,\n",
    "                    ecolor='tab:blue', capsize=3, linestyle='None', linewidth=1, marker=\"o\", \n",
    "                             markersize=5, mfc=\"tab:blue\", mec=\"tab:blue\")\n",
    "        else:\n",
    "            plt.errorbar(x=[row['Odds Ratio']], y=[row.name], xerr=ci,\n",
    "                ecolor='tab:gray', capsize=3, linestyle='None', linewidth=1, marker=\"o\", \n",
    "                         markersize=5, mfc=\"tab:gray\", mec=\"tab:gray\")\n",
    "    plt.axvline(x=1, linewidth=0.8, linestyle='--', color='black')\n",
    "    plt.tick_params(axis='both', which='major', labelsize=8)\n",
    "    plt.xlabel('Odds Ratio and 95% Confidence Interval', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder/'forest_plot_{}.png'.format(period))\n",
    "    plt.show()\n",
    "model_directory = model_folder /'Determinants of integrative medicine'/ 'Logistic regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_plot(odds_2017, model_directory, '2017')\n",
    "forest_plot(odds_2018, model_directory, '2018')\n",
    "forest_plot(odds_2021, model_directory, '2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_matching(df, treatment_var, year, note):\n",
    "    \"\"\"\n",
    "    This function performs propensity score matching and returns a dataframe with both matched treatment and control observations.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataframe for which propensity score matching is to be performed. \n",
    "                           This dataframe should already contain the propensity scores.\n",
    "        treatment_var (str): The name of the treatment variable in df.\n",
    "\n",
    "    Returns:\n",
    "        df_matched (pd.DataFrame): A dataframe with matched treatment and control observations.\n",
    "    \"\"\"\n",
    "    # Split the dataset into treatment and control groups\n",
    "    treatment_data = df[df[treatment_var] == 1]\n",
    "    control_data = df[df[treatment_var] == 0]\n",
    "    \n",
    "    # Create a NearestNeighbors matcher using the propensity scores\n",
    "    matcher = NearestNeighbors(n_neighbors=1)\n",
    "    matcher.fit(control_data['propensity_score'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Find the nearest control observation for each treatment observation\n",
    "    distances, indices = matcher.kneighbors(treatment_data['propensity_score'].values.reshape(-1, 1))\n",
    "\n",
    "    # Create a matched dataset\n",
    "    matched_control_indices = indices.flatten()\n",
    "    matched_control_data = control_data.iloc[matched_control_indices]\n",
    "    \n",
    "    df_matched = pd.concat([treatment_data, matched_control_data]).reset_index(drop=True)\n",
    "    \n",
    "    # Add a column 'tt_status' to denote treatment and control status\n",
    "    df_matched.loc[df_matched[treatment_var] == 1, 'tt_status'] = 'Treatment'\n",
    "    df_matched.loc[df_matched[treatment_var] == 0, 'tt_status'] = 'Control'\n",
    "    df_matched.to_parquet('../Data/processed/PSM/df_matched_{}_{}.parquet.gzip'.format(year,note), compression='gzip')\n",
    "    \n",
    "    return df_matched, treatment_data, control_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_matched_2017, treatment_2017, control_2017 =  perform_matching(df_psm_2017,'treatment','2017','unfiltered')\n",
    "df_psm_matched_2018, treatment_2018, control_2018 =  perform_matching(df_psm_2018,'treatment','2018','unfiltered')\n",
    "df_psm_matched_2019, treatment_2019, control_2019 =  perform_matching(df_psm_2019,'treatment','2019','unfiltered')\n",
    "df_psm_matched_2020, treatment_2020, control_2020 =  perform_matching(df_psm_2020,'treatment','2020','unfiltered')\n",
    "df_psm_matched_2021, treatment_2021, control_2021 =  perform_matching(df_psm_2021,'treatment','2021','unfiltered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_matched_2017_filtered, treatment_2017_filtered, control_2017_filtered =  perform_matching(df_psm_2017_filtered,'treatment','2017', 'filtered')\n",
    "df_psm_matched_2018_filtered, treatment_2018_filtered, control_2018_filtered =  perform_matching(df_psm_2018_filtered,'treatment','2018', 'filtered')\n",
    "df_psm_matched_2019_filtered, treatment_2019_filtered, control_2019_filtered =  perform_matching(df_psm_2019_filtered,'treatment','2019', 'filtered')\n",
    "df_psm_matched_2020_filtered, treatment_2020_filtered, control_2020_filtered =  perform_matching(df_psm_2020_filtered,'treatment','2020', 'filtered')\n",
    "df_psm_matched_2021_filtered, treatment_2021_filtered, control_2021_filtered =  perform_matching(df_psm_2021_filtered,'treatment','2021', 'filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score_jitter_plot(treatment_data, control_data, matched_data):\n",
    "    \"\"\"\n",
    "    This function generates a jitter plot of propensity scores for treatment and control groups before and after matching.\n",
    "\n",
    "    Parameters:\n",
    "        treatment_data (pd.DataFrame): The dataframe containing the original treatment group data.\n",
    "        control_data (pd.DataFrame): The dataframe containing the original control group data.\n",
    "        matched_data (pd.DataFrame): The dataframe containing the matched treatment and control group data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the dataset into different categories\n",
    "    unmatched_treatment = treatment_data[~treatment_data.uuid.isin(matched_data.uuid)]\n",
    "    unmatched_control = control_data[~control_data.uuid.isin(matched_data.uuid)]\n",
    "\n",
    "    matched_treatment = treatment_data[treatment_data.uuid.isin(matched_data.uuid)]\n",
    "    matched_control = control_data[control_data.uuid.isin(matched_data.uuid)]\n",
    "    \n",
    "    # Create a jitter plot for each category\n",
    "    fig, ax = plt.subplots(figsize = (10,5))\n",
    "    \n",
    "    sns.stripplot(y=['Unmatched Treatment']*len(unmatched_treatment), x=unmatched_treatment['propensity_score'], jitter=0.2, alpha=0.01, color='black', marker='o', linewidth=0.1, ax=ax)\n",
    "    sns.stripplot(y=['Matched Treatment']*len(matched_treatment), x=matched_treatment['propensity_score'], jitter=0.2, alpha=0.01, color='black', marker='o', linewidth=0.1, ax=ax)\n",
    "    sns.stripplot(y=['Matched Control']*len(matched_control), x=matched_control['propensity_score'], jitter=0.2, alpha=0.01, color='black', marker='o', linewidth=0.1, ax=ax)\n",
    "    sns.stripplot(y=['Unmatched Control']*len(unmatched_control), x=unmatched_control['propensity_score'], jitter=0.2, alpha=0.01, color='black', marker='o', linewidth=0.1, ax=ax)\n",
    "\n",
    "    ax.set_ylabel('Propensity Score')\n",
    "    ax.set_title('Jitter Plot of Propensity Scores')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "propensity_score_jitter_plot(treatment_2017, control_2017, df_psm_matched_2017)\n",
    "propensity_score_jitter_plot(treatment_2018, control_2018, df_psm_matched_2018)\n",
    "propensity_score_jitter_plot(treatment_2019, control_2019, df_psm_matched_2019)\n",
    "propensity_score_jitter_plot(treatment_2020, control_2020, df_psm_matched_2020)\n",
    "propensity_score_jitter_plot(treatment_2021, control_2021, df_psm_matched_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "propensity_score_jitter_plot(treatment_2017_filtered, control_2017_filtered, df_psm_matched_2017_filtered)\n",
    "propensity_score_jitter_plot(treatment_2018_filtered, control_2018_filtered, df_psm_matched_2018_filtered)\n",
    "propensity_score_jitter_plot(treatment_2019_filtered, control_2019_filtered, df_psm_matched_2019_filtered)\n",
    "propensity_score_jitter_plot(treatment_2020_filtered, control_2020_filtered, df_psm_matched_2020_filtered)\n",
    "propensity_score_jitter_plot(treatment_2021_filtered, control_2021_filtered, df_psm_matched_2021_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_matched_2017[df_psm_matched_2017.treatment == 0].groupby('uuid', observed = True).size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score_histogram(treatment_data, control_data):\n",
    "    \"\"\"\n",
    "    This function generates a histogram of propensity scores for treatment and control groups.\n",
    "\n",
    "    Parameters:\n",
    "        treatment_data (pd.DataFrame): The dataframe containing the treatment group data.\n",
    "        control_data (pd.DataFrame): The dataframe containing the control group data.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(control_data.propensity_score, bins=20, alpha=0.5, label='Control')\n",
    "    plt.hist(treatment_data.propensity_score, bins=20, alpha=0.5, label='Treatment')\n",
    "    plt.xlabel('Propensity Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propensity_score_histogram(treatment_2017, control_2017)\n",
    "propensity_score_histogram(df_psm_matched_2017[df_psm_matched_2017['treatment'] == 1], df_psm_matched_2017[df_psm_matched_2017['treatment'] == 0])\n",
    "propensity_score_histogram(df_psm_matched_2018[df_psm_matched_2018['treatment'] == 1], df_psm_matched_2018[df_psm_matched_2018['treatment'] == 0])\n",
    "propensity_score_histogram(df_psm_matched_2019[df_psm_matched_2019['treatment'] == 1], df_psm_matched_2019[df_psm_matched_2019['treatment'] == 0])\n",
    "propensity_score_histogram(df_psm_matched_2020[df_psm_matched_2020['treatment'] == 1], df_psm_matched_2020[df_psm_matched_2020['treatment'] == 0])\n",
    "propensity_score_histogram(df_psm_matched_2021[df_psm_matched_2021['treatment'] == 1], df_psm_matched_2021[df_psm_matched_2021['treatment'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = ['NBAGE', 'SEX_F', 'cds','ssep2','mean_ndvi', 'CANTON_ACRONYM_GE','CANTON_ACRONYM_VS']\n",
    "figure_title = \"Covariate Distributions Before and After Matching\"\n",
    "plot_covariate_distributions(df_psm_2021, df_psm_matched_2021, covariates, figure_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_comparison = compare_balance(df_psm_2021, df_psm_matched_2021, categorical_columns+continuous_columns, treatment_var)\n",
    "balance_comparison.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_categorical_proportional_diff(data_scaled, df_matched, 'SEX_F', treatment_var)\n",
    "# plot_categorical_proportional_diff(data_scaled, df_matched, 'CANTON_NAME_Genève', treatment_var)\n",
    "# plot_categorical_proportional_diff(data_scaled, df_matched, 'CANTON_NAME_Valais', treatment_var)\n",
    "\n",
    "# plot_categorical_proportional_diff(data_scaled, df_matched, 'ssep2', treatment_var)\n",
    "# plot_categorical_proportional_diff(data_scaled, df_matched, 'cds', treatment_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the following data\n",
    "variable_names = pd.DataFrame({\"old\": [\"NBAGE\", \"ssep2\", \"SEX_F\", \"cds\",'MTFRANCHISECOUV','LANG_FR','LANG_DE','CANTON_ACRONYM_GE','CANTON_ACRONYM_VS','E','N','E:N','D_MEDIC_B','D_MEDIC_S','mean_pm10','mean_no2','mean_pm25','mean_ndvi','mean_lst','mean_carnight'],\n",
    "                               \"new\": [\"Age\", \"SES index\", \"Sex\", \"CDS\",'Franchise','French speaking','German speaking','Canton - Genève','Canton - Valais','E','N','E:N','Access to prim. care med.','Access to spec. med.','PM10','NO2','PM25','NDVI','LST','Nighttime car noise']})\n",
    "\n",
    "\n",
    "# Calculate mean differences and proportions\n",
    "mean_diffs_and_props = compute_mean_differences_and_proportions(df_psm_2017, df_psm_matched_2017, variable_names, treatment_var)\n",
    "love_plot(mean_diffs_and_props, 0.1, 1)\n",
    "mean_diffs_and_props = compute_mean_differences_and_proportions(df_psm_2021, df_psm_matched_2021, variable_names, treatment_var)\n",
    "love_plot(mean_diffs_and_props, 0.1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Step 7: Assess the robustness of the results\n",
    "\n",
    "To ensure the robustness of the estimated treatment effect, you can perform sensitivity analyses, such as varying the number of nearest neighbors or using alternative matching algorithms. This step helps confirm that your results are not overly sensitive to the specific matching approach used.\n",
    "\n",
    "Here's an example of how to perform a sensitivity analysis by varying the number of nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sensitivity_analysis_k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sensitivity analysis for a range of k values\n",
    "k_values = [1, 3, 5, 10, 20]\n",
    "sensitivity_results = sensitivity_analysis_k_neighbors(df_psm_2017, treatment_2017, control_2017, continuous_columns+categorical_columns, treatment_var, outcome_var, k_values)\n",
    "print(sensitivity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sensitivity analysis for a range of k values\n",
    "k_values = [1, 3, 5, 10, 20]\n",
    "sensitivity_results = sensitivity_analysis_k_neighbors(df_psm_2018, treatment_2018, control_2018, continuous_columns+categorical_columns, treatment_var, outcome_var, k_values)\n",
    "print(sensitivity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sensitivity analysis for a range of k values\n",
    "k_values = [1, 3, 5, 10, 20]\n",
    "sensitivity_results = sensitivity_analysis_k_neighbors(df_psm_2019, treatment_2019, control_2019, continuous_columns+categorical_columns, treatment_var, outcome_var, k_values)\n",
    "print(sensitivity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sensitivity analysis for a range of k values\n",
    "k_values = [1, 3, 5, 10, 20]\n",
    "sensitivity_results = sensitivity_analysis_k_neighbors(df_psm_2020, treatment_2020, control_2020, continuous_columns+categorical_columns, treatment_var, outcome_var, k_values)\n",
    "print(sensitivity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sensitivity analysis for a range of k values\n",
    "k_values = [1, 3, 5, 10, 20]\n",
    "sensitivity_results = sensitivity_analysis_k_neighbors(df_psm_2021, treatment_2021, control_2021, continuous_columns+categorical_columns, treatment_var, outcome_var, k_values)\n",
    "print(sensitivity_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "This code performs the sensitivity analysis by estimating the ATE for different numbers of nearest neighbors (k). You can modify the k_values list to include other values or implement alternative matching algorithms to assess the robustness of your results further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "The Average Treatment Effect (ATE) represents the average difference in outcomes between the treatment and control groups in your matched dataset. An ATE of 1241.2 suggests that, on average, receiving the treatment is associated with an increase of 1241.2 units in the outcome variable compared to not receiving the treatment.\n",
    "\n",
    "However, to provide a more meaningful interpretation, it's important to consider the context and the specific variables in your study. For example, if your study is evaluating the effect of a job training program (treatment) on annual income (outcome), an ATE of 1241.2 would imply that, on average, individuals who participated in the job training program earned $1,241.2 more per year than their matched counterparts who did not participate in the program.\n",
    "\n",
    "Keep in mind that although propensity score matching helps control for observed covariates, it does not address unobserved confounders. Consequently, the ATE estimate should be interpreted as the average treatment effect on the treated (ATT) under the assumption of no unobserved confounding.\n",
    "\n",
    "It's also essential to consider the quality of the matching, the robustness of the results, and any limitations in your study when interpreting the ATE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "There are several methods to estimate treatment effects, apart from the Average Treatment Effect (ATE) that we discussed earlier. Here are a few other popular treatment effect measures:\n",
    "\n",
    "**Average Treatment Effect on the Treated (ATT)**: This measure calculates the average treatment effect for the individuals who received the treatment. It compares the outcomes of the treated group with their counterfactual outcomes if they had not received the treatment. It is especially useful when the focus is on understanding the impact of the treatment on those who were actually treated.\n",
    "\n",
    "**Average Treatment Effect on the Controls (ATC)**: This measure calculates the average treatment effect for the individuals who did not receive the treatment. It compares the outcomes of the control group with their counterfactual outcomes if they had received the treatment. It helps to estimate the potential impact if the treatment were expanded to include those who were not treated initially.\n",
    "\n",
    "**Local Average Treatment Effect (LATE)**: This measure estimates the treatment effect for a specific subpopulation, usually defined by an instrument variable. LATE is useful when the treatment effect is heterogeneous and the interest is in understanding the impact of the treatment on a particular subset of the population.\n",
    "\n",
    "**Conditional Average Treatment Effect (CATE)**: This measure estimates the treatment effect for different subpopulations based on specific covariates or characteristics. It helps to understand the heterogeneous treatment effects across different groups, which can be useful for targeting interventions or identifying subpopulations that benefit the most or the least from the treatment.\n",
    "\n",
    "Various estimation techniques can be applied to compute these treatment effect measures, such as matching, weighting, regression adjustment, and instrumental variable methods. The choice of method and treatment effect measure depends on the research question, data availability, and the assumptions that can be made about the data and the underlying causal relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## Outcome analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine in year 1 have lower spending in the same year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATE = df_psm_matched_2017.groupby(treatment_var)[outcome_var].mean().diff().iloc[-1]\n",
    "print(f\"Average Treatment Effect (ATE): {ATE}\")\n",
    "\n",
    "treated_outcomes = df_psm_matched_2017.loc[df_psm_matched_2017[treatment_var] == 1, outcome_var]\n",
    "control_outcomes = df_psm_matched_2017.loc[df_psm_matched_2017[treatment_var] == 0, outcome_var]\n",
    "ATT = treated_outcomes.mean() - control_outcomes.mean()\n",
    "print(f\"Average Treatment Effect on the Treated (ATT): {ATT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = outcome_var, ax = ax)\n",
    "# annotator = Annotator(chart, pairs=[('Treatment','Control')], data=df_matched, x='tt_status', y='NBAGE', order = list([i for i in df_matched['tt_status'].sort_values().unique()]))\n",
    "# annotator.configure(test='Mann-Whitney', text_format='star', loc='inside', comparisons_correction=\"Bonferroni\")\n",
    "# annotator.apply_and_annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'PRESTATIONS_NETTES_AOS', ax = ax)\n",
    "# annotator = Annotator(chart, pairs=[('Treatment','Control')], data=df_matched, x='tt_status', y='NBAGE', order = list([i for i in df_matched['tt_status'].sort_values().unique()]))\n",
    "# annotator.configure(test='Mann-Whitney', text_format='star', loc='inside', comparisons_correction=\"Bonferroni\")\n",
    "# annotator.apply_and_annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'PRESTATIONS_BRUTES_LCA', ax = ax)\n",
    "# annotator = Annotator(chart, pairs=[('Treatment','Control')], data=df_matched, x='tt_status', y='NBAGE', order = list([i for i in df_matched['tt_status'].sort_values().unique()]))\n",
    "# annotator.configure(test='Mann-Whitney', text_format='star', loc='inside', comparisons_correction=\"Bonferroni\")\n",
    "# annotator.apply_and_annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average treatment effect (ATE)\n",
    "ate = df_psm_matched_2017.groupby(treatment_var)[outcome_var].mean().diff().iloc[-1]\n",
    "print(\"Average Treatment Effect:\", ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine have better health outcomes in the same year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'n_inpatient_hosp', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'n_outpatient_hosp', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'time_to_rehosp_in', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'time_to_rehosp_out', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_matched_2018['n_month_outpatienthosp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'n_month_outpatienthosp', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'n_month_inpatienthosp', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ate_by_year(covariate):\n",
    "    _dict = {}\n",
    "    # Calculate the average treatment effect (ATE)\n",
    "    for df, year in zip([df_psm_matched_2017, df_psm_matched_2018, df_psm_matched_2019, df_psm_matched_2020, df_psm_matched_2021], [2017, 2018, 2019, 2020, 2021]):\n",
    "        ate = df.groupby(treatment_var)[covariate].mean().diff().iloc[-1]\n",
    "        print(f\"Average Treatment Effect {year}:\", ate)\n",
    "        _dict[year] = ate\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(list(_dict.items()), columns=['Year', 'ATE'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ate_inpatient_hosp = {}\n",
    "# Calculate the average treatment effect (ATE)\n",
    "for df, year in zip([df_psm_matched_2017, df_psm_matched_2018, df_psm_matched_2019, df_psm_matched_2020, df_psm_matched_2021], [2017, 2018, 2019, 2020, 2021]):\n",
    "    ate = df.groupby(treatment_var)['n_month_inpatienthosp'].mean().diff().iloc[-1]\n",
    "    print(f\"Average Treatment Effect {year}:\", ate)\n",
    "    dict_ate_inpatient_hosp[year] = ate\n",
    "# Create a DataFrame\n",
    "df_ate_inhosp = pd.DataFrame(list(dict_ate_inpatient_hosp.items()), columns=['Year', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine have lower drug consumption in the same year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "\n",
    "chart = sns.barplot(data = df_psm_matched_2021, x = 'tt_status', y = 'DRUGAMOUNT_BRUT', ax=ax)\n",
    "# annotator = Annotator(chart, pairs=[('Treatment','Control')], data=df_matched, x='tt_status', y='DRUGAMOUNT_BRUT', order = list([i for i in df_matched['tt_status'].sort_values().unique()]))\n",
    "# annotator.configure(test='Mann-Whitney', text_format='star', loc='inside', comparisons_correction=\"Bonferroni\")\n",
    "# annotator.apply_and_annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ate_drugamount = get_ate_by_year('DRUGAMOUNT_BRUT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ate_drugamount = get_ate_by_year('n_atc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'n_atc', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average treatment effect (ATE)\n",
    "ate = df_psm_matched_2017.groupby(treatment_var)['DRUGAMOUNT_BRUT'].mean().diff().iloc[-1]\n",
    "print(\"Average Treatment Effect:\", ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average treatment effect (ATE)\n",
    "ate = df_psm_matched_2017.groupby(treatment_var)['n_atc'].mean().diff().iloc[-1]\n",
    "print(\"Average Treatment Effect:\", ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'time_to_rehosp_in', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_matched_2017.loc[df_psm_matched_2017.time_to_rehosp_out == 0, 'time_to_rehosp_out'] = np.nan\n",
    "df_psm_matched_2017.loc[df_psm_matched_2017.time_to_rehosp_in == 0, 'time_to_rehosp_out'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'time_to_rehosp_out', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "chart = sns.barplot(data = df_psm_matched_2017, x = 'tt_status', y = 'time_to_rehosp_in', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average treatment effect (ATE)\n",
    "ate = df_psm_matched_2017.groupby(treatment_var)['time_to_rehosp_out'].mean().diff().iloc[-1]\n",
    "print(\"Average Treatment Effect:\", ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psm_matched_2017.time_to_rehosp_out.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine in year 1 have lower spending in following years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine in year 1 have lower drug consumption in following years?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine in year 1 have better health outcomes in the following years?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### Do individuals using integrative medicine in year 1 have better CDS in the following years?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "### Is there an effect of the number of years in the treatment group ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "## PSM on a continuous treatment variable\n",
    "Implementation using Python using GPT 4 below, documentation from a CRAN package on this link https://cran.r-project.org/web/packages/CBPS/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propensity Score Matching (PSM) with a continuous treatment variable requires a different approach compared to binary treatment. One common method is Generalized Propensity Score (GPS) matching. The GPS is the conditional density of receiving a particular treatment level given the observed covariates. Here's a step-by-step guide using Python:\n",
    "\n",
    "#Import Libraries: Import necessary Python libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Prepare Data: Assume df is your DataFrame and treatment is the continuous treatment variable, and covariates are your control variables.\n",
    "covariates = df[['covariate_1', 'covariate_2', 'covariate_3']]\n",
    "treatment = df['treatment']\n",
    "#Estimate Propensity Scores: Fit a regression model to estimate propensity scores. The Linear Regression model works well for continuous treatments.\n",
    "model = LinearRegression()\n",
    "model.fit(covariates, treatment)\n",
    "propensity_scores = model.predict(covariates)\n",
    "#Calculate GPS: You can calculate the generalized propensity score. For simplicity, we can consider it as the density of the predicted propensity score, which can be calculated using the Normal distribution in this example.\n",
    "\n",
    "gps_scores = norm.pdf(propensity_scores, np.mean(propensity_scores), np.std(propensity_scores))\n",
    "#Match: Now, you can match the units based on the calculated GPS. Several matching techniques like nearest neighbor, caliper matching, etc., can be employed. You may need to implement this step manually or use specialized libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "## Panel data modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels.panel import RandomEffects\n",
    "from statsmodels.datasets import grunfeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "data = grunfeld.load_pandas().data\n",
    "# Loading Grunfeld Investment data\n",
    "year = pd.Categorical(data.year)\n",
    "\n",
    "# Preparing data for panel model\n",
    "data = data.set_index(['firm','year'])\n",
    "data['year'] = year\n",
    "\n",
    "# Pooled OLS model\n",
    "pols = PanelOLS.from_formula('invest ~ value + capital + EntityEffects', data=data)\n",
    "pols_result = pols.fit()\n",
    "print(pols_result)\n",
    "\n",
    "# Fixed effects model\n",
    "fem = PanelOLS.from_formula('invest ~ value + capital + EntityEffects', data=data)\n",
    "fem_result = fem.fit()\n",
    "print(fem_result)\n",
    "\n",
    "# Random effects model\n",
    "rem = RandomEffects.from_formula('invest ~ value + capital', data=data)\n",
    "rem_result = rem.fit()\n",
    "print(rem_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "# Legacy code - Other PSM approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "## Matching without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into treatment and control groups\n",
    "treatment_data_wo_replacement = data_scaled[data_scaled[treatment_var] == 1]\n",
    "control_data_wo_replacement = data_scaled[data_scaled[treatment_var] == 0]\n",
    "# Set an initial large distance for each control individual\n",
    "control_data_wo_replacement['distance'] = np.inf\n",
    "\n",
    "# Set the index to be the original row order for later identification\n",
    "control_data_wo_replacement['index'] = range(len(control_data_wo_replacement))\n",
    "\n",
    "for i in range(len(treatment_data_wo_replacement)):\n",
    "    # Calculate the absolute distance between the treatment individual and all control individuals\n",
    "    distances_wo_replacement = abs(treatment_data_wo_replacement.iloc[i]['propensity_score'] - control_data_wo_replacement['propensity_score'])\n",
    "    \n",
    "    # If the minimum distance is less than the current saved distance for that control individual, update the match\n",
    "    if distances_wo_replacement.min() < control_data_wo_replacement.loc[distances_wo_replacement.idxmin(), 'distance']:\n",
    "        control_data_wo_replacement.loc[distances_wo_replacement.idxmin(), 'distance'] = distances_wo_replacement.min()\n",
    "        control_data_wo_replacement.loc[distances_wo_replacement.idxmin(), 'match'] = i\n",
    "\n",
    "# Select only those control individuals that have a match\n",
    "matched_control_data_wo_replacement = control_data_wo_replacement.dropna(subset=['match'])\n",
    "\n",
    "# Create the matched dataset\n",
    "df_matched_wo_replacement = pd.concat([treatment_data_wo_replacement, matched_control_data_wo_replacement]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched_wo_replacement.loc[df_matched_wo_replacement['treatment'] == 1, 'tt_status'] = 'Treatment'\n",
    "df_matched_wo_replacement.loc[df_matched_wo_replacement['treatment'] == 0, 'tt_status'] = 'Control'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "### Adding a caliper\n",
    "\n",
    "From the results of it, looks quite useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute absolute differences between treatment and control propensities\n",
    "abs_diff_propensity = np.abs(treatment_data['propensity_score'].values.reshape(-1, 1) - control_data.iloc[matched_control_indices]['propensity_score'].values.reshape(-1, 1))\n",
    "\n",
    "# Define caliper\n",
    "caliper = 0.05\n",
    "\n",
    "# Apply caliper: we only keep the pairs for which the absolute difference in propensity score is below the caliper\n",
    "indices_within_caliper = abs_diff_propensity.flatten() < caliper\n",
    "\n",
    "# Filter treatment and control data\n",
    "treatment_data_caliper = treatment_data[indices_within_caliper]\n",
    "matched_control_data_caliper = matched_control_data[indices_within_caliper]\n",
    "\n",
    "# Concatenate treatment and control data to get the final matched dataset\n",
    "df_matched_caliper = pd.concat([treatment_data_caliper, matched_control_data_caliper]).reset_index(drop=True)\n",
    "df_matched_caliper = pd.merge(df_matched_caliper, data_2017[['uuid', outcome_var]], on='uuid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "## Matching with replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "Use the `NearestNeighbors` algorithm from `scikit-learn` to perform 1-to-1 nearest-neighbor matching based on the propensity scores. Then, create a matched dataset containing the matched treatment and control observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into treatment and control groups\n",
    "treatment_data = data_scaled[data_scaled[treatment_var] == 1]\n",
    "control_data = data_scaled[data_scaled[treatment_var] == 0]\n",
    "# Create a NearestNeighbors matcher using the propensity scores\n",
    "matcher = NearestNeighbors(n_neighbors=1)\n",
    "matcher.fit(control_data['propensity_score'].values.reshape(-1, 1))\n",
    "# Find the nearest control observation for each treatment observation\n",
    "distances, indices = matcher.kneighbors(treatment_data['propensity_score'].values.reshape(-1, 1))\n",
    "\n",
    "# Create a matched dataset\n",
    "matched_control_indices = indices.flatten()\n",
    "matched_control_data = control_data.iloc[matched_control_indices]\n",
    "df_matched = pd.concat([treatment_data, matched_control_data]).reset_index(drop=True)\n",
    "# df_matched = pd.merge(df_matched, data_2017[['uuid',outcome_var]], on = 'uuid', how='left')\n",
    "df_matched.loc[df_matched['treatment'] == 1, 'tt_status'] = 'Treatment'\n",
    "df_matched.loc[df_matched['treatment'] == 0, 'tt_status'] = 'Control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STORING MATCHES\n",
    "\n",
    "# Split the dataset into treatment and control groups\n",
    "treatment_data = data_scaled[data_scaled[treatment_var] == 1]\n",
    "control_data = data_scaled[data_scaled[treatment_var] == 0]\n",
    "\n",
    "# Create a NearestNeighbors matcher using the propensity scores\n",
    "matcher = NearestNeighbors(n_neighbors=1)\n",
    "matcher.fit(control_data['propensity_score'].values.reshape(-1, 1))\n",
    "# Find the nearest control observation for each treatment observation\n",
    "distances, indices = matcher.kneighbors(treatment_data['propensity_score'].values.reshape(-1, 1))\n",
    "\n",
    "# Create a matched dataset\n",
    "# matched_control_indices = indices.flatten()\n",
    "matched_control_uuids = control_data.iloc[indices.flatten()]['uuid'].values\n",
    "# matched_control_data = control_data.iloc[matched_control_indices]\n",
    "# treatment_data = treatment_data.assign(matched_pair=np.arange(treatment_data.shape[0]))\n",
    "treatment_data['matched_uuid'] = matched_control_uuids\n",
    "\n",
    "matched_control_data = matched_control_data.assign(matched_pair=np.arange(matched_control_data.shape[0]))\n",
    "\n",
    "# df_matched = pd.concat([treatment_data, matched_control_data]).reset_index(drop=True)\n",
    "df_matched_w_match = treatment_data.merge(control_data, left_on='matched_uuid', right_on='uuid', suffixes=('_treatment', '_control'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "## Sensitivity analysis using causalml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "An alternative approach to propensity score matching is Coarsened Exact Matching (CEM). CEM is an orthogonal matching method that temporarily coarsens the data by placing observations into strata based on their covariate values and then performs exact matching on the coarsened data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import causalml\n",
    "from causalml.match import NearestNeighborMatch, MatchOptimizer\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def coarsened_exact_matching(treatment_data, control_data, treatment_var, covariate_columns, bins=5):\n",
    "    n = len(treatment_data) + len(control_data)\n",
    "    data = pd.concat([treatment_data, control_data])\n",
    "\n",
    "    # Coarsen the covariates\n",
    "    coarsened_covariates = pd.DataFrame(index=data.index, columns=covariate_columns)\n",
    "    \n",
    "    for col in covariate_columns:\n",
    "        coarsened_covariates[col] = pd.cut(data[col], bins=bins, labels=False)\n",
    "    \n",
    "    # Create a matcher and find the matched pairs\n",
    "    matcher = NearestNeighborMatch(replace=False, ratio=1, random_state=42)\n",
    "    matches = matcher.match(data.loc[:, treatment_var], [treatment_var], coarsened_covariates)\n",
    "    \n",
    "    # Extract the matched dataset\n",
    "    matched_data = data.loc[matches.index]\n",
    "    \n",
    "    return matched_data\n",
    "\n",
    "# Perform CEM on the treatment and control data\n",
    "# cem_matched_data = coarsened_exact_matching(treatment_data, control_data, treatment_var, covariate_columns, bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "Check the quality of the matching by comparing the balance of covariates between the treatment and control groups in the CEM-matched dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_comparison_cem = compare_balance(data_scaled, cem_matched_data, covariate_columns, treatment_var)\n",
    "print(balance_comparison_cem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "## Using pymatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_sample[df_sample.treatment == 1]\n",
    "control = df_sample[df_sample.treatment == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Matcher(test, control, yvar=\"treatment\", exclude=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "m.fit_scores(balance=True, nmodels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {},
   "source": [
    "## Using `psmpy`\n",
    "\n",
    "This script assumes that your data is in a CSV file named \"data.csv\" and that the variable indicating treatment status is called \"treatment\" (with 1 indicating the treatment group and 0 indicating the control group). The script also assumes that the variables you want to use for propensity score estimation are \"age\", \"gender\", and \"income\".\n",
    "\n",
    "The script first uses the PropensityScoreEstimator class to estimate the propensity scores for each individual in the treatment and control groups based on the specified covariates. It then uses the PropensityScoreMatching class to match individuals from the treatment and control groups based on their estimated propensity scores. Finally, it uses the balance_table function to examine the balance of covariates in the matched sample.\n",
    "\n",
    "You can also use other matching methods like Nearest Neighbor, Radius, and Kernel methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psmpy import PsmPy\n",
    "from psmpy.functions import cohenD\n",
    "from psmpy.plotting import *\n",
    "import sys\n",
    "# import pymatch\n",
    "# from pymatch.Matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm = PsmPy(data_scaled, treatment='treatment', indx='uuid', exclude = [], seed = 42)\n",
    "\n",
    "psm.logistic_ps(balance = True)\n",
    "\n",
    "psm.predicted_data\n",
    "\n",
    "psm.knn_matched(matcher='propensity_logit', replacement=True, caliper=0.05, drop_unmatched=False)\n",
    "\n",
    "# psm.knn_matched_12n(matcher='propensity_logit', how_many=2)\n",
    "\n",
    "psm.plot_match(Title='Side by side matched controls', Ylabel='Number of individuals', Xlabel= 'Propensity logit', names = ['treatment', 'control'], save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched_psmpy=psm.df_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm.effect_size_plot(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_COLOUR = 'grey'\n",
    "T_COLOUR = 'green'\n",
    "C_LABEL = 'Control'\n",
    "T_LABEL = 'Treatment'\n",
    "for var in ['NBAGE', 'SEX_F','MTFRANCHISECOUV','CANTON_NAME_Genève']:\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
    "    # Visualise original distribution\n",
    "    sns.kdeplot(data=df_sample[df_sample['treatment'] == 0], x=var, fill=True, \n",
    "                color=C_COLOUR, label=C_LABEL, ax=ax[0])\n",
    "    sns.kdeplot(data=df_sample[df_sample['treatment'] == 1], x=var, fill=True, \n",
    "                color=T_COLOUR, label=T_LABEL, ax=ax[0])\n",
    "    ax[0].set_title('Before matching')\n",
    "    \n",
    "    # Visualise new distribution\n",
    "    sns.kdeplot(data=df_matched[df_matched['treatment'] == 0], x=var, \n",
    "                fill=True, color=C_COLOUR, label=C_LABEL, ax=ax[1])\n",
    "    sns.kdeplot(data=df_matched[df_matched['treatment'] == 1], x=var, \n",
    "                fill=True, color=T_COLOUR, label=T_LABEL, ax=ax[1])\n",
    "    ax[1].set_title('After matching')\n",
    "    ax[1].set_ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "ax[0].legend(loc='center', bbox_to_anchor=(1.1, -0.3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = pd.merge(df_matched, data_2017[['uuid',outcome_var]].sample(20000, random_state=42), on = 'uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average treatment effect (ATE)\n",
    "ate = df_matched.groupby(treatment_var)[outcome_var].mean().diff().iloc[-1]\n",
    "print(\"Average Treatment Effect:\", ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "## Method 2 - Package `DoWhy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Specify treatment variable and covariates\n",
    "df_sample = data_2017[['uuid','treatment','NBAGE','MTFRANCHISECOUV','SEX_F','PRESTATIONS_TOTAL']].sample(2000, random_state=42)\n",
    "\n",
    "# Define causal model using DoWhy\n",
    "model = CausalModel(\n",
    "    data=df_sample,\n",
    "    treatment='treatment',\n",
    "    outcome='PRESTATIONS_TOTAL',\n",
    "    common_causes=['NBAGE', 'SEX_F']\n",
    ")\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"backdoor.propensity_score_stratification\")\n",
    "#print(estimate)\n",
    "print(\"The Causal Estimate is \" + str(estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.view_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate_match = model.estimate_effect(identified_estimand,\n",
    "                                              method_name=\"backdoor.propensity_score_matching\",\n",
    "                                              target_units=\"atc\", method_params={\n",
    "        'ratio': 1.0,\n",
    "        'matching_method': 'nearest',\n",
    "        'distance_metric': 'absolute_difference',\n",
    "    })\n",
    "print(causal_estimate_match)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate_match.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot propensity score distribution before and after matching\n",
    "propensity_score_data = df_sample.propensity_score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_sample[df_sample['treatment'] == 0].propensity_score, bins=20, alpha=0.5, label='Control')\n",
    "plt.hist(df_sample[df_sample['treatment'] == 1].propensity_score, bins=20, alpha=0.5, label='Treated')\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import matplotlib.pyplot as plt\n",
    "from dowhy.do_samplers import propensity_score_matching_estimator\n",
    "\n",
    "\n",
    "# Specify treatment variable and covariates\n",
    "\n",
    "# Define causal model using DoWhy\n",
    "model = CausalModel(\n",
    "    data=data,\n",
    "    treatment=treatment,\n",
    "    outcome='outcome',\n",
    "    common_causes=covariates\n",
    ")\n",
    "\n",
    "# Estimate propensity scores using logistic regression\n",
    "propensity_score_estimator = propensity_score_matching_estimator(\n",
    "    data=data,\n",
    "    treatment_variable=treatment,\n",
    "    outcome_variable='outcome',\n",
    "    method='lr'\n",
    ")\n",
    "propensity_score_estimator.reset()\n",
    "propensity_scores = propensity_score_estimator.estimate()\n",
    "data['propensity_score'] = propensity_scores['fitted']\n",
    "# Perform matching\n",
    "estimate = model.estimate_effect(\n",
    "    method_name='backdoor.propensity_score_matching',\n",
    "    target_units='ate',\n",
    "    method_params={\n",
    "        'ratio': 1.0,\n",
    "        'matching_method': 'nearest',\n",
    "        'distance_metric': 'absolute_difference',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print average treatment effect estimate\n",
    "print(\"ATE estimate: \", estimate.value)\n",
    "\n",
    "# Plot propensity score distribution before and after matching\n",
    "propensity_score_data = model.propensity_score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(propensity_score_data[data[treatment] == 0], bins=20, alpha=0.5, label='Control')\n",
    "plt.hist(propensity_score_data[data[treatment] == 1], bins=20, alpha=0.5, label='Treated')\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147",
   "metadata": {},
   "source": [
    "## Method 3 - Package `causalinference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017.columns[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from causalinference import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a CausalModel\n",
    "cm = CausalModel(\n",
    "    Y=data_2017[outcome_var].values, \n",
    "    D=data_scaled[treatment_var].values, \n",
    "    X=data_scaled[categorical_columns+continuous_columns].values\n",
    ")\n",
    "\n",
    "# Estimate propensity scores\n",
    "cm.est_propensity()\n",
    "\n",
    "# Perform matching with caliper\n",
    "cm.trim_s()\n",
    "cm.stratify_s()\n",
    "# cm.match_s()\n",
    "cm.est_via_matching(matches=1, bias_adj=True)\n",
    "\n",
    "# Print matched data summary\n",
    "print(cm.summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_2017['PRESTATIONS_TOTAL'].values\n",
    "t = data_2017['treatment'].values\n",
    "X = data_2017[['SEX_F', 'NBAGE','MTFRANCHISECOUV']]\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), \n",
    "                 columns=X.columns).values\n",
    "model = CausalModel(y, t, X)\n",
    "model.est_via_matching()\n",
    "print(model.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['logit', 'age']:\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
    "    # Visualise original distribution\n",
    "    sns.kdeplot(data=df[~df[TREATMENT]], x=var, shade=True, \n",
    "                color=C_COLOUR, label=C_LABEL, ax=ax[0])\n",
    "    sns.kdeplot(data=df[df[TREATMENT]], x=var, shade=True, \n",
    "                color=T_COLOUR, label=T_LABEL, ax=ax[0])\n",
    "    ax[0].set_title('Before matching')\n",
    "    \n",
    "    # Visualise new distribution\n",
    "    sns.kdeplot(data=matched_df[~matched_df[TREATMENT]], x=var, \n",
    "                shade=True, color=C_COLOUR, label=C_LABEL, ax=ax[1])\n",
    "    sns.kdeplot(data=matched_df[matched_df[TREATMENT]], x=var, \n",
    "                shade=True, color=T_COLOUR, label=T_LABEL, ax=ax[1])\n",
    "    ax[1].set_title('After matching')\n",
    "    ax[1].set_ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "ax[0].legend(loc='center', bbox_to_anchor=(1.1, -0.3));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153",
   "metadata": {},
   "source": [
    "## Optimising the procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154",
   "metadata": {},
   "source": [
    "Perform KNN matching.\n",
    "\n",
    "psm.knn_matched(matcher='propensity_logit', replacement=False, caliper=None, drop_unmatched=True)\n",
    "\n",
    "Note:\n",
    "\n",
    "matcher - propensity_logit (default) and generated in previous step alternative option is propensity_score, specifies the argument on which matching will proceed\n",
    "\n",
    "replacement - False (default), determines whethermacthing will happen with or without replacement,when replacement is false matching happens 1:1\n",
    "\n",
    "caliper - None (default), user can specify caliper size relative to std. dev of the control sample, restricting neighbors eligible to match within a certain distance.\n",
    "\n",
    "drop_unmatched - True (default) In the event that indexes do not have a match due to caliper size it will remove them from the 'matched_df', 'matched_ids' and subsequent calculations of effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a larger sample size for propensity score estimation\n",
    "sample_size = 2000\n",
    "\n",
    "# Increase the number of neighbors used for matching\n",
    "k = 3\n",
    "\n",
    "# Use a larger caliper\n",
    "caliper = 0.2\n",
    "\n",
    "# Use decision tree to estimate the propensity scores\n",
    "psm = PsmPy(data_2017[['uuid','treatment','NBAGE','MTFRANCHISECOUV','SEX_F']].sample(sample_size),\n",
    "            treatment='treatment', indx='uuid', exclude=[])\n",
    "\n",
    "psm.logistic_ps(balance=True)\n",
    "\n",
    "psm.knn_matched(replacement=False, caliper=caliper)\n",
    "\n",
    "psm.plot_match(Title='Side by side matched controls', Ylabel='Number of individuals',\n",
    "               Xlabel='Propensity score', names=['treatment', 'control'], save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "psm.effect_size_plot(save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "## Procedure with XGBoost to predict scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the treatment and outcome variables\n",
    "treatment = 'treatment'\n",
    "outcome = 'outcome'\n",
    "\n",
    "# Define the covariates\n",
    "covariates = ['NBAGE','MTFRANCHISECOUV','SEX_F']\n",
    "\n",
    "# Split the data into treatment and control groups\n",
    "treated = data_2017[data_2017[treatment] == 1]\n",
    "control = data_2017[data_2017[treatment] == 0]\n",
    "\n",
    "# Sample the data to improve the training speed\n",
    "treated = treated.sample(frac=0.1, replace=False, random_state=1)\n",
    "control = control.sample(frac=0.1, replace=False, random_state=1)\n",
    "\n",
    "# Create the training and testing datasets\n",
    "train = pd.concat([treated, control], axis=0)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Create the XGBoost data matrices\n",
    "dtrain = xgb.DMatrix(train[covariates], label=train[treatment])\n",
    "dtest = xgb.DMatrix(test[covariates])\n",
    "\n",
    "# Define the XGBoost hyperparameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'seed': 1\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "# Predict the propensity scores\n",
    "train['propensity_score'] = bst.predict(dtrain)\n",
    "test['propensity_score'] = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the caliper value for matching\n",
    "caliper = 0.05\n",
    "\n",
    "# Combine the treated and control groups\n",
    "matched_data = pd.concat([treated, control], axis=0)\n",
    "\n",
    "# Create a PsmPy object with the matched data\n",
    "psm = PsmPy(matched_data[['uuid','treatment','NBAGE','MTFRANCHISECOUV','SEX_F']], treatment=treatment, indx='uuid', exclude=[])\n",
    "\n",
    "# Perform nearest-neighbor matching using the predicted propensity scores\n",
    "psm.knn_matched(replacement=False, caliper=caliper)\n",
    "\n",
    "# Plot the matched data\n",
    "psm.plot_match(Title='Side by side matched controls', Ylabel='Number of individuals',\n",
    "               Xlabel='Propensity score', names=['treatment', 'control'], save=True)\n",
    "\n",
    "# Compute the effect size\n",
    "effect_size = cohenD(psm.data[treatment], psm.data[outcome], psm.data['Matched'])\n",
    "\n",
    "# Print the effect size\n",
    "print('Effect size:', effect_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "## R MatchIt implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = '/Users/david/miniforge3/envs/py310/lib/R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Load the MatchIt package in R\n",
    "matchit = importr('MatchIt')\n",
    "\n",
    "# Load the data into R\n",
    "robjects.globalenv['data'] = robjects.conversion.py2rpy(data_2017)\n",
    "\n",
    "# Define the treatment and outcome variables\n",
    "treatment = 'treatment'\n",
    "outcome = 'outcome'\n",
    "\n",
    "# Define the covariates\n",
    "covariates = ['NBAGE','MTFRANCHISECOUV','SEX_F']\n",
    "robjects.globalenv['covariates'] = robjects.StrVector(covariates)\n",
    "\n",
    "# Define the R script to perform propensity score matching\n",
    "script = \"\"\"\n",
    "# Load the data into R\n",
    "install.packages('Matchit')\n",
    "data <- data.frame(data)\n",
    "\n",
    "# Define the treatment and outcome variables\n",
    "treatment <- '\"\"\" + treatment + \"\"\"'\n",
    "outcome <- '\"\"\" + outcome + \"\"\"'\n",
    "\n",
    "# Define the covariates\n",
    "covariates <- covariates\n",
    "\n",
    "# Perform propensity score matching using the nearest neighbor method with a caliper\n",
    "matched_data <- matchit(\n",
    "    formula = as.formula(paste(treatment, \"~\", paste(covariates, collapse=\"+\"))),\n",
    "    data = data,\n",
    "    method = \"nearest\",\n",
    "    caliper = 0.05\n",
    ")\n",
    "\n",
    "# Extract the matched data from the \"matched\" object\n",
    "matched_data <- match.data(matched_data)\n",
    "\n",
    "# Return the matched data as a data frame\n",
    "matched_data <- data.frame(matched_data)\n",
    "\"\"\"\n",
    "\n",
    "# Run the R script to perform propensity score matching\n",
    "robjects.r(script)\n",
    "\n",
    "# Retrieve the matched data from R and convert it to a pandas dataframe\n",
    "matched_data = pd.DataFrame(np.array(robjects.globalenv['matched_data']), columns=data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects.packages as rpackages\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Load the MatchIt package\n",
    "matchit = importr('MatchIt')\n",
    "\n",
    "# Load the Lalonde dataset from the MatchIt package\n",
    "lalonde = matchit.Lalonde\n",
    "\n",
    "# Create a formula for the treatment variable and covariates\n",
    "formula = robjects.Formula('treat ~ age + educ + black + hisp + married + nodegr + re74 + re75')\n",
    "\n",
    "# Perform matching using the nearest neighbor method\n",
    "matched_data = matchit.matchit(formula=formula, data=lalonde, method='nearest', ratio=1)\n",
    "\n",
    "# View the matched data\n",
    "print(matched_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psm",
   "language": "python",
   "name": "psm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
