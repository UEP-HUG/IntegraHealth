{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "os.environ['USE_PYGEOS'] = '0'  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import geoplot\n",
    "import geoplot.crs as gcrs\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "import fiona\n",
    "import libpysal as lps\n",
    "from scipy.spatial import cKDTree\n",
    "from libpysal.weights.distance import get_points_array\n",
    "from esda import fdr\n",
    "# import datashader as ds, colorcet as cc\n",
    "# import holoviews as hv\n",
    "# from holoviews.element.tiles import EsriImagery\n",
    "# from datashader.utils import export_image\n",
    "# from holoviews.operation.datashader import datashade\n",
    "# hv.extension(\"bokeh\")\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "sys.path.append('/Users/david/Dropbox/PhD/Scripts/Spatial analyses')\n",
    "import pyspace\n",
    "import utils\n",
    "from utils import optimize_memory_df, feature_map, show_values, sizeof_fmt, find_intersection, read_data\n",
    "\n",
    "# Local imports\n",
    "from importlib import reload  # Are you using this somewhere?\n",
    "\n",
    "\n",
    "plt.rc('font', family='Helvetica')  # Try to keep configuration parameters together, maybe in a single configuration function or at the beginning of your script.\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "\n",
    "This notebook is dedicated to a large range of data preparation and exploratory data analyses (EDA) and including ESDA. This notebook is meant to be a building block to generate questions and problem statements that will be investigated in subsequent notebooks. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Data</b> \n",
    "\n",
    "- Groupe Mutuel :\n",
    "    - AOS couverture\n",
    "    - LCA couverture\n",
    "    - AOS prestations\n",
    "    - LCA prestations\n",
    "    - AOS prescriptions\n",
    "    - AOS & LCA geomasked coordinates\n",
    "- Socio-economic:\n",
    "    - Area-based index of socio-economic position in Switzerland â€“ Swiss-SEP (2012) https://jech.bmj.com/content/66/12/1129.long\n",
    "    - Paper describing Swiss-SEP update https://smw.ch/index.php/smw/article/view/3285/5527. The new Swiss-SEP can be obtained by signing a contract with the SNC (managed by OFSP since 2022). Visit https://boris-portal.unibe.ch/handle/20.500.12422/148 for more info.\n",
    "- Geographic units:\n",
    "    - Lakes\n",
    "    - Cantons\n",
    "    - Communes\n",
    "    - Populated hectares\n",
    "- Accessibility\n",
    "- Environmental indicators:\n",
    "    - Noise pollution\n",
    "    - Air pollution\n",
    "    - Vegetation index\n",
    "    - Land surface temperature\n",
    "    \n",
    "</div> \n",
    "  \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TO DO LIST</b>   \n",
    "\n",
    "- Prestations LCA:\n",
    "    - One-hot encoding LCA specialties\n",
    "    - Therapy-price pairs (is it solvable?)\n",
    "- Prestations AOS:\n",
    "    - Creation of a variable : `hospitalized` YES/NO\n",
    "    - Creation of a variable : `re-hospitalized` YES/NO if hospitalized for the same MDC in a period of 6 months\n",
    "    - Creation of a variable : `n_hosp` INT for the number of hospitalisations\n",
    "    - One-hot encoding of DRGs\n",
    "    - One-hot encoding of MDCs\n",
    "\n",
    "- For both type of prestations and drugs `time-variables`:\n",
    "    - Spike profile\n",
    "    - Month with highest amount\n",
    "    - Average monthly amount\n",
    "    - Last 3 months amount\n",
    "    - Total amount\n",
    "    - Number of months above mean\n",
    "    - Maximum monthly amount\n",
    "\n",
    "- Drug AOS:\n",
    "    - Create variable `polymedication` YES/NO if n_atc > 5 and age > 65 \n",
    "\n",
    "</div> \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Done</b>   \n",
    "\n",
    "- Prepare data for PSM (yearly):\n",
    "    - Preparation of prestations LCA\n",
    "        - Agregation of LCA specialties\n",
    "        - Total amount\n",
    "        - Number of factures\n",
    "    - Preparation of prestations AOS\n",
    "        - One-hot encoding by sous_categorie_dispensateur\n",
    "        - One-hot encoding by type_prestation\n",
    "        - Total amount\n",
    "        - Number of factures\n",
    "        - Hospitalisation :\n",
    "            - Completion of the SwissDRGs list\n",
    "    - Preparation of drug AOS:\n",
    "        - One-hot encoding of ATCs\n",
    "        - Total number of ATCs\n",
    "\n",
    "- Group definition (yearly) \n",
    "- Group transitions (yearly)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "</div> \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTES</b> \n",
    "\n",
    "- Basic outcomes :\n",
    "    - Prestations amount\n",
    "    - Prescription amount\n",
    "    - Total amount\n",
    "    - Amount by prestation\n",
    "    - Amount by prescription\n",
    "    - Polymedication (0/1) or number of different drugs\n",
    "    - MIP (0/1) or number of MIP\n",
    "    - Hospitalisation (0/1)\n",
    "    - Number of hospitalisations\n",
    "    - Total length of stay in hospital\n",
    "    - Re-hospitalisation (0/1)\n",
    "    - Time to re-hospitalisation\n",
    "    \n",
    "- Feature engineering:\n",
    "    - Spike profile\n",
    "    - total_monthly_drug_cost\n",
    "    - total_drug_cost\n",
    "    - max_monthly_drug_cost\n",
    "    - mean_monthly_drug_cost\n",
    "    - n_months_above_mean\n",
    "    - last_3months_total_drug_cost\n",
    "    - Gender\n",
    "    - Age\n",
    "    - Franchise\n",
    "    - Canton (one-hot encoded)\n",
    "    - Commune (one-hot encoded)\n",
    "    - X\n",
    "    - Y\n",
    "    - SES (0 to 100)\n",
    "    - Accessibility to healthcare services\n",
    "    - Environmental indicators\n",
    "    - One-hot encoded prestations (to think about...data leaks)\n",
    "    - One-hot encoded prescriptions (to think about...data leaks)\n",
    "\n",
    "- Forecasting :\n",
    "    - Agregated by time -> 1 time-series\n",
    "    - Agregated by time and individuals -> n individuals time-series\n",
    "    - Agregated by time and groups of individuals -> n groups time-series\n",
    "- Survival analyses:\n",
    "    - Time to AOS usage\n",
    "    - Time to LCA usage\n",
    "But, we don't really have censored data! For the whole period, we could censor people who have never used any AOS or LCA. But as we see hereunder, we have a very low fraction of individuals who didn't use LCA in the period 2017-2021.\n",
    "    \n",
    "- Cumulated outcomes :\n",
    "    - Cumulated number of bills\n",
    "    - Cumulated amount of bills\n",
    "    - Cumulated time hospitalized\n",
    "    - Number of re-hospitalization\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base data folder\n",
    "data_folder  = Path('../Data/')\n",
    "# Define base result folder\n",
    "result_folder = Path('../Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Insurance claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_couverture_aos = read_data(data_folder/'processed'/'df_couverture_aos_preprocessed.parquet.gzip')\n",
    "df_paires_lamal_lca = pd.read_csv(data_folder/'max_probs_w_zipcode_pour_david_w_uuid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paires_lamal_lca['matching_score'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paires_lamal_lca.id_lca.nunique()                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "df_prestation_aos = read_data(data_folder/'processed'/'df_prestation_aos_preprocessed.parquet.gzip')\n",
    "df_prestation_aos_cam = read_data(data_folder/'processed'/'df_prestation_aos_cam_preprocessed.parquet.gzip')\n",
    "df_prestation_lca = read_data(data_folder/'processed'/'df_prestation_lca_preprocessed.parquet.gzip')\n",
    "df_drug_aos = read_data(data_folder/'processed'/'df_drug_aos_preprocessed.parquet.gzip')\n",
    "df_couverture_aos = read_data(data_folder/'processed'/'df_couverture_aos_preprocessed.parquet.gzip')\n",
    "df_couverture_lca = read_data(data_folder/'processed'/'df_couverture_lca_preprocessed.parquet.gzip')\n",
    "df_flag_aos = read_data(data_folder/'processed'/'df_flag_aos_preprocessed.parquet.gzip')\n",
    "\n",
    "df_addresses_w_access_pollution_ndvi_lst_sep = read_data(data_folder/'processed'/'df_addresses_with_socio_env.parquet.gzip', geo=True, lon='lon_masked', lat='lat_masked')\n",
    "df_full_address = read_data(data_folder/'processed'/'df_full_address.parquet.gzip', geo=True, lon='lon_masked', lat='lat_masked')\n",
    "\n",
    "# Dictionary creation\n",
    "dict_lamal_to_uuid = df_paires_lamal_lca.set_index('id_lamal')['uuid'].to_dict()\n",
    "dict_lca_to_uuid = df_paires_lamal_lca.set_index('id_lca')['uuid'].to_dict()\n",
    "\n",
    "dict_lamal_to_lca = df_paires_lamal_lca.set_index('id_lamal')['id_lca'].to_dict()\n",
    "dict_lca_to_lamal = df_paires_lamal_lca.set_index('id_lca')['id_lamal'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prestation_aos_cam = read_data(data_folder/'processed'/'df_prestation_aos_cam_preprocessed.parquet.gzip')\n",
    "# df_couverture_aos = read_data(data_folder/'processed'/'df_couverture_aos_preprocessed.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam = pd.merge(df_prestation_aos_cam, df_couverture_aos[['uuid','NOANNEE','CANTON_NAME']].drop_duplicates(), left_on = ['uuid','ANNEE_TRAITEMENT'], right_on = ['uuid','NOANNEE'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tarmed_cam = {0.171:'Acupuncture',\n",
    "                   0.172:'Acupuncture',\n",
    "                   0.173:'Acupuncture',\n",
    "                   0.173:'Acupuncture',\n",
    "                   0.174:'Neural therapy',\n",
    "                   0.175:'Neural therapy',\n",
    "                   0.176:'Neural therapy',\n",
    "                   0.177:'Homeopathy',\n",
    "                   0.178:'Homeopathy',\n",
    "                   0.179:'Homeopathy',\n",
    "                   0.180:'Homeopathy',\n",
    "                   0.180:'Homeopathy',\n",
    "                   0.181:'Traditional Chinese medicine',\n",
    "                   0.182:'Traditional Chinese medicine',\n",
    "                   0.183:'Traditional Chinese medicine',\n",
    "                   0.184:'Anthroposophic medicine',\n",
    "                   0.185:'Anthroposophic medicine',\n",
    "                   0.186:'Anthroposophic medicine',\n",
    "                   0.187:'Phytotherapy',\n",
    "                   0.1871:'Phytotherapy',\n",
    "                   0.1872:'Phytotherapy',\n",
    "                   0.188:'Phone consultation',\n",
    "                   0.189:'Phone consultation',\n",
    "                   0.1895:'Phone consultation',\n",
    "                   0.1896:'Phone consultation',\n",
    "                   0.19:'Phone consultation',\n",
    "\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam['CDPOSITION_cat'] = df_prestation_aos_cam['CDPOSITION'].map(dict_tarmed_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam.CDPOSITION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam.groupby('CANTON_NAME')['ID_DISPENSATEUR'].nunique().sort_values().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam.groupby('CDPOSITION_cat')['ID_DISPENSATEUR'].nunique().sort_values().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Prevalence of complementary medicine\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Problem Statement</b> \n",
    "\n",
    "What is the prevalence of integrative medicine utilization among patients in the claims data? This can help to understand the scale of the problem and the potential impact of integrative medicine interventions.\n",
    "\n",
    "**Notes**\n",
    "- What is the definition for the group that did not use LCA? Across the whole study period, within a year, a month, a treatment period?\n",
    "- How do we define a treatment period?\n",
    "    \n",
    "    \n",
    "To handle an analysis comparing two groups of individuals \"Consumers of healthcare insurance\" and \"Non-consumers of healthcare insurance\" over time, I would use a longitudinal study design. This would involve tracking the same individuals over a period of time, and recording their healthcare insurance status at multiple time points.\n",
    "\n",
    "To handle the fact that individuals can change groups over time, I would use a combination of methods. First, I would use appropriate statistical methods, such as multi-state models, to account for the transition of individuals between the two groups over time. Second, I would ensure that the study design and data collection methods are robust enough to accurately capture changes in individuals' healthcare insurance status. Finally, I would also report any missing data or loss to follow-up in the analysis, and consider how this may have affected the results.\n",
    "## Multi-state model \n",
    "A multi-state model is a type of statistical model that is used to analyze data from a longitudinal study in which individuals can transition between different states over time. In the context of healthcare insurance, a multi-state model could be used to analyze the transition of individuals between being a consumer and non-consumer of healthcare insurance over time.\n",
    "\n",
    "A multi-state model is typically represented by a set of equations that describe the probability of transitioning between different states, and the probability of remaining in the same state. The model takes into account the time elapsed between transitions, and can include covariates, such as individual characteristics or exposures, that may influence the transition probabilities. The results of a multi-state model can provide insight into the dynamics of the healthcare insurance status over time, and inform policy decisions.\n",
    "    \n",
    "``` \n",
    "from lifelines import Multistate Cox Regression\n",
    "\n",
    "# Prepare the data in the format required by the model\n",
    "data = ... \n",
    "\n",
    "# Specify the transition matrix\n",
    "transition_matrix = ...\n",
    "\n",
    "# Fit the model\n",
    "mscr = MultistateCoxRegression(data, transition_matrix)\n",
    "mscr.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(mscr.summary)\n",
    "```\n",
    "    \n",
    "Or using `statsmodels` :\n",
    "    \n",
    "```import statsmodels.api as sm\n",
    "\n",
    "# Prepare the data in the format required by the model\n",
    "data = ... \n",
    "\n",
    "# Specify the transition matrix\n",
    "transition_matrix = ...\n",
    "\n",
    "# Fit the model\n",
    "mscr = sm.Multinomial(data, transition_matrix)\n",
    "mscr.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(mscr.summary)\n",
    "```\n",
    "\n",
    "In a multi-state model, the transition matrix is a square matrix that describes the probability of transitioning between different states over time. The rows and columns of the matrix correspond to the different states, and the elements of the matrix represent the transition probabilities.\n",
    "\n",
    "Here's an example of how you might define a transition matrix for a multi-state model with two states (consumer and non-consumer of healthcare insurance):\n",
    "\n",
    "```\n",
    "transition_matrix = [[0.9, 0.1],\n",
    "                     [0.3, 0.7]]\n",
    "```\n",
    "This matrix represents the probability of transitioning from one state to another over time. The matrix tells us that:\n",
    "\n",
    "The probability of staying in the consumer state is 0.9, and the probability of transitioning to the non-consumer state is 0.1\n",
    "The probability of staying in the non-consumer state is 0.7, and the probability of transitioning to the consumer state is 0.3\n",
    "It's important to note that the probabilities in the matrix must sum to 1 for each row, because it's representing the probability of being in a state or transitioning to another state.\n",
    "\n",
    "You can also specify the transition matrix in a more flexible way by including covariates that may influence the transition probabilities. This can be done by defining the matrix as a function of the covariates, and estimating the parameters of the function using the data.\n",
    "\n",
    "It's also important to note that when you use a multi-state model, you need to have the data in a format that includes the state of each individual at each time point, and the time at which the transition occurred. So, you need to have a dataset that includes the healthcare insurance status of each individual at multiple time points.\n",
    "\n",
    "### Transition probabilities\n",
    "The transition probabilities in a multi-state model are typically estimated from the data using maximum likelihood estimation (MLE) or Bayesian inference.\n",
    "\n",
    "Maximum likelihood estimation (MLE) is a method for estimating the parameters of a statistical model that makes the observed data most probable. The MLE method estimates the transition probabilities by maximizing the likelihood of the observed data, given the model and the parameters. For example, in the lifelines package, the Multistate Cox Regression model uses MLE to estimate the transition probabilities.\n",
    "\n",
    "Bayesian inference is a method for estimating the parameters of a statistical model based on prior information and the observed data. It uses Bayes' theorem to update the prior probability distribution of the parameters, given the data. Bayesian inference can be used to estimate the transition probabilities in a multi-state model by specifying prior distributions for the parameters and updating them using the data.\n",
    "\n",
    "Once you have the transition probabilities calculated, you can use them to estimate the probability of an individual being in a particular state at a given time point, or the probability of transitioning from one state to another over a given time interval. These probabilities can be used to make predictions about the future healthcare insurance status of individuals and make policy decisions based on that.\n",
    "    \n",
    "### Example of running a multi-state model with transition probabilities estimation\n",
    "```    \n",
    "from lifelines import MultistateCoxRegressionFitter\n",
    "\n",
    "# Prepare the data in the format required by the model\n",
    "data = pd.DataFrame({'id': [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "                    'time': [1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "                    'state': [1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0],\n",
    "                    'covariate': [0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]})\n",
    "\n",
    "# Specify the transition matrix\n",
    "transition_matrix = [[0, 1], [1, 0]]\n",
    "\n",
    "# Create an instance of the Multi-State Cox Regression Fitter\n",
    "mscrf = MultistateCoxRegressionFitter(transition_matrix=transition_matrix)\n",
    "\n",
    "# Fit the model\n",
    "mscrf.fit(data, 'time', 'state', id_col='id', show_progress=True)\n",
    "\n",
    "# Print the summary\n",
    "print(mscrf.summary)\n",
    "```\n",
    "In this example, the data is in the long format, it includes the individual ID, the time of the transition, the state of the individual (consumer or non-consumer of healthcare insurance) and a covariate that may influence the transition probability.\n",
    "\n",
    "The transition matrix is defined as [[0, 1], [1, 0]]. The first row of the matrix represents the probability of transitioning from the consumer state to the non-consumer state, and the second row represents the probability of transitioning from the non-consumer state to the consumer state.\n",
    "\n",
    "The MultistateCoxRegressionFitter function is used to fit the model. The function takes the data, the name of the time column, the name of the state column, and the name of the individual ID column as input. The fit() method is used to fit the model.\n",
    "\n",
    "The summary() method prints the summary of the model, which includes the estimates of the transition probabilities and their standard errors, along with other information such as the log-likelihood, AIC, and BIC.\n",
    "\n",
    "It's important to note that this is just an example and not a complete script, you may need to adjust it based on your data and the specific requirements of your analysis. Also, this script assumes that you have installed the lifelines package and imported the necessary library.\n",
    "</div>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### How many people having a LCA did not have any \"prestations\" in the period 2017-2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ID_LCA not in df_prestation_lca\n",
    "insured_without_prestation = df_couverture_lca[~df_couverture_lca.ID_LCA.isin(df_prestation_lca.ID_LCA)]\n",
    "\n",
    "# Count unique ID_LCA\n",
    "unique_insured_count = insured_without_prestation.ID_LCA.nunique()\n",
    "\n",
    "# Print the message\n",
    "print(f'There are only {unique_insured_count} insured people who did not have a single LCA prestation from 2017 to 2021.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of insured people who did not use their LCA\n",
    "non_users = df_couverture_lca[~df_couverture_lca.ID_LCA.isin(df_prestation_lca.ID_LCA)].ID_LCA.nunique()\n",
    "total_users = df_couverture_lca.ID_LCA.nunique()\n",
    "non_user_percent = (non_users / total_users) * 100\n",
    "\n",
    "# Print the message\n",
    "print(f\"That's only {non_user_percent:.3f} % of the sample. Soooo, people do like and use their LCA!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### What about within a single year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframes for 2017\n",
    "df_couverture_lca_2017 = df_couverture_lca[df_couverture_lca.NOANNEE == 2017]\n",
    "df_prestation_lca_2017 = df_prestation_lca[df_prestation_lca.ANNEE_TRAITEMENT == 2017]\n",
    "\n",
    "# Find the IDs in df_couverture_lca_2017 but not in df_prestation_lca_2017\n",
    "non_users_2017 = df_couverture_lca_2017[~df_couverture_lca_2017.ID_LCA.isin(df_prestation_lca_2017.ID_LCA)]\n",
    "\n",
    "# Count the unique IDs (insured people who did not use their LCA in 2017)\n",
    "non_user_count_2017 = non_users_2017.ID_LCA.nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f'There are only {non_user_count_2017} insured people who did not have a single LCA prestation in 2017.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of insured people who did not use their LCA in 2017\n",
    "non_users_2017_count = non_users_2017.ID_LCA.nunique()\n",
    "total_users_2017_count = df_couverture_lca_2017.ID_LCA.nunique()\n",
    "non_user_percent_2017 = (non_users_2017_count / total_users_2017_count) * 100\n",
    "\n",
    "# Print the message\n",
    "print(f\"That's {non_user_percent_2017:.3f} % of the sample. So people use their LCA BUT within a single year we still have more than 40% that didn't use it!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year column and ID column\n",
    "df1_year = df_couverture_lca['NOANNEE']\n",
    "df1_id = df_couverture_lca['uuid']\n",
    "df2_year = df_prestation_lca['ANNEE_TRAITEMENT']\n",
    "df2_id = df_prestation_lca['uuid']\n",
    "\n",
    "# create a set of unique IDs in df2 for each year\n",
    "df2_id_sets = df_prestation_lca.groupby('ANNEE_TRAITEMENT', observed = True)['uuid'].apply(set)\n",
    "\n",
    "# create a new column in df1 to indicate whether the ID is present in df2 for that year\n",
    "df_couverture_lca['in_df2'] = df_couverture_lca.apply(lambda x: x['uuid'] in df2_id_sets[x['NOANNEE']], axis=1)\n",
    "\n",
    "# filter out rows where the ID is present in df2\n",
    "df_no_lca_in_year = df_couverture_lca[df_couverture_lca['in_df2'] == False]\n",
    "df_lca_in_year = df_couverture_lca[df_couverture_lca['in_df2'] == True]\n",
    "\n",
    "# group by year and count the number of IDs not present in df2\n",
    "count_by_year_no_lca = df_no_lca_in_year.groupby(df1_year, observed = True)['uuid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of insured individuals not using their LCA within a year')\n",
    "(count_by_year_no_lca/df_couverture_lca.groupby('NOANNEE', observed = True).ID_LCA.nunique()).mul(100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Some features are directly visible:\n",
    "- Almost 100% of insured individuals utilized their complementary insurance coverage during the period 2017-2021.\n",
    "- Around 40% of the insured individuals do not utilize their complementary insurance coverage within a single year (for complementary medecine purposes).\n",
    "- There is an increase in LCA non-utilization, most likely linked to the COVID-19 pandemic.\n",
    "- The prevalence goes back to usual levels in 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## AOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year column and ID column\n",
    "df1_year = df_couverture_aos['NOANNEE']  # all insured people\n",
    "df1_id = df_couverture_aos['uuid']\n",
    "df2_year = df_prestation_aos['ANNEE_TRAITEMENT']  # insured people that used aos\n",
    "df2_id = df_prestation_aos['uuid']\n",
    "\n",
    "# create a DataFrame with unique IDs in df2 for each year\n",
    "df2_unique_ids = df_prestation_aos[['ANNEE_TRAITEMENT', 'uuid']].drop_duplicates()\n",
    "\n",
    "# merge df_couverture_aos and df2_unique_ids on uuid and NOANNEE/ANNEE_TRAITEMENT columns\n",
    "merged_df = pd.merge(df_couverture_aos, df2_unique_ids, left_on=['uuid', 'NOANNEE'], right_on=['uuid', 'ANNEE_TRAITEMENT'], how='left', indicator=True)\n",
    "\n",
    "# filter out rows where the ID is present in df2\n",
    "df_no_aos_in_year = optimize_memory_df(merged_df[merged_df['_merge'] == 'left_only'])\n",
    "df_aos_in_year = optimize_memory_df(merged_df[merged_df['_merge'] == 'both'])\n",
    "\n",
    "# group by year and count the number of IDs not present in df2\n",
    "count_by_year_no_aos = df_no_aos_in_year.groupby(df1_year, observed=True)['uuid'].nunique()\n",
    "\n",
    "print(count_by_year_no_aos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### How many people having a AOS did not have any \"prestations\" in the period 2017-2021?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of unique ID_LAMAL values in both dataframes\n",
    "unique_ids_couverture = set(df_couverture_aos['ID_LAMAL'])\n",
    "unique_ids_prestation = set(df_prestation_aos['ID_LAMAL'])\n",
    "\n",
    "# Find the difference between the sets, i.e., IDs in \"df_couverture_aos\" that are not in \"df_prestation_aos\"\n",
    "ids_without_prestation = unique_ids_couverture - unique_ids_prestation\n",
    "\n",
    "# Count the number of such IDs\n",
    "num_ids_without_prestation = len(ids_without_prestation)\n",
    "\n",
    "# Print the result\n",
    "print(f'There are only {num_ids_without_prestation} insured people who did not have a single ID_LAMAL prestation from 2017 to 2021.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique ID_LAMAL values in each dataframe\n",
    "total_unique_ids = df_couverture_aos['ID_LAMAL'].nunique()\n",
    "unique_ids_without_prestation = len(ids_without_prestation) # from the previous step\n",
    "\n",
    "# Calculate the proportion of IDs that do not have a prestation\n",
    "proportion_without_prestation = unique_ids_without_prestation / total_unique_ids\n",
    "\n",
    "# Convert the proportion to a percentage and round it to three decimal places\n",
    "percentage_without_prestation = round(proportion_without_prestation * 100, 3)\n",
    "\n",
    "# Print the result\n",
    "print(f\"That's only {percentage_without_prestation} % of the sample. So, there are more people using their LCA than using their LAMAL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### What about within a single year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_uuid_by_year = df_prestation_aos_cam.groupby(['ANNEE_TRAITEMENT']).uuid.nunique().reset_index()\n",
    "print(\"Number of distinct individuals receiving CAM within AOS by year\",df_unique_uuid_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total des prestations CAM within the AOS for the period 2017-2021: \",df_prestation_aos_cam.PRESTATIONS_BRUTES.sum().round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# extract year column and ID column\n",
    "df1_year = df_couverture_aos['NOANNEE']  # all insured people\n",
    "df1_id = df_couverture_aos['uuid']\n",
    "df2_year = df_prestation_aos['ANNEE_TRAITEMENT']  # insured people that used aos\n",
    "df2_id = df_prestation_aos['uuid']\n",
    "\n",
    "# create a DataFrame with unique IDs in df2 for each year\n",
    "df2_unique_ids = df_prestation_aos[['ANNEE_TRAITEMENT', 'uuid']].drop_duplicates()\n",
    "\n",
    "# merge df_couverture_aos and df2_unique_ids on uuid and NOANNEE/ANNEE_TRAITEMENT columns\n",
    "merged_df = pd.merge(df_couverture_aos, df2_unique_ids, left_on=['uuid', 'NOANNEE'], right_on=['uuid', 'ANNEE_TRAITEMENT'], how='left', indicator=True)\n",
    "\n",
    "# filter out rows where the ID is present in df2\n",
    "df_no_aos_in_year = merged_df[merged_df['_merge'] == 'left_only']\n",
    "df_aos_in_year = merged_df[merged_df['_merge'] == 'both']\n",
    "df_aos_in_year = optimize_memory_df(df_aos_in_year)\n",
    "\n",
    "# group by year and count the number of IDs not present in df2\n",
    "count_by_year_no_aos = df_no_aos_in_year.groupby(df1_year, observed=True)['uuid'].nunique()\n",
    "print('Number of people without AOS claims within a year')\n",
    "print(count_by_year_no_aos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of insured individuals not using their LCA within a year')\n",
    "\n",
    "count_by_year_no_aos/df_couverture_aos.groupby('NOANNEE', observed = True).uuid.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Some features are directly visible:\n",
    "- 98% of insured individuals utilized their mandatory insurance coverage (AOS) during the period 2017-2021.\n",
    "- Around 5-10% of the insured individuals do not utilize their mandatory insurance coverage (AOS) within a year (for complementary medecine purposes).\n",
    "- There seems to be a trend of increasing prevalence of AOS usage over time.\n",
    "- The prevalence of AOS utilization is the highest in 2021, with only around 2% not utilizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Verification of total amounts and number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CAM - AOS', df_prestation_aos_cam['PRESTATIONS_BRUTES'].sum()/1000000, df_prestation_aos_cam.ID_LAMAL.nunique())\n",
    "print('AOS', df_prestation_aos['PRESTATIONS_BRUTES'].sum()/1000000, df_prestation_lca.ID_LAMAL.nunique())\n",
    "print('LCA', df_prestation_lca['PRESTATIONS_BRUTES'].sum()/1000000, df_prestation_lca.ID_LCA.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Everything ok at this stage !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### People not insured for both insurance each year of the 2017-2021 period\n",
    "After some digging, we found that we have a good number of people who actually don't have both insurance for the whole period ! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_insured_aos_in_year = pd.merge(df_couverture_lca[[\"uuid\",'NOANNEE']].drop_duplicates(), df_couverture_aos[[\"uuid\",'NOANNEE','Annee_naiss']].drop_duplicates(), on = ['uuid','NOANNEE'], how = 'left')\n",
    "df_not_insured_lca_in_year = pd.merge(df_couverture_aos[[\"uuid\",'NOANNEE']].drop_duplicates(), df_couverture_lca[[\"uuid\",'NOANNEE','Annee_naiss']].drop_duplicates(), on = ['uuid','NOANNEE'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_insured_aos_in_year = df_not_insured_aos_in_year[df_not_insured_aos_in_year.Annee_naiss.isnull()]\n",
    "df_not_insured_lca_in_year = df_not_insured_lca_in_year[df_not_insured_lca_in_year.Annee_naiss.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "This technique is great to identify people that present in one type of insurance but not the other (not insured that year). But can't identify people that are in neither...not insured at all. Forming a gp9 based on not_insured_aos and not_insured_lca won't work bc of that (I commented out this code below). What we can easily do is by elimination define that these are the ones not insured at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Define groups\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Problem Statement</b> \n",
    "    \n",
    "We need to create groups of insured individuals based on their AOS and LCA utilization. This step is rather straightforward. The only challenge is to decide how to consider how individuals may change groups overtime depending on the time period selected. Are we ok with the fact that individuals might be part of group 1 in year 1, then 3 in year 2, then 4 in year 3, then 1 again in year 4, etc. \n",
    "    \n",
    " If we consider that insurance utilization is independent between years, I would say yes. But that is a simplification, as we know that it is not actually independent as there is autocorrelation in an individual's healthcare consumption.\n",
    "    \n",
    "We can :\n",
    "1) Calculate the prevalence of individuals switching groups over the whole period and over any two years. This will help better understand how people change behaviors over time and indicate how much back and forth there might be between AOS and LCA. \n",
    "2) We can use models for longitudinal data (General Estimating Equation GEE, Multilevel modeling) using the UUID as a random variable.\n",
    "3) See if we can predict usage of LCA. Are there any condition, period of the year, or sociodemographic determinants of utilization?\n",
    "4) See if we can predict when someone is going to use LCA ! That would be a great forecasting task\n",
    "    \n",
    "- Define groups : \n",
    "    1) Group 1 : Used both LCA & LAMAL\n",
    "    2) Group 2 : Used only LCA\n",
    "    3) Group 3 : Used only LAMAL\n",
    "    4) Group 4 : Used neither\n",
    "- Time period : whole period, year, quarter, month, treatment\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_couverture_aos['uuid'] = df_couverture_aos['ID_LAMAL'].map(dict_lamal_to_uuid)\n",
    "# df_couverture_lca['uuid'] = df_couverture_lca['ID_LCA'].map(dict_lca_to_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prestation_aos['uuid'] = df_prestation_aos['ID_LAMAL'].map(dict_lamal_to_uuid)\n",
    "# df_prestation_lca['uuid'] = df_prestation_lca['ID_LCA'].map(dict_lca_to_uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Simplest version - Time period = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df_no_aos_in_year.groupby('NOANNEE', observed = True).uuid.unique()\n",
    "s2 = df_aos_in_year.groupby('NOANNEE', observed = True).uuid.unique()\n",
    "s3 = df_lca_in_year.groupby('NOANNEE', observed = True).uuid.unique()\n",
    "s4 = df_no_lca_in_year.groupby('NOANNEE', observed = True).uuid.unique()\n",
    "s5 = df_not_insured_aos_in_year.groupby('NOANNEE',observed = True).uuid.unique()\n",
    "s6 = df_not_insured_lca_in_year.groupby('NOANNEE',observed = True).uuid.unique()\n",
    "s7 = df_prestation_aos_cam.groupby('ANNEE_TRAITEMENT', observed = True).uuid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gps = pd.concat([s1, s2, s3, s4, s5, s6, s7], axis = 1)\n",
    "df_gps.columns =  ['no_aos', 'aos', 'lca', 'no_lca', 'not_insured_aos', 'not_insured_lca', 'cam_in_aos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_intersection(row, col1, col2):\n",
    "    return list(set(row[col1]).intersection(row[col2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row of the DataFrame\n",
    "df_gps['gp1'] = df_gps.apply(lambda x: find_intersection(x, ['aos', 'lca']), axis=1)\n",
    "df_gps['gp2'] = df_gps.apply(lambda x: find_intersection(x, ['no_aos', 'lca']), axis=1)\n",
    "df_gps['gp3'] = df_gps.apply(lambda x: find_intersection(x, ['aos', 'no_lca']), axis=1)\n",
    "df_gps['gp4'] = df_gps.apply(lambda x: find_intersection(x, ['no_aos', 'no_lca']), axis=1)\n",
    "df_gps['gp5'] = df_gps.apply(lambda x: find_intersection(x, ['not_insured_aos', 'lca']), axis=1)\n",
    "df_gps['gp6'] = df_gps.apply(lambda x: find_intersection(x, ['aos', 'not_insured_lca']), axis=1)\n",
    "df_gps['gp7'] = df_gps.apply(lambda x: find_intersection(x, ['no_aos', 'not_insured_lca']), axis=1)\n",
    "df_gps['gp8'] = df_gps.apply(lambda x: find_intersection(x, ['not_insured_aos', 'no_lca']), axis=1)\n",
    "df_gps['gp9'] = df_gps.apply(lambda x: find_intersection(x, ['aos', 'cam_in_aos']), axis=1)\n",
    "df_gps['gp10'] = df_gps.apply(lambda x: find_intersection(x, ['no_aos', 'cam_in_aos']), axis=1)\n",
    "df_gps['gp11'] = df_gps.apply(lambda x: find_intersection(x, ['lca', 'cam_in_aos']), axis=1)\n",
    "df_gps['gp12'] = df_gps.apply(lambda x: find_intersection(x, ['no_lca', 'cam_in_aos']), axis=1)\n",
    "df_gps['gp13'] = df_gps.apply(lambda x: find_intersection(x, ['lca', 'aos', 'cam_in_aos']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels_gps =  {1:'LCA & AOS',\n",
    "                    2:'LCA only',\n",
    "                    3:'AOS only',\n",
    "                    4:'No usage',\n",
    "                    5:'Not insured AOS, LCA',\n",
    "                    6:'Not insured LCA, AOS',\n",
    "                    7:'No usage - No AOS & not insured LCA',\n",
    "                    8:'No usage - No LCA & not insured AOS',\n",
    "                    9:'AOS & CAM in AOS',\n",
    "                    10:'No AOS & CAM in AOS',\n",
    "                    11:'LCA & CAM in AOS',\n",
    "                    12:'No LCA & CAM in AOS',\n",
    "                    13:'LCA & AOS & CAM in AOS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 14):\n",
    "    df_gps[f'len_gp{i}'] = df_gps[f'gp{i}'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gps = df_gps.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gps_exploded = pd.concat([pd.DataFrame({'NOANNEE':df_gps['index'],'uuid': df_gps[col].explode(), 'gp': int(col.replace('gp',''))}) for col in df_gps.columns if col.startswith('gp')]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retain only the gps that are non-overlapping. \n",
    "# Groups 9, 10, 11, 12, 13 are a bit problematic but may be of interest for other analyses\n",
    "df_gps_exploded_excl_gp = df_gps_exploded[df_gps_exploded.gp < 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_mapping_dict = df_gps_exploded.set_index(['NOANNEE','uuid'])['gp'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_value(row, col1 , col2):\n",
    "#     col1_val = row[col1]\n",
    "#     col2_val = row[col2]\n",
    "#     return gp_mapping_dict.get((col1_val, col2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_couverture_aos = df_couverture_aos.merge(df_gps_exploded_excl_gp, on=[\"NOANNEE\", \"uuid\"], how=\"left\")\n",
    "df_couverture_lca = df_couverture_lca.merge(df_gps_exploded_excl_gp, on=[\"NOANNEE\", \"uuid\"], how=\"left\")\n",
    "df_prestation_lca = df_prestation_lca.merge(df_gps_exploded_excl_gp, left_on=['ANNEE_TRAITEMENT','uuid'], right_on=[\"NOANNEE\", \"uuid\"], how=\"left\")\n",
    "df_prestation_aos = df_prestation_aos.merge(df_gps_exploded_excl_gp, left_on=['ANNEE_TRAITEMENT','uuid'], right_on=[\"NOANNEE\", \"uuid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam = df_prestation_aos_cam.merge(df_gps_exploded, left_on=['ANNEE_TRAITEMENT','uuid'], right_on=[\"NOANNEE\", \"uuid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_cam.gp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "### Prestations AOS\n",
    "\n",
    "Create a dataset containing the outcomes relevant to the study by month and by year\n",
    "\n",
    "- Nombre de prestations par an et par patient\n",
    "- Montant total (BRUT) de prestations par patient et par an\n",
    "- Montant total (NET) de prestations par patient et par an\n",
    "- Nombre de factures par an et par patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos[['ANNEE_TRAITEMENT','MOIS_TRAITEMENT']] = df_prestation_aos[['ANNEE_TRAITEMENT','MOIS_TRAITEMENT']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For time series analyses, or month based analyses in the future\n",
    "\n",
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'n_prestation_aos_by_patient_by_month.parquet.gzip'):\n",
    "    n_prestation_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).size()\n",
    "else:\n",
    "    n_prestation_aos_by_patient_by_month = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'n_prestation_aos_by_patient_by_month.parquet.gzip')\n",
    "\n",
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'sum_prestation_brutes_aos_by_patient_by_month.parquet.gzip'):\n",
    "    sum_prestation_brutes_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).PRESTATIONS_BRUTES.sum()\n",
    "else:\n",
    "    sum_prestation_brutes_aos_by_patient_by_month = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'sum_prestation_brutes_aos_by_patient_by_month.parquet.gzip')\n",
    "\n",
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'sum_prestation_nettes_aos_by_patient_by_month.parquet.gzip'):\n",
    "    sum_prestation_nettes_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).PRESTATIONS_NETTES.sum()\n",
    "else:\n",
    "    sum_prestation_nettes_aos_by_patient_by_month = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'sum_prestation_nettes_aos_by_patient_by_month.parquet.gzip') \n",
    "\n",
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'n_bill_prestation_aos_by_patient_by_month.parquet.gzip'):\n",
    "    n_bill_prestation_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).NBRE_FACTURES.sum()\n",
    "else:\n",
    "    n_bill_prestation_aos_by_patient_by_month = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'n_bill_prestation_aos_by_patient_by_month.parquet.gzip')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For time series analyses, or month based analyses in the future\n",
    "# n_prestation_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).size()\n",
    "# sum_prestation_brutes_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).PRESTATIONS_BRUTES.sum()\n",
    "# sum_prestation_nettes_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).PRESTATIONS_NETTES.sum()\n",
    "# n_bill_prestation_aos_by_patient_by_month = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).NBRE_FACTURES.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute key indicators from AOS spending\n",
    "n_prestation_aos_by_patient_by_year = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT']).size()\n",
    "sum_prestation_brutes_aos_by_patient_by_year = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT']).PRESTATIONS_BRUTES.sum()\n",
    "sum_prestation_brutes_aos_ambulatoire_by_patient_by_year = df_prestation_aos[df_prestation_aos.TYPE_PRESTATION == 'AMBULATOIRE'].groupby(['uuid','ANNEE_TRAITEMENT']).PRESTATIONS_BRUTES.sum()\n",
    "sum_prestation_brutes_aos_stationnaire_by_patient_by_year = df_prestation_aos[df_prestation_aos.TYPE_PRESTATION == 'STATIONNAIRE'].groupby(['uuid','ANNEE_TRAITEMENT']).PRESTATIONS_BRUTES.sum()\n",
    "sum_prestation_nettes_aos_by_patient_by_year = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT']).PRESTATIONS_NETTES.sum()\n",
    "n_ss_categorie_disp_aos_by_patient_by_year = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT']).SOUS_CATEGORIE_DISPENSATEUR.nunique()\n",
    "n_bill_prestation_aos_by_patient_by_year = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT']).NBRE_FACTURES.sum()\n",
    "sum_prestation_brutes_cam_aos_by_patient_by_year = df_prestation_aos_cam.groupby(['uuid','ANNEE_TRAITEMENT']).PRESTATIONS_BRUTES.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prestation_brutes_aos_by_patient_by_year.sum()/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prestation_brutes_aos_by_patient_by_month = pd.DataFrame(sum_prestation_brutes_aos_by_patient_by_month).reset_index()\n",
    "sum_prestation_brutes_aos_by_patient_by_month['MOIS_TRAITEMENT'] = sum_prestation_brutes_aos_by_patient_by_month['MOIS_TRAITEMENT'].astype(float)\n",
    "sum_prestation_brutes_aos_by_patient_by_year = pd.DataFrame(sum_prestation_brutes_aos_by_patient_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the cumulative sum within each year\n",
    "sum_prestation_brutes_aos_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] = sum_prestation_brutes_aos_by_patient_by_month.sort_values(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].cumsum()\n",
    "\n",
    "month_reached_1000_aos = sum_prestation_brutes_aos_by_patient_by_month[sum_prestation_brutes_aos_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 1000].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()\n",
    "month_reached_5000_aos = sum_prestation_brutes_aos_by_patient_by_month[sum_prestation_brutes_aos_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 5000].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()\n",
    "month_reached_10000_aos = sum_prestation_brutes_aos_by_patient_by_month[sum_prestation_brutes_aos_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 10000].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest month\n",
    "max_monthly_prestation_cost = sum_prestation_brutes_aos_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly average\n",
    "mean_monthly_prestation_cost = sum_prestation_brutes_aos_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean three last months\n",
    "last_3months_total_prestation_cost = sum_prestation_brutes_aos_by_patient_by_month[sum_prestation_brutes_aos_by_patient_by_month.MOIS_TRAITEMENT.isin([10,11,12])].groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N months above mean - LONG\n",
    "# n_months_above_mean_prestation = sum_prestation_brutes_aos_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT'], group_keys=True)['PRESTATIONS_BRUTES'].apply(lambda x: x> x.mean())\n",
    "# n_months_above_mean_prestation = n_months_above_mean_prestation[n_months_above_mean_prestation == True].groupby(['uuid','ANNEE_TRAITEMENT']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike profile - LONG\n",
    "# spike_profile_prestation = sum_prestation_brutes_aos_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT'], group_keys=True)['PRESTATIONS_BRUTES'].apply(lambda x: x> 0.50*x.sum())\n",
    "# spike_profile_prestation = spike_profile_prestation[spike_profile_prestation == True].groupby(['uuid','ANNEE_TRAITEMENT']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "#### Nombre de categorie dispensateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dispensateur_aos = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT']).CATEGORIE_DISPENSATEUR.apply(set).apply(lambda x: len(x) if isinstance(x, set) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### Concat all AOS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_outcomes_by_year = pd.concat([n_prestation_aos_by_patient_by_year, sum_prestation_brutes_aos_by_patient_by_year, sum_prestation_brutes_cam_aos_by_patient_by_year, sum_prestation_brutes_aos_ambulatoire_by_patient_by_year, sum_prestation_brutes_aos_stationnaire_by_patient_by_year, sum_prestation_nettes_aos_by_patient_by_year, n_bill_prestation_aos_by_patient_by_year,month_reached_1000_aos, month_reached_5000_aos, month_reached_10000_aos, max_monthly_prestation_cost,mean_monthly_prestation_cost, last_3months_total_prestation_cost, n_dispensateur_aos, n_ss_categorie_disp_aos_by_patient_by_year], axis = 1).reset_index().rename(columns = {0:'NBROWS'})\n",
    "# df_prestation_aos_outcomes_by_year = df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT'], observed = True)[['NBROWS','PRESTATIONS_BRUTES','PRESTATIONS_NETTES','NBRE_FACTURES']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_outcomes_by_year.columns = ['uuid', 'ANNEE_TRAITEMENT', 'NBROWS', 'PRESTATIONS_BRUTES','PRESTATIONS_BRUTES_CAM', 'PRESTATIONS_BRUTES_AMBULATOIRE', \"PRESTATIONS_BRUTES_STATIONNAIRE\",\n",
    "       'PRESTATIONS_NETTES', 'NBRE_FACTURES','month_reached_1000_aos','month_reached_5000_aos','month_reached_10000_aos','max_monthly_aos','mean_monthly_aos','last3month_aos','n_cat_dispensateur_aos','n_ss_cat_dispensateur_aos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prestation_aos_outcomes['treatmentdate'] = pd.to_datetime(df_prestation_aos_outcomes['ANNEE_TRAITEMENT'].astype('string') + '-' + df_prestation_lca_outcomes['MOIS_TRAITEMENT'].astype('string'))\n",
    "# df_prestation_aos_outcomes['treatmentmonth'] = df_prestation_aos_outcomes['treatmentdate'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "#### Amount CAM by CDPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_CDPOSITION.parquet.gzip'):\n",
    "\n",
    "    df_amount_by_cdposition = pd.DataFrame(df_prestation_aos_cam.groupby(['uuid','ANNEE_TRAITEMENT','CDPOSITION_cat']).PRESTATIONS_BRUTES.sum()).reset_index()\n",
    "    df_amount_by_cdposition = df_amount_by_cdposition.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'CDPOSITION_cat', values = 'PRESTATIONS_BRUTES').reset_index().fillna(0)\n",
    "    df_amount_by_cdposition.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_cdposition.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_amount_by_cdposition = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_cdposition.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "#### Amount by type sinistre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_sinistre.parquet.gzip'):\n",
    "\n",
    "    df_amount_by_sinistre = pd.DataFrame(df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','CDTYPESINISTRE']).PRESTATIONS_BRUTES.sum()).reset_index()\n",
    "    df_amount_by_sinistre = df_amount_by_sinistre.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'CDTYPESINISTRE', values = 'PRESTATIONS_BRUTES').reset_index()\n",
    "    df_amount_by_sinistre.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_sinistre.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_amount_by_sinistre = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_sinistre.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "#### Amount by sous-catÃ©gorie dispensateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_souscat_disp.parquet.gzip'):\n",
    "\n",
    "    df_amount_by_souscat_disp = pd.DataFrame(df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','SOUS_CATEGORIE_DISPENSATEUR']).PRESTATIONS_BRUTES.sum()).reset_index()\n",
    "    df_amount_by_souscat_disp = df_amount_by_souscat_disp.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'SOUS_CATEGORIE_DISPENSATEUR', values = 'PRESTATIONS_BRUTES').reset_index()\n",
    "    df_amount_by_souscat_disp.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_souscat_disp.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_amount_by_souscat_disp = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_souscat_disp.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "#### Proportion by type of prestation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_type_prestation.parquet.gzip'):\n",
    "    df_amount_by_type_prestation = pd.DataFrame(df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','TYPE_PRESTATION'])['PRESTATIONS_BRUTES'].sum()).reset_index()\n",
    "    df_amount_by_type_prestation = df_amount_by_type_prestation.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'TYPE_PRESTATION', values = 'PRESTATIONS_BRUTES').reset_index()\n",
    "    df_amount_by_type_prestation['AMBULATOIRE'] = df_amount_by_type_prestation['AMBULATOIRE']\n",
    "    df_amount_by_type_prestation['STATIONNAIRE'] = df_amount_by_type_prestation['STATIONNAIRE']\n",
    "    df_amount_by_type_prestation.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_type_prestation.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_amount_by_type_prestation = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_type_prestation.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prestation_aos_outcomes_by_year = pd.concat([n_prestation_aos_by_patient_by_year, sum_prestation_brutes_aos_by_patient_by_year, sum_prestation_nettes_aos_by_patient_by_year, n_bill_prestation_aos_by_patient_by_year], axis = 1).reset_index().rename(columns = {0:'NBROWS'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### SwissDRGs\n",
    "\n",
    "1. Manually copy pasted list from [SwissDRGs](https://datenspiegel120.swissdrg.org/drgs?locale=fr) into an excel file.\n",
    "\n",
    "2. Completed the file because there were missing DRGs, we used [SwissDRG v.6.0](https://www.swissdrg.org/application/files/7114/8111/2947/Swiss-DRG_Version_6.0_Fallpauschalenkatalog_franz_KV_genehmigt.pdf), [SwissDRG v.7.0](https://www.swissdrg.org/application/files/9514/9907/7413/Swiss-DRG_Version_7.0_Fallpauschalenkatalog_PV_2016_2018_genehmigt_f.pdf) and [SwissDRG v.12.0](https://www.swissdrg.org/application/files/5016/7152/9703/SwissDRG-Version_12.0_Fallpauschalenkatalog_AV_2023_2023_f.pdf) \n",
    "\n",
    "\n",
    "We can also download excel version of each SwissDRG version [Here](https://www.swissdrg.org/fr/somatique-aigue/archiv-swissdrg-system/systeme-swissdrg-1002021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swiss_drg = pd.read_excel(data_folder/'raw'/'SwissDRGs.xlsx')\n",
    "df_swiss_drg_v10 = pd.read_excel(data_folder/'raw'/'SwissDRG-Version_10.0.xlsx', sheet_name = 'HÃ´pitaux de soins aigus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swiss_drg_v10_supplemented = pd.concat([df_swiss_drg_v10, df_swiss_drg[df_swiss_drg.DRG.isin(df_swiss_drg_v10.DRG) == False]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swiss_drg_v10_supplemented = df_swiss_drg_v10_supplemented.rename(columns = {'DÃ©signation':'DRG_desc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swiss_drg_v10_supplemented[df_swiss_drg_v10_supplemented['DRG_desc'].str.contains('\\?', na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_drg = pd.merge(df_prestation_aos, df_swiss_drg_v10_supplemented[['DRG','DRG_desc','Cost-weight','DurÃ©e moyenne de sÃ©jour']], left_on = 'CODE_DRG', right_on = 'DRG', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_drg.to_parquet(data_folder/'processed'/'df_aos_drg.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_prestation_aos_drg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prestation_aos = df_prestation_aos.drop(['DRG_desc','Cost-weight','DurÃ©e moyenne de sÃ©jour'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "#### TO DO : There seems to be something missing here...We are not done with DRGs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "#### Hospitalized\n",
    "\n",
    "Flags stationnaires : 'LOCDRHOSP' : flag sÃ©jour officiel de la compensation des risques : si 1, lâ€™assurÃ© a passÃ© au moins 3 nuits consÃ©cutives dans 1 hopital ou 1 EMS.\n",
    "'LOPCG' : PCG oui/non, est Ã  1 si lâ€™assurÃ© Ã  au moins 1 PCG. Ci-dessous aussi est Ã  1 si lâ€™assurÃ© Ã  le PCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nomenclature_flags = pd.read_csv(data_folder/'raw'/'GM'/'Full'/'Nomenclature_flags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hospital = df_prestation_aos[df_prestation_aos.CODE_DRG.isnull()==False].groupby(['uuid','ANNEE_TRAITEMENT'])['CODE_DRG'].transform(lambda x: x.notnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos[~df_prestation_aos.CODE_DRG.isnull()]['CODE_DRG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inpatient_hosp = df_prestation_aos[(df_prestation_aos.CODE_DRG.isnull()==False)&(df_prestation_aos.TYPE_PRESTATION == 'STATIONNAIRE')]\n",
    "df_outpatient_hosp = df_prestation_aos[(df_prestation_aos.CODE_DRG.isnull()==False)&(df_prestation_aos.TYPE_PRESTATION == 'AMBULATOIRE')]\n",
    "\n",
    "df_outpatient_hosp['treatmentmonth'] = pd.to_datetime(df_outpatient_hosp['treatmentmonth'].astype('string'))\n",
    "df_inpatient_hosp['treatmentmonth'] = pd.to_datetime(df_inpatient_hosp['treatmentmonth'].astype('string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "#### Number of hospitalisations\n",
    "\n",
    "- We differentiate in and outpatient hosp.\n",
    "- We consider that if there is an hosp. for the same DRGs for two consecutive months, it counts for 1 hosp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_month_inpatient = pd.DataFrame(df_prestation_aos[(df_prestation_aos.CODE_DRG.isnull()==False)&(df_prestation_aos.TYPE_PRESTATION == 'STATIONNAIRE')].groupby(['uuid', 'treatmentmonth']).CODE_DRG.apply(set)).reset_index()\n",
    "df_grouped_month_outpatient = pd.DataFrame(df_prestation_aos[(df_prestation_aos.CODE_DRG.isnull()==False)&(df_prestation_aos.TYPE_PRESTATION == 'AMBULATOIRE')].groupby(['uuid', 'treatmentmonth']).CODE_DRG.apply(set)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_month_inpatient['treatmentmonth'] = pd.to_datetime(df_grouped_month_inpatient['treatmentmonth'].astype('string'))\n",
    "df_grouped_month_outpatient['treatmentmonth'] = pd.to_datetime(df_grouped_month_outpatient['treatmentmonth'].astype('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOES NOT WORK AS INTENDED BUT I KEEP IT BC IT MAY BE USEFUL FOR TIME BETWEEN HOSP\n",
    "\n",
    "# # Group the data by individual ID and year, and count the number of events within a year having distinct DRGs\n",
    "# df_grouped_year_inpatient = df_grouped_month_inpatient.groupby(['uuid', pd.Grouper(key='treatmentmonth', freq='1Y')])['CODE_DRG'].apply(lambda x: x.ne(x.shift()).cumsum().nunique() if not x.dropna().empty else 0)\n",
    "# df_grouped_year_outpatient = df_grouped_month_outpatient.groupby(['uuid', pd.Grouper(key='treatmentmonth', freq='1Y')])['CODE_DRG'].apply(lambda x: x.ne(x.shift()).cumsum().nunique() if not x.dropna().empty else 0)\n",
    "\n",
    "# # Reset the index to get a new dataframe with the 'uuid', 'treatmentdate', and 'num_hospitalisations' columns\n",
    "# df_result_inpatient = df_grouped_year_inpatient.reset_index(name='num_hospitalisations')\n",
    "# df_result_outpatient = df_grouped_year_outpatient.reset_index(name='num_hospitalisations')\n",
    "\n",
    "# # Merge the 'num_hospitalisations' column back to the original dataframe\n",
    "# # df = pd.merge(df, df_result, on=['uuid', 'treatmentdate'], how='left')\n",
    "\n",
    "# # Replace NaN values with 0\n",
    "# # df['num_hospitalisations'] = df['num_hospitalisations'].fillna(0)\n",
    "\n",
    "# # Convert the 'num_hospitalisations' column to integer type\n",
    "# # df['num_hospitalisations'] = df['num_hospitalisations'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_grouped_year_inpatient.parquet.gzip'):\n",
    "    \n",
    "    df_grouped_month_inpatient['year'] = df_grouped_month_inpatient['treatmentmonth'].dt.year\n",
    "\n",
    "    groups = df_grouped_month_inpatient.groupby(['uuid', pd.Grouper(key='treatmentmonth', freq='1Y')])\n",
    "\n",
    "    for (uuid, month), group in groups:\n",
    "        # initialize the count of hospitalisations\n",
    "        count = 0\n",
    "        # initialize the previous month\n",
    "        prev_month = ''\n",
    "        prev_code = ''\n",
    "        # loop over the rows in the group\n",
    "        for i, row in group.iterrows():\n",
    "            # check if there is a hospitalisation code\n",
    "            if not pd.isna(row['CODE_DRG']):\n",
    "                # check if it's a new hospitalisation event\n",
    "                if row['treatmentmonth'] != prev_month:\n",
    "                    if row['CODE_DRG'] != prev_code:\n",
    "                        count += 1\n",
    "                        prev_month = row['treatmentmonth']\n",
    "                        prev_code = row['CODE_DRG']\n",
    "            # update the count of hospitalisations for this row\n",
    "            df_grouped_month_inpatient.loc[i, 'n_inpatient_hosp'] = count\n",
    "\n",
    "    df_grouped_year_inpatient = pd.DataFrame(df_grouped_month_inpatient.groupby(['uuid','year'])['n_inpatient_hosp'].max()).reset_index()\n",
    "    df_grouped_year_inpatient.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_grouped_year_inpatient.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_grouped_year_inpatient = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_grouped_year_inpatient.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_grouped_year_outpatient.parquet.gzip'):\n",
    "\n",
    "    df_grouped_month_outpatient['year'] = df_grouped_month_outpatient['treatmentmonth'].dt.year\n",
    "\n",
    "    groups = df_grouped_month_outpatient.groupby(['uuid', pd.Grouper(key='treatmentmonth', freq='1Y')])\n",
    "\n",
    "    for (uuid, month), group in groups:\n",
    "        # initialize the count of hospitalisations\n",
    "        count = 0\n",
    "        # initialize the previous month\n",
    "        prev_month = ''\n",
    "        prev_code = ''\n",
    "        # loop over the rows in the group\n",
    "        for i, row in group.iterrows():\n",
    "            # check if there is a hospitalisation code\n",
    "            if not pd.isna(row['CODE_DRG']):\n",
    "                # check if it's a new hospitalisation event\n",
    "                if row['treatmentmonth'] != prev_month:\n",
    "                    if row['CODE_DRG'] != prev_code:\n",
    "                        count += 1\n",
    "                        prev_month = row['treatmentmonth']\n",
    "                        prev_code = row['CODE_DRG']\n",
    "            # update the count of hospitalisations for this row\n",
    "            df_grouped_month_outpatient.loc[i, 'n_outpatient_hosp'] = count\n",
    "\n",
    "    df_grouped_year_outpatient = pd.DataFrame(df_grouped_month_outpatient.groupby(['uuid','year'])['n_outpatient_hosp'].max()).reset_index()\n",
    "    df_grouped_year_outpatient.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_grouped_year_outpatient.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_grouped_year_outpatient = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_grouped_year_outpatient.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "#### Number of hospitalized months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_month_outpatient = pd.DataFrame(df_grouped_month_outpatient[df_grouped_month_outpatient.CODE_DRG.isnull()==False].groupby(['uuid', pd.Grouper(key='treatmentmonth', freq='1Y')]).size(), columns = ['n_month_outpatienthosp']).reset_index()\n",
    "df_n_month_inpatient = pd.DataFrame(df_grouped_month_inpatient[df_grouped_month_inpatient.CODE_DRG.isnull()==False].groupby(['uuid', pd.Grouper(key='treatmentmonth', freq='1Y')]).size(), columns = ['n_month_inpatienthosp']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_month_outpatient['year'] = df_n_month_outpatient['treatmentmonth'].dt.year\n",
    "df_n_month_inpatient['year'] = df_n_month_inpatient['treatmentmonth'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_month_inpatient['year'] = df_grouped_month_inpatient['treatmentmonth'].dt.year\n",
    "df_grouped_month_outpatient['year'] = df_grouped_month_outpatient['treatmentmonth'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "Upon evaluating certain aspects, here are some conclusions:\n",
    "\n",
    "- The procedure to compute the N months hosp is correct\n",
    "- Most individuals have an equal annual number of months for outpatient and inpatient (risk of multicollinearity)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### Time to rehospitalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_to_rehosp_outpatient = (df_grouped_month_outpatient[df_grouped_month_outpatient.CODE_DRG.isnull()==False].groupby('uuid')['treatmentmonth'].diff().fillna(pd.Timedelta(seconds=0))\n",
    "                                   / pd.Timedelta(days=30)).astype(int)\n",
    "df_time_to_rehosp_inpatient = (df_grouped_month_inpatient[df_grouped_month_inpatient.CODE_DRG.isnull()==False].groupby('uuid')['treatmentmonth'].diff().fillna(pd.Timedelta(seconds=0))\n",
    "                                   / pd.Timedelta(days=30)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_month_outpatient['time_to_rehosp_out'] = df_time_to_rehosp_outpatient\n",
    "df_grouped_month_inpatient['time_to_rehosp_in'] = df_time_to_rehosp_inpatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_month_inpatient['year'] = df_grouped_month_inpatient['treatmentmonth'].dt.year\n",
    "df_grouped_month_outpatient['year'] = df_grouped_month_outpatient['treatmentmonth'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_to_rehosp_inpatient_final = df_grouped_month_inpatient[df_grouped_month_inpatient.time_to_rehosp_in > 0].dropna(subset = 'time_to_rehosp_in').drop(['treatmentmonth','CODE_DRG'], axis = 1).groupby(['uuid','year']).mean().reset_index()\n",
    "df_time_to_rehosp_outpatient_final = df_grouped_month_outpatient[df_grouped_month_outpatient.time_to_rehosp_out > 0].dropna(subset = 'time_to_rehosp_out').drop(['treatmentmonth','CODE_DRG'], axis = 1).groupby(['uuid','year']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_to_rehosp_inpatient_final[df_time_to_rehosp_inpatient_final.time_to_rehosp_in == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "## Concat hospilisations features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_hosp = pd.merge(df_grouped_year_inpatient, df_grouped_year_outpatient, on = ['uuid','year'], how = 'outer').fillna(0)\n",
    "df_outcomes_hosp = pd.merge(df_outcomes_hosp, df_n_month_outpatient[['uuid','year','n_month_outpatienthosp']], on = ['uuid','year'], how = 'outer').fillna(0)\n",
    "df_outcomes_hosp = pd.merge(df_outcomes_hosp, df_n_month_inpatient[['uuid','year','n_month_inpatienthosp']], on = ['uuid','year'], how = 'outer').fillna(0)\n",
    "df_outcomes_hosp = pd.merge(df_outcomes_hosp, df_time_to_rehosp_inpatient_final[['uuid','year','time_to_rehosp_in']], on = ['uuid','year'], how = 'outer')\n",
    "df_outcomes_hosp = pd.merge(df_outcomes_hosp, df_time_to_rehosp_outpatient_final[['uuid','year','time_to_rehosp_out']], on = ['uuid','year'], how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125",
   "metadata": {},
   "source": [
    "## (FIXED) Identify the CAM in the AOS\n",
    "\n",
    "**Strategy** : So...there are four types of CAM in the LAMal, homeopathy, MTC, phytotherapy and anthroposophic medicine. These have to be performed by certified doctors to be reimbursed. So, how do we go about this?\n",
    "\n",
    "1. Most of this must be in the from of prescriptions? -> Find prescriptions in these 4 but...we can't retrieve the doctor that prescribed since it agregated by sous_categorie dispensateur for the prestations.\n",
    "2. ATC codes related to CAM?\n",
    "3. \n",
    "\n",
    "### UPDATE : Data extracted based on DRGs corresponding to CAM in LAMAL sent by C. Bagnoud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "### LCA\n",
    "\n",
    "Create a dataset containing the outcomes relevant to the study by month and by year\n",
    "\n",
    "- Nombre de prestations LCA par an et par patient\n",
    "- Montant total de prestations LCA par an et par patient\n",
    "- Nombres de factures par an et par patient\n",
    "- Nb quantitÃ© par an et par patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "### Identify prestations that are clearly CAM and the ones that are quite ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "### Define a complementary medicine status\n",
    "\n",
    "Some claims are clearly complementary medicine as usually understood (a therapist with known practices, a code related to it, etc.) But there are also claimed billed by Doctors, Dentists, Fitness centers. These should be flagged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca['medcomp_status'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca.loc[~df_prestation_lca.CODES_THERAPIES.isnull(), 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.CATEGORIE_DISPENSATEUR == 'Pharmacies', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Medecine douce', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Medicament medecine douce', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Medecine douce medecins', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Acupuncture et homeopathie', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Osteopathie et etiopathie', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Sophrologie', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Soins balneaires', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Naturopathie', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Soins dietetiques', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Electroacupuncture', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == 'Medecines douces massage', 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == \"Soins balneaires a l'etranger\", 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == \"Soins chiropratiques\", 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == \"Soins orthoptiques\", 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == \"Prestations Yoga\", 'medcomp_status'] = 'Clear'\n",
    "df_prestation_lca.loc[df_prestation_lca.TXGENREFRAISLGFR == \"Soins podologiques\", 'medcomp_status'] = 'Clear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca[df_prestation_lca.medcomp_status != 'Clear'].TXGENREFRAISLGFR.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prestation_lca_by_patient_by_month = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT'], observed = True).size()\n",
    "sum_prestation_lca_by_patient_by_month = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT'], observed = True).PRESTATIONS_BRUTES.sum()\n",
    "n_bill_prestation_lca_by_patient_by_month = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT'], observed = True).NBRE_FACTURES.sum()\n",
    "n_quantity_prestation_lca_by_patient_by_month = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT'], observed = True).NBQUANTITE.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prestation_lca_by_patient_by_year = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT'], observed = True).size()\n",
    "sum_prestation_lca_by_patient_by_year = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT'], observed = True).PRESTATIONS_BRUTES.sum()\n",
    "n_bill_prestation_lca_by_patient_by_year = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT'], observed = True).NBRE_FACTURES.sum()\n",
    "n_quantity_prestation_lca_by_patient_by_year = df_prestation_lca[df_prestation_lca.medcomp_status == 'Clear'].groupby(['uuid','ANNEE_TRAITEMENT'], observed = True).NBQUANTITE.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prestation_lca_by_patient_by_year.sum()/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prestation_lca_by_patient_by_month = pd.DataFrame(sum_prestation_lca_by_patient_by_month)\n",
    "sum_prestation_lca_by_patient_by_month = sum_prestation_lca_by_patient_by_month.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_quantity_prestation_lca_by_patient_by_month = pd.DataFrame(n_quantity_prestation_lca_by_patient_by_month)\n",
    "n_quantity_prestation_lca_by_patient_by_month = n_quantity_prestation_lca_by_patient_by_month.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the cumulative sum within each year\n",
    "sum_prestation_lca_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] = sum_prestation_lca_by_patient_by_month.sort_values(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT']).groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].cumsum()\n",
    "month_reached_500_lca = sum_prestation_lca_by_patient_by_month[sum_prestation_lca_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 500].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()\n",
    "\n",
    "month_reached_1000_lca = sum_prestation_lca_by_patient_by_month[sum_prestation_lca_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 1000].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()\n",
    "month_reached_2500_lca = sum_prestation_lca_by_patient_by_month[sum_prestation_lca_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 2500].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()\n",
    "\n",
    "month_reached_5000_lca = sum_prestation_lca_by_patient_by_month[sum_prestation_lca_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 5000].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()\n",
    "month_reached_10000_lca = sum_prestation_lca_by_patient_by_month[sum_prestation_lca_by_patient_by_month['PRESTATIONS_BRUTES_CUMSUM'] >= 10000].groupby(['uuid','ANNEE_TRAITEMENT'])['MOIS_TRAITEMENT'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest month\n",
    "max_monthly_lca_cost = sum_prestation_lca_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly average\n",
    "mean_monthly_lca_cost = sum_prestation_lca_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].mean()\n",
    "# Frequency average\n",
    "\n",
    "mean_monthly_lca_freq = n_quantity_prestation_lca_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT']).size()/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean three last months\n",
    "last_3months_total_lca_cost = sum_prestation_lca_by_patient_by_month[sum_prestation_lca_by_patient_by_month.MOIS_TRAITEMENT.isin([10,11,12])].groupby(['uuid','ANNEE_TRAITEMENT'])['PRESTATIONS_BRUTES'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of months, weeks using LCA\n",
    "n_month_lca_by_patient = sum_prestation_lca_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prestation_lca_outcomes['treatmentdate'] = pd.to_datetime(df_prestation_lca_outcomes['ANNEE_TRAITEMENT'].astype('string') + '-' + df_prestation_lca_outcomes['MOIS_TRAITEMENT'].astype('string'))\n",
    "# df_prestation_lca_outcomes['treatmentmonth'] = df_prestation_lca_outcomes['treatmentdate'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "## Cleaning of LCA therapy types\n",
    "##### 1. Import the simplified ontology for LCA therapies previously created (details in Notebook Preparation GM - LCA ontology simplification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_therap_clean = pd.read_csv('../Data/processed/20230223_Therapies_ontology.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "Les donnÃ©es sur les codes ASCA sont disponibles [ici](http://asca.ch/therapies.aspx?all=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_therap_clean['Code'] = filtered_therap_clean['Code'].str.replace(' ','')\n",
    "filtered_therap_clean['Code'] = filtered_therap_clean['Code'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ontology_lca = filtered_therap_clean.set_index('Code')['therapie_lvl2'].to_dict()\n",
    "dict_ontology_lca_by_discipline = filtered_therap_clean.set_index('Code')['Methode'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca.CATEGORIE_DISPENSATEUR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca.TXGENREFRAISLGFR.value_counts(normalize = True).mul(100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca[df_prestation_lca.medcomp_status.isnull()].TXGENREFRAISLGFR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca = df_prestation_lca[['ID_DISPENSATEUR','CODES_THERAPIES','THERAPIES','TXGENREFRAISLGFR','CATEGORIE_DISPENSATEUR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca['CODES_THERAPIES'] = df_dispensateurs_lca['CODES_THERAPIES'].str.split(',')\n",
    "df_dispensateurs_lca['THERAPIES'] = df_dispensateurs_lca['THERAPIES'].str.split(',')\n",
    "\n",
    "def strip_if_list(item):\n",
    "    if isinstance(item, list):\n",
    "        return [str_elem.strip() for str_elem in item]\n",
    "    elif isinstance(item, str):\n",
    "        return item.strip()\n",
    "    return item\n",
    "\n",
    "# Apply the function to the DataFrame column\n",
    "df_dispensateurs_lca['CODES_THERAPIES'] = df_dispensateurs_lca['CODES_THERAPIES'].apply(strip_if_list)\n",
    "df_dispensateurs_lca['THERAPIES'] = df_dispensateurs_lca['THERAPIES'].apply(strip_if_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_ontology(x, dict_mapping):\n",
    "    try:\n",
    "        x = [i.strip() for i in x]\n",
    "        y = list(dict_mapping[i] if i in dict_mapping.keys() else i for i in x)\n",
    "        return y\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each row - \n",
    "## For each row, any string containing the substring APTN in CODES_THERAPIES is removed from CODES_THERAPIES\n",
    "## For each row, any string containing the subtring APTN in THERAPIES is added in CODES_THERAPIES\n",
    "def process_row(row):\n",
    "    if isinstance(row['CODES_THERAPIES'], list) and isinstance(row['THERAPIES'], list):\n",
    "        # Remove elements with 'APTN' from CODES_THERAPIES\n",
    "        row['CODES_THERAPIES'] = [code for code in row['CODES_THERAPIES'] if 'APTN' not in code]\n",
    "        \n",
    "        # Extract codes with 'APTN' from THERAPIES and add to CODES_THERAPIES\n",
    "        aptn_codes = [therapy for therapy in row['THERAPIES'] if 'APTN' in therapy]\n",
    "        row['CODES_THERAPIES'].extend(aptn_codes)\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function row-wise\n",
    "df_dispensateurs_lca = df_dispensateurs_lca.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca['THERAPIES_SIMPLIFIED'] = df_dispensateurs_lca.apply(lambda x : simplify_ontology(x['CODES_THERAPIES'], dict_ontology_lca), axis = 1)\n",
    "df_dispensateurs_lca['DISCIPLINES_SIMPLIFIED'] = df_dispensateurs_lca.apply(lambda x : simplify_ontology(x['CODES_THERAPIES'], dict_ontology_lca_by_discipline), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_codes_lca = df_dispensateurs_lca['CODES_THERAPIES'].explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dispensateurs_lca['THERAPIES'] = df_dispensateurs_lca['THERAPIES'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_therapies_lca = df_dispensateurs_lca[df_dispensateurs_lca.THERAPIES.isnull()==False]['THERAPIES'].explode().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_lca_manquants = []\n",
    "for code_lca in unique_codes_lca:\n",
    "    try:\n",
    "        print(dict_ontology_lca[code_lca.strip()])\n",
    "    except:\n",
    "        print('Code manquant', code_lca)\n",
    "        codes_lca_manquants.append(code_lca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(codes_lca_manquants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca_exploded = df_dispensateurs_lca.explode(['CODES_THERAPIES','THERAPIES_SIMPLIFIED','DISCIPLINES_SIMPLIFIED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP 50 most practiced therapy types \n",
    "df_dispensateurs_lca_exploded.groupby('THERAPIES_SIMPLIFIED').ID_DISPENSATEUR.nunique().sort_values().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the exploded dispensers DataFrame to a parquet file\n",
    "df_dispensateurs_lca_exploded.to_parquet(\n",
    "    data_folder/'processed'/'df_dispensateur_lca_exploded.parquet.gzip', compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to handle float inputs and convert non-floats into sets\n",
    "def set_or_nan(x):\n",
    "    if isinstance(x, float):\n",
    "        return float('nan')\n",
    "    else:\n",
    "        return set(x)\n",
    "\n",
    "# Apply the function to the 'THERAPIES_SIMPLIFIED' column\n",
    "df_dispensateurs_lca['THERAPIES_SIMPLIFIED_SET'] = df_dispensateurs_lca['THERAPIES_SIMPLIFIED'].apply(set_or_nan)\n",
    "df_dispensateurs_lca['DISCIPLINES_SIMPLIFIED_SET'] = df_dispensateurs_lca['DISCIPLINES_SIMPLIFIED'].apply(set_or_nan)\n",
    "\n",
    "# Group by 'ID_DISPENSATEUR', aggregate unique therapies for each dispenser\n",
    "df_dispensateurs_lca_nodupli_a = df_dispensateurs_lca.groupby('ID_DISPENSATEUR').agg({\n",
    "    'THERAPIES_SIMPLIFIED_SET': lambda x: set().union(*[y for y in x if isinstance(y, set)])\n",
    "})\n",
    "df_dispensateurs_lca_nodupli_b = df_dispensateurs_lca.groupby('ID_DISPENSATEUR').agg({\n",
    "    'DISCIPLINES_SIMPLIFIED_SET': lambda x: set().union(*[y for y in x if isinstance(y, set)])\n",
    "})\n",
    "\n",
    "df_dispensateurs_lca_nodupli = pd.merge(df_dispensateurs_lca_nodupli_a, df_dispensateurs_lca_nodupli_b, left_index = True, right_index = True)\n",
    "# Count the number of unique therapies for each dispenser\n",
    "df_dispensateurs_lca_nodupli['n_therapies'] = df_dispensateurs_lca_nodupli['THERAPIES_SIMPLIFIED_SET'].apply(len)\n",
    "df_dispensateurs_lca_nodupli['n_disciplines'] = df_dispensateurs_lca_nodupli['DISCIPLINES_SIMPLIFIED_SET'].apply(len)\n",
    "\n",
    "# Reset the DataFrame index\n",
    "df_dispensateurs_lca_nodupli = df_dispensateurs_lca_nodupli.reset_index()\n",
    "\n",
    "# Explode the 'THERAPIES_SIMPLIFIED_SET' column into multiple rows, duplicating the values of the other columns\n",
    "df_dispensateurs_lca_nodupli_exploded = df_dispensateurs_lca_nodupli.explode('THERAPIES_SIMPLIFIED_SET')\n",
    "\n",
    "# Create a dummy column for pivoting purposes\n",
    "df_dispensateurs_lca_nodupli_exploded['dummy'] = 1\n",
    "\n",
    "# Pivot the DataFrame to get a one-hot encoded matrix for the therapies, replacing NaNs with 0\n",
    "df_dispensateurs_lca_nodupli_pivot = df_dispensateurs_lca_nodupli_exploded.explode('THERAPIES_SIMPLIFIED_SET').pivot(\n",
    "    index='ID_DISPENSATEUR', columns='THERAPIES_SIMPLIFIED_SET', values='dummy'\n",
    ").fillna(0)\n",
    "\n",
    "# Sort dispensers by the number of therapies they offer\n",
    "df_dispensateurs_lca_nodupli.sort_values('n_therapies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca_nodupli.groupby('n_disciplines').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca_nodupli[df_dispensateurs_lca_nodupli.n_disciplines ==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1_thera_disp = df_dispensateurs_lca_nodupli[df_dispensateurs_lca_nodupli.n_therapies == 1].ID_DISPENSATEUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca_nodupli.groupby('n_disciplines').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dispensateurs_lca_nodupli[df_dispensateurs_lca_nodupli.n_disciplines == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the exploded dispensers DataFrame to a parquet file\n",
    "df_dispensateurs_lca_nodupli.to_parquet(\n",
    "    data_folder/'processed'/'df_dispensateurs_lca_nodupli.parquet.gzip', compression='gzip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_souscat_disp.parquet.gzip'):\n",
    "\n",
    "#     df_amount_by_souscat_disp = pd.DataFrame(df_prestation_aos.groupby(['uuid','ANNEE_TRAITEMENT','SOUS_CATEGORIE_DISPENSATEUR']).PRESTATIONS_BRUTES.sum()).reset_index()\n",
    "#     df_amount_by_souscat_disp = df_amount_by_souscat_disp.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'SOUS_CATEGORIE_DISPENSATEUR', values = 'PRESTATIONS_BRUTES').reset_index()\n",
    "#     df_amount_by_souscat_disp.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_souscat_disp.parquet.gzip', compression = 'gzip')\n",
    "# else:\n",
    "#     df_amount_by_souscat_disp = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_souscat_disp.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174",
   "metadata": {},
   "source": [
    "#### After cleaning, filtering and removing duplicates in the THERAPIES, we add the column to prestation_lca. \n",
    "\n",
    "**TO DO** : \n",
    "\n",
    "- There is a big chance that some therapists have changing CODES and THERAPIES over years, this is not taken into account atm. Something that could be done in the future.\n",
    "- Check if there is a way to disentangle which bill is associated to which THERAPY based on the amount. To know which price is associated to which therapy, we can use the therapists having only one specialty.\n",
    "    - We don't have the number of sessions that were agregated in the monthly agregation -> we have amounts that go up to > 3000CHF ! We thus have another step to find the \"unique\" sessions and their price. We can then find the number of sessions agregated. Cool cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging df_prestation_lca with df_dispensateurs_lca_nodupli on 'ID_DISPENSATEUR'\n",
    "# keeping only the relevant columns ('ID_DISPENSATEUR', 'THERAPIES_SIMPLIFIED_SET', 'n_therapies') from the latter.\n",
    "# 'how = left' ensures all rows from df_prestation_lca are retained and filled with NaN for missing matches.\n",
    "df_prestation_lca = pd.merge(df_prestation_lca, \n",
    "                             df_dispensateurs_lca_nodupli[['ID_DISPENSATEUR','THERAPIES_SIMPLIFIED_SET','n_therapies','DISCIPLINES_SIMPLIFIED_SET','n_disciplines']], \n",
    "                             on = 'ID_DISPENSATEUR', \n",
    "                             how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df_prestation_lca.CATEGORIE_DISPENSATEUR == 'Pharmacies', {'Methodes prescriptives'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Medicament medecine douce', {'Methodes prescriptives'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Acupuncture et homeopathie', {'Methodes orientales','Methodes prescriptives'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Osteopathie et etiopathie', {'Methodes energetiques manuelles'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Sophrologie', {'Methodes psychologiques complementaires'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Soins balneaires', {'Methodes hydrotherapeutiques'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Naturopathie', {'Methodes orientales'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Soins dietetiques', {'Methodes prescriptives'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Electroacupuncture', {'Methodes orientales'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Medecines douces massage', {'Methodes de massage'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == \"Soins balneaires a l'etranger\", {'Methodes psychologiques complementaires'}),\n",
    "    (df_prestation_lca.TXGENREFRAISLGFR == 'Soins chiropratiques', {'Methodes energetiques manuelles'})\n",
    "]\n",
    "\n",
    "for condition, value_set in conditions:\n",
    "    df_prestation_lca.loc[condition, 'DISCIPLINES_SIMPLIFIED_SET'] = df_prestation_lca.loc[condition, 'DISCIPLINES_SIMPLIFIED_SET'].apply(lambda x: value_set if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca['n_disciplines'] = df_prestation_lca['DISCIPLINES_SIMPLIFIED_SET'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of prestations done by therapists with 1, 2, and less than 5 specialties respectively\n",
    "pct_single_specialty = (df_prestation_lca[df_prestation_lca.n_therapies == 1].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "pct_two_specialties = (df_prestation_lca[df_prestation_lca.n_therapies <= 2].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "pct_less_five_specialties = (df_prestation_lca[df_prestation_lca.n_therapies < 5].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "\n",
    "# Use formatted string literals (f-strings) for more readable print statements\n",
    "print(f'About {pct_single_specialty:.1f}% of LCA prestations are done by a therapist having 1 specialty')\n",
    "print(f'About {pct_two_specialties:.1f}% of LCA prestations are done by a therapist having 1 or 2 specialties')\n",
    "print(f'About {pct_less_five_specialties:.1f}% of LCA prestations are done by a therapist having less than 5 specialties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of prestations done by therapists with 1, 2, and less than 5 specialties respectively\n",
    "pct_zero_discipline = (df_prestation_lca[df_prestation_lca.n_disciplines == 0].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "pct_single_discipline = (df_prestation_lca[df_prestation_lca.n_disciplines == 1].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "pct_two_disciplines = (df_prestation_lca[df_prestation_lca.n_disciplines <= 2].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "pct_less_five_disciplines = (df_prestation_lca[df_prestation_lca.n_disciplines < 5].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "pct_less_ten_disciplines = (df_prestation_lca[df_prestation_lca.n_disciplines < 10].shape[0] / df_prestation_lca.shape[0]) * 100\n",
    "\n",
    "# Use formatted string literals (f-strings) for more readable print statements\n",
    "print(f'About {pct_zero_discipline:.1f}% of LCA prestations are done by a therapist without a discipline')\n",
    "print(f'About {pct_single_discipline:.1f}% of LCA prestations are done by a therapist having 1 discipline')\n",
    "print(f'About {pct_two_disciplines:.1f}% of LCA prestations are done by a therapist having 1 or 2 disciplines')\n",
    "print(f'About {pct_less_five_disciplines:.1f}% of LCA prestations are done by a therapist having less than 5 disciplines')\n",
    "print(f'About {pct_less_ten_disciplines:.1f}% of LCA prestations are done by a therapist having less than 10 disciplines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca.groupby('n_disciplines').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181",
   "metadata": {},
   "source": [
    "That means that we have a big third that is fine, another big third that is potentially manageable...the rest...will be quite hard to manage !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca[df_prestation_lca.n_therapies > 2].uuid.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183",
   "metadata": {},
   "source": [
    "#### Number by type of therapy code LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_n_by_lca_therapy.parquet.gzip'):\n",
    "    df_n_by_lca_therapy = df_prestation_lca.explode('THERAPIES_SIMPLIFIED_SET')\n",
    "    df_n_by_lca_therapy = pd.DataFrame(df_n_by_lca_therapy.groupby(['uuid','ANNEE_TRAITEMENT','THERAPIES_SIMPLIFIED_SET']).size()).reset_index()\n",
    "    df_n_by_lca_therapy = df_n_by_lca_therapy.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'THERAPIES_SIMPLIFIED_SET', values = 0).reset_index()\n",
    "    df_n_by_lca_therapy.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_n_by_lca_therapy.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_n_by_lca_therapy = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_n_by_lca_therapy.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_lca_therapy.parquet.gzip'):\n",
    "    df_amount_by_lca_therapy = df_prestation_lca.explode('THERAPIES_SIMPLIFIED_SET')\n",
    "    df_amount_by_lca_therapy = pd.DataFrame(df_amount_by_lca_therapy.groupby(['uuid','ANNEE_TRAITEMENT','THERAPIES_SIMPLIFIED_SET']).PRESTATIONS_BRUTES.sum()).reset_index()\n",
    "    df_amount_by_lca_therapy = df_amount_by_lca_therapy.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'THERAPIES_SIMPLIFIED_SET', values = 'PRESTATIONS_BRUTES').reset_index()\n",
    "    df_amount_by_lca_therapy.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_lca_therapy.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_amount_by_lca_therapy = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_lca_therapy.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186",
   "metadata": {},
   "source": [
    "#### Number and amount by LCA discipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_n_by_lca_discipline.parquet.gzip'):\n",
    "    df_n_by_lca_discipline = df_prestation_lca.explode('DISCIPLINES_SIMPLIFIED_SET')\n",
    "    df_n_by_lca_discipline = pd.DataFrame(df_n_by_lca_discipline.groupby(['uuid','ANNEE_TRAITEMENT','DISCIPLINES_SIMPLIFIED_SET']).size()).reset_index()\n",
    "    df_n_by_lca_discipline = df_n_by_lca_discipline.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'DISCIPLINES_SIMPLIFIED_SET', values = 0).reset_index()\n",
    "    df_n_by_lca_discipline.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_n_by_lca_discipline.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_n_by_lca_discipline = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_n_by_lca_discipline.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_lca_discipline.parquet.gzip'):\n",
    "    df_amount_by_lca_discipline = df_prestation_lca.explode('DISCIPLINES_SIMPLIFIED_SET')\n",
    "    df_amount_by_lca_discipline = pd.DataFrame(df_amount_by_lca_discipline.groupby(['uuid','ANNEE_TRAITEMENT','DISCIPLINES_SIMPLIFIED_SET']).PRESTATIONS_BRUTES.sum()).reset_index()\n",
    "    df_amount_by_lca_discipline = df_amount_by_lca_discipline.pivot(index = ['uuid','ANNEE_TRAITEMENT'], columns = 'DISCIPLINES_SIMPLIFIED_SET', values = 'PRESTATIONS_BRUTES').reset_index()\n",
    "    df_amount_by_lca_discipline.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_lca_discipline.parquet.gzip', compression = 'gzip')\n",
    "else:\n",
    "    df_amount_by_lca_discipline = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_lca_discipline.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dispensateur_lca = df_prestation_lca.groupby(['uuid','ANNEE_TRAITEMENT']).ID_DISPENSATEUR.apply(set).apply(lambda x: len(x) if isinstance(x, set) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190",
   "metadata": {},
   "source": [
    "## Final LCA features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_outcomes_by_year = pd.concat([n_prestation_lca_by_patient_by_year, sum_prestation_lca_by_patient_by_year, n_bill_prestation_lca_by_patient_by_year, n_quantity_prestation_lca_by_patient_by_year,month_reached_500_lca, month_reached_1000_lca, month_reached_2500_lca, month_reached_5000_lca, month_reached_10000_lca, max_monthly_lca_cost, mean_monthly_lca_cost, mean_monthly_lca_freq, last_3months_total_lca_cost, n_month_lca_by_patient, n_dispensateur_lca], axis = 1).reset_index().rename(columns = {0:'NBROWS'})\n",
    "# df_prestation_lca_outcomes_by_year = df_prestation_lca_outcomes.groupby(['uuid','ANNEE_TRAITEMENT'], observed = True)[['NBROWS','PRESTATIONS_BRUTES','NBRE_FACTURES','NBQUANTITE']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_outcomes_by_year.columns = ['uuid', 'ANNEE_TRAITEMENT', 'NBROWS', 'PRESTATIONS_BRUTES',\n",
    "       'NBRE_FACTURES', 'NBQUANTITE','month_reached_500_lca','month_reached_1000_lca','month_reached_2500_lca','month_reached_5000_lca','month_reached_10000_lca','max_monthly_lca','mean_monthly_lca','mean_monthly_nbquantite_lca','last3month_lca','n_month_lca_by_patient', 'n_dispensateur_lca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_outcomes_by_year = pd.merge(df_prestation_lca_outcomes_by_year, df_n_by_lca_discipline.fillna(0), on = ['uuid','ANNEE_TRAITEMENT'], how = 'outer').merge(df_amount_by_lca_discipline.fillna(0), on = ['uuid','ANNEE_TRAITEMENT'], how = 'outer', suffixes = ('_n','_amount'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_outcomes_by_year.PRESTATIONS_BRUTES.sum()/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195",
   "metadata": {},
   "source": [
    "Still all good at this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "del n_prestation_lca_by_patient_by_year, n_quantity_prestation_lca_by_patient_by_year, df_n_by_lca_discipline, df_amount_by_lca_discipline, month_reached_500_lca, month_reached_1000_lca, month_reached_2500_lca, month_reached_5000_lca, month_reached_10000_lca, max_monthly_lca_cost, mean_monthly_lca_cost, mean_monthly_lca_freq, last_3months_total_lca_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197",
   "metadata": {},
   "source": [
    "## Save dataset of prestations LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca.to_parquet(data_folder/'processed'/'df_prestation_lca_processed.parquet_gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199",
   "metadata": {},
   "source": [
    "### Creating a DataFrame of Therapy-Price Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting the dispensateurs having only 1 THERAPY type\n",
    "df_prestation_lca_1spe = df_prestation_lca[df_prestation_lca.n_therapies == 1].explode('THERAPIES_SIMPLIFIED_SET')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201",
   "metadata": {},
   "source": [
    "##### Check the most expensive therapies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_1spe[['ID_LCA','MOIS_TRAITEMENT','ANNEE_TRAITEMENT','CODES_THERAPIES','TXGENREFRAISLGFR','PRESTATIONS_BRUTES','NBRE_FACTURES','NBQUANTITE','THERAPIES_SIMPLIFIED_SET']].sort_values(['PRESTATIONS_BRUTES']).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,30))\n",
    "sns.barplot(data=df_prestation_lca_1spe, x=\"PRESTATIONS_BRUTES\",y = 'THERAPIES_SIMPLIFIED_SET',dodge=False, hue=\"THERAPIES_SIMPLIFIED_SET\", ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204",
   "metadata": {},
   "source": [
    "We note that actually, this way, we don't find the most expensive therapies but the highest monthly total amounts. We need to filter out all the amounts that are obviously the result of the monthly agregation of multiple therapy sessions. Then, we may be able to find a price per type of therapy.\n",
    "\n",
    "Let's select only the `prestations` which an amount < 200CHF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_1spe_1session = df_prestation_lca_1spe[df_prestation_lca_1spe.PRESTATIONS_BRUTES < 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_labels = df_prestation_lca_1spe_1session.groupby('THERAPIES_SIMPLIFIED_SET')['PRESTATIONS_BRUTES'].median().sort_values().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,15))\n",
    "# Plot the orbital period with horizontal boxes\n",
    "sns.boxplot(data=df_prestation_lca_1spe_1session, x=\"PRESTATIONS_BRUTES\",y = 'THERAPIES_SIMPLIFIED_SET', order = ordered_labels, width=.6, palette=\"vlag\", ax = ax)\n",
    "plt.savefig(result_folder/\"EDA\"/'Therapy-Price pairs'/'Box plot - Montants par type de thÃ©rapie.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208",
   "metadata": {},
   "source": [
    "#### Filtering out everything that is not a session (taxes and medicines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_1spe_1session_notax = df_prestation_lca_1spe_1session[~df_prestation_lca_1spe_1session.TXGENREFRAISLGFR.isin(['Medicaments hors liste','Medicament medecine douce','Taxe pour livraison'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_labels = df_prestation_lca_1spe_1session_notax.groupby('THERAPIES_SIMPLIFIED_SET')['PRESTATIONS_BRUTES'].median().sort_values().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,15))\n",
    "# Plot the orbital period with horizontal boxes\n",
    "sns.boxplot(data=df_prestation_lca_1spe_1session_notax, x=\"PRESTATIONS_BRUTES\",y = 'THERAPIES_SIMPLIFIED_SET', order = ordered_labels, width=.6, palette=\"vlag\", ax = ax)\n",
    "plt.savefig(result_folder/\"EDA\"/'Therapy-Price pairs'/'Box plot - Montants par type de thÃ©rapie - Taxes et mÃ©dicaments exclus.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ostheo = df_prestation_lca_1spe_1session_notax[df_prestation_lca_1spe_1session_notax['THERAPIES_SIMPLIFIED_SET'] == 'Osteopathie']\n",
    "df_massage = df_prestation_lca_1spe_1session_notax[df_prestation_lca_1spe_1session_notax['THERAPIES_SIMPLIFIED_SET'] == 'Massage classique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data = df_ostheo, x = 'PRESTATIONS_BRUTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(data = df_massage[df_massage.ID_LCA.isin(df_massage['ID_LCA'].sample(1))], x = 'PRESTATIONS_BRUTES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215",
   "metadata": {},
   "source": [
    "With a global approach like this, we see that it will be very hard to create a therapy:price dataframe. Prices may vary by region, by therapist and over the study period. Probably a better strategy is to check the different prices that each therapist has practiced over the 5 years. If there are a lot, maybe we can have something like this:\n",
    "\n",
    "|ID| YEAR |THERAPY|PRICE|\n",
    "|---|---|---|---|\n",
    "|123432| 2020| Massage|96|\n",
    "|123432| 2021| Massage|102|\n",
    "|123433| 2021| Osteopathy|120|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_1spe_1session_notax['PRESTATIONS_BRUTES_rounded'] = df_prestation_lca_1spe_1session_notax['PRESTATIONS_BRUTES'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_prestation_lca_1spe_1session_notax.groupby(['ID_DISPENSATEUR','ANNEE_TRAITEMENT','THERAPIES_SIMPLIFIED_SET'])['PRESTATIONS_BRUTES_rounded'].unique()).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218",
   "metadata": {},
   "source": [
    "**Conclusions** : This is way messier than we could have hoped for...It will be almost impossible to infer what therapy has been used during a session for any session done at a therapist having more than 2 specialties. Even then, it may be challenging since the prices are all over the place !\n",
    "\n",
    "**TO DO**: Cry ... although ... It seems that the pricing is actually quite uniform ! This should be revisited. For example, the price of a visit at the osteo is normally 120 CHF. There is apparently a standardized tarification that is explained here : https://terap.ch/fr/blog/tarif-590 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219",
   "metadata": {},
   "source": [
    "### Check if prices vary by canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_lca_1spe_1session_notax = pd.merge(df_prestation_lca_1spe_1session_notax, df_couverture_aos[['uuid','CDCANTON_POST']].drop_duplicates(subset='uuid'), on = ['uuid'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ostheo = df_prestation_lca_1spe_1session_notax[df_prestation_lca_1spe_1session_notax['THERAPIES_SIMPLIFIED_SET'] == 'Osteopathie']\n",
    "df_massage = df_prestation_lca_1spe_1session_notax[df_prestation_lca_1spe_1session_notax['THERAPIES_SIMPLIFIED_SET'] == 'Massage classique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_labels = df_ostheo.groupby('CDCANTON_POST')['PRESTATIONS_BRUTES'].median().sort_values().index\n",
    "fig, ax = plt.subplots(figsize = (6,10))\n",
    "\n",
    "sns.boxplot(data = df_ostheo, x = 'PRESTATIONS_BRUTES',order = ordered_labels,y = 'CDCANTON_POST', width=.6, palette=\"vlag\", ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ostheo[df_ostheo.CDCANTON_POST == 'VS']['PRESTATIONS_BRUTES'].plot.hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_labels = df_ostheo.groupby('CDCANTON_POST')['PRESTATIONS_BRUTES'].median().sort_values().index\n",
    "fig, ax = plt.subplots(figsize = (6,10))\n",
    "\n",
    "sns.boxplot(data = df_massage, x = 'PRESTATIONS_BRUTES',order = ordered_labels,y = 'CDCANTON_POST', width=.6, palette=\"vlag\", ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225",
   "metadata": {},
   "source": [
    "### Combine LCA and AOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for clarity\n",
    "df_prestation_lca_outcomes_by_year = df_prestation_lca_outcomes_by_year.rename(columns = {\n",
    "    'NBROWS': \"NBROWS_LCA\",\n",
    "    'PRESTATIONS_BRUTES': \"PRESTATIONS_BRUTES_LCA\",\n",
    "    'NBRE_FACTURES': \"NBRE_FACTURES_LCA\",\n",
    "    'NBQUANTITE': \"NBQUANTITE_LCA\"})\n",
    "\n",
    "df_prestation_aos_outcomes_by_year = df_prestation_aos_outcomes_by_year.rename(columns = {\n",
    "    'NBROWS': \"NBROWS_AOS\",\n",
    "    'PRESTATIONS_BRUTES': \"PRESTATIONS_BRUTES_AOS\",\n",
    "    \"PRESTATIONS_NETTES\": \"PRESTATIONS_NETTES_AOS\",\n",
    "    'NBRE_FACTURES': \"NBRE_FACTURES_AOS\",\n",
    "    'NBQUANTITE': \"NBQUANTITE_AOS\"})\n",
    "\n",
    "# Combining the two dataframes by setting 'uuid' and 'ANNEE_TRAITEMENT' as index and concatenating along columns\n",
    "df_outcomes_prestation = pd.concat(\n",
    "    [df_prestation_lca_outcomes_by_year.set_index(['uuid','ANNEE_TRAITEMENT']), \n",
    "     df_prestation_aos_outcomes_by_year.set_index(['uuid','ANNEE_TRAITEMENT'])], \n",
    "    axis = 1).reset_index()\n",
    "\n",
    "# Filling NaN values with 0.0\n",
    "# Get columns that don't contain 'month_'\n",
    "cols_to_fill = df_outcomes_prestation.filter(regex='^(?!.*month_).*$').columns\n",
    "\n",
    "# Fill NaN values in these columns\n",
    "df_outcomes_prestation[cols_to_fill] = df_outcomes_prestation[cols_to_fill].fillna(0.0)\n",
    "\n",
    "# Creating new columns for total prestations and total number of invoices\n",
    "df_outcomes_prestation['PRESTATIONS_TOTAL'] = df_outcomes_prestation[['PRESTATIONS_BRUTES_AOS', 'PRESTATIONS_BRUTES_LCA']].sum(axis = 1)\n",
    "df_outcomes_prestation['NBRE_FACTURES_TOTAL'] = df_outcomes_prestation[['NBRE_FACTURES_AOS', 'NBRE_FACTURES_LCA']].sum(axis = 1)\n",
    "\n",
    "# Merging with df_gps_exploded_excl_gp on ['ANNEE_TRAITEMENT','uuid'] and [\"NOANNEE\", \"uuid\"] respectively\n",
    "df_outcomes_prestation = df_outcomes_prestation.merge(\n",
    "    df_gps_exploded_excl_gp, \n",
    "    left_on=['ANNEE_TRAITEMENT','uuid'], \n",
    "    right_on=[\"NOANNEE\", \"uuid\"], \n",
    "    how=\"left\")\n",
    "\n",
    "# Mapping the 'gp' column using dict_labels_gps\n",
    "df_outcomes_prestation['gp'] = df_outcomes_prestation['gp'].map(dict_labels_gps)\n",
    "\n",
    "# Filtering out rows where 'gp' contains 'No usage'\n",
    "df_outcomes_prestation = df_outcomes_prestation[~df_outcomes_prestation.gp.str.contains('No usage', na = False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation.gp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation[df_outcomes_prestation.gp.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation.PRESTATIONS_BRUTES_LCA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation.PRESTATIONS_BRUTES_AOS.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231",
   "metadata": {},
   "source": [
    "**Still all good for the total sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation.groupby('gp', observed = True).PRESTATIONS_TOTAL.mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'df_outcomes_prestation' with 'df_amount_by_souscat_disp' on keys ['uuid','ANNEE_TRAITEMENT']\n",
    "# Fill NaN values with 0 after the merge\n",
    "df_outcomes_prestation_temp = pd.merge(\n",
    "    df_outcomes_prestation, \n",
    "    df_amount_by_souscat_disp, \n",
    "    on=['uuid','ANNEE_TRAITEMENT'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge the above merged dataframe with 'df_amount_by_type_prestation' on keys ['uuid','ANNEE_TRAITEMENT']\n",
    "# Fill NaN values with 0 after the merge\n",
    "df_outcomes_prestation_temp = pd.merge(\n",
    "    df_outcomes_prestation_temp, \n",
    "    df_amount_by_type_prestation.fillna(0), \n",
    "    on=['uuid','ANNEE_TRAITEMENT'], \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Merge the above merged dataframe with 'df_amount_by_sinistre' on keys ['uuid','ANNEE_TRAITEMENT']\n",
    "# Fill NaN values with 0 after the merge\n",
    "df_outcomes_prestation_temp = pd.merge(\n",
    "    df_outcomes_prestation_temp, \n",
    "    df_amount_by_sinistre.fillna(0), \n",
    "    on=['uuid','ANNEE_TRAITEMENT'], \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Merge the above merged dataframe with 'df_outcomes_hosp' on keys ['uuid','ANNEE_TRAITEMENT'] and ['uuid','year'] respectively\n",
    "# Fill NaN values with 0 after the merge\n",
    "df_outcomes_prestation_temp = pd.merge(\n",
    "    df_outcomes_prestation_temp, \n",
    "    df_outcomes_hosp,\n",
    "    left_on=['uuid','ANNEE_TRAITEMENT'], \n",
    "    right_on=['uuid','year'], \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Merge the above merged dataframe with 'df_n_by_lca_therapy' on keys ['uuid','ANNEE_TRAITEMENT'] and ['uuid','year'] respectively\n",
    "# Fill NaN values with 0 after the merge\n",
    "df_outcomes_prestation_temp = pd.merge(\n",
    "    df_outcomes_prestation_temp, \n",
    "    df_n_by_lca_therapy.fillna(0),\n",
    "    left_on=['uuid','ANNEE_TRAITEMENT'], \n",
    "    right_on=['uuid','ANNEE_TRAITEMENT'], \n",
    "    how='outer'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns 'A', 'B' and 'M' to 'PRESTATIONS_ACCIDENT', 'PRESTATIONS_BIRTH' and 'PRESTATIONS_DISEASE'\n",
    "# This is done for clarity and ease of understanding during subsequent analysis\n",
    "df_outcomes_prestation_temp = df_outcomes_prestation_temp.rename(\n",
    "    columns={\n",
    "        'A':'PRESTATIONS_ACCIDENT',\n",
    "        'B':'PRESTATIONS_BIRTH', \n",
    "        'M':'PRESTATIONS_DISEASE'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation_temp['PRESTATIONS_BRUTES_AOS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation_temp['PRESTATIONS_BRUTES_LCA'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237",
   "metadata": {},
   "source": [
    "## Prescription data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238",
   "metadata": {},
   "source": [
    "### Total number of prescriptions, total amount by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_and_amount_prescriptions_by_year = optimize_memory_df(df_drug_aos.groupby(['uuid','ANNEE_TRAITEMENT'], observed = True).agg({'NBQUANTITE': 'count', 'PRESTATIONS_BRUTES': 'sum'}).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240",
   "metadata": {},
   "source": [
    "### Total number of prescriptions, total amount by year and sous_categorie_dispensateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_and_amount_year_dispensateur = optimize_memory_df(df_drug_aos.groupby(['uuid','ANNEE_TRAITEMENT','SOUS_CATEGORIE_DISPENSATEUR'], observed = True).agg({'NBQUANTITE': 'count', 'PRESTATIONS_BRUTES': 'sum'}).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_year_dispensateur_onehot = nb_and_amount_year_dispensateur.pivot(columns = 'SOUS_CATEGORIE_DISPENSATEUR', index = ['uuid','ANNEE_TRAITEMENT'], values = 'NBQUANTITE').astype('category').reset_index()\n",
    "amount_year_dispensateur_onehot = nb_and_amount_year_dispensateur.pivot(columns = 'SOUS_CATEGORIE_DISPENSATEUR', index = ['uuid','ANNEE_TRAITEMENT'], values = 'PRESTATIONS_BRUTES').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all columns in the DataFrame\n",
    "for column_name in nb_year_dispensateur_onehot.columns:\n",
    "    # Check if the column is of Categorical data type\n",
    "    if pd.api.types.is_categorical_dtype(nb_year_dispensateur_onehot[column_name]):\n",
    "        # Get current categories\n",
    "        current_categories = nb_year_dispensateur_onehot[column_name].cat.categories\n",
    "        \n",
    "        # Add the new category (0) to the list of categories, if not already present\n",
    "        updated_categories = current_categories.tolist()\n",
    "        if 0 not in updated_categories:\n",
    "            updated_categories.append(0)\n",
    "\n",
    "        # Update the categories of the Categorical column\n",
    "        nb_year_dispensateur_onehot[column_name] = nb_year_dispensateur_onehot[column_name].cat.set_categories(updated_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_year_dispensateur_onehot = nb_year_dispensateur_onehot.fillna(0)\n",
    "amount_year_dispensateur_onehot = amount_year_dispensateur_onehot.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245",
   "metadata": {},
   "source": [
    "### ATCs by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246",
   "metadata": {},
   "outputs": [],
   "source": [
    "netamount_patient = df_drug_aos.groupby(['uuid','ANNEE_TRAITEMENT','ATC3'], observed = True)['PRESTATIONS_BRUTES'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_amount_by_atc = pd.DataFrame(df_drug_aos.groupby(['uuid','ANNEE_TRAITEMENT','ATC3']).PRESTATIONS_BRUTES.sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Convert the pandas DataFrame to a Dask DataFrame\n",
    "# Since we can't pivot a Dask dataframe using multiple columns...we use a little trick to get a single column combining year and uuid\n",
    "if not os.path.isfile(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_atc.parquet.gzip'):\n",
    "\n",
    "    df_drug_aos['year_uuid'] = df_drug_aos['ANNEE_TRAITEMENT'].astype(str)+'_'+ df_drug_aos['uuid'].astype(str)\n",
    "    ddf_drug_aos = dd.from_pandas(df_drug_aos, npartitions=3)\n",
    "    ddf_drug_aos = ddf_drug_aos.categorize(columns=['ATC3','year_uuid'])\n",
    "\n",
    "    df_amount_by_atc = ddf_drug_aos.pivot_table(index='year_uuid',\n",
    "                                                columns='ATC3',\n",
    "                                                values='PRESTATIONS_BRUTES',\n",
    "                                                aggfunc='sum').reset_index()\n",
    "\n",
    "    df_amount_by_atc = df_amount_by_atc.compute()\n",
    "\n",
    "    df_amount_by_atc[['ANNEE_TRAITEMENT','uuid']] = df_amount_by_atc.year_uuid.str.split(\"_\", n=1, expand=True)\n",
    "    df_amount_by_atc.to_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_atc.parquet.gzip', compression = 'gzip')\n",
    "\n",
    "else:\n",
    "    df_amount_by_atc = pd.read_parquet(data_folder/'processed'/'Intermediate datasets'/'df_amount_by_atc.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249",
   "metadata": {},
   "outputs": [],
   "source": [
    "netamount_patient = df_drug_aos.groupby(['uuid','ANNEE_TRAITEMENT'], observed = True)['PRESTATIONS_BRUTES'].sum()\n",
    "patient_drugs = df_drug_aos[['uuid','ATC3','ANNEE_TRAITEMENT']].drop_duplicates()\n",
    "X = pd.get_dummies(patient_drugs['ATC3'])\n",
    "patient_drugs = pd.concat([patient_drugs.drop('ATC3', axis = 1), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = patient_drugs.groupby(['uuid','ANNEE_TRAITEMENT'], observed = True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs['PRESTATIONS_BRUTES'] = netamount_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = patient_drugs.reset_index()\n",
    "patient_drugs['n_atc'] = patient_drugs.drop(['uuid','PRESTATIONS_BRUTES','ANNEE_TRAITEMENT'],axis = 1).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = pd.merge(patient_drugs, amount_year_dispensateur_onehot, on = ['uuid','ANNEE_TRAITEMENT'], how = 'left')\n",
    "patient_drugs = pd.merge(patient_drugs, nb_year_dispensateur_onehot, on = ['uuid','ANNEE_TRAITEMENT'], how = 'left', suffixes = ('','_amount') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in patient_drugs.columns:\n",
    "    # Check if the column is of Categorical data type\n",
    "    if pd.api.types.is_categorical_dtype(patient_drugs[column_name]):\n",
    "        patient_drugs[column_name] = patient_drugs[column_name].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = patient_drugs.groupby(['uuid','ANNEE_TRAITEMENT']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = pd.merge(patient_drugs, df_amount_by_atc, on = ['uuid','ANNEE_TRAITEMENT'], how = 'left', suffixes=['_ATC_N','_ATC_AMOUNT']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_amount_by_atc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259",
   "metadata": {},
   "source": [
    "### Quality checks before final concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs.uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation_temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_uuid_years_combi.uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation_temp.uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs_light = patient_drugs[['uuid','ANNEE_TRAITEMENT','n_atc','PRESTATIONS_BRUTES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs_light.columns = ['uuid','ANNEE_TRAITEMENT','n_atc','PRESTATIONS_BRUTES_ATC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = patient_drugs.rename(columns={'PRESTATIONS_BRUTES':'PRESTATIONS_BRUTES_ATC'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268",
   "metadata": {},
   "source": [
    "## Combine Prestations & Prescriptions data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269",
   "metadata": {},
   "source": [
    "The basis of the dataset should be fully exhaustive, i.e. containing all possible combinations of uuid-YEAR for the years 2017 to 2021. Some people have no prescription, others no prestation within a year, that's usual...but we also have some people that were not insured for both insurance for certain years. These have been flagged thanks to the `group definition` step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "ids = pd.concat([df_couverture_aos.uuid, df_couverture_lca.uuid]).drop_duplicates()\n",
    "years = [2017,2018,2019,2020,2021]\n",
    "id_years = list(itertools.product(ids, years))\n",
    "df_all_uuid_years_combi = pd.DataFrame(id_years, columns=['uuid', 'NOANNEE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi = df_all_uuid_years_combi.merge(df_gps_exploded_excl_gp, on=[\"NOANNEE\", \"uuid\"], how=\"left\")\n",
    "df_all_uuid_years_combi['gp'] = df_all_uuid_years_combi['gp'].map(dict_labels_gps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272",
   "metadata": {},
   "source": [
    "#### We see that we have ~104,000 uuid-NOANNEE combinations that don't have a group. We will have to solve this at some point. Probably something associated with some combinations not being present even in the df_couverture df. \n",
    "\n",
    "One example `74bc0983-8527-444a-8dbe-e267e5530772`:\n",
    "- Used LCA in 2017\n",
    "- 2018, 2019 : No use of his/her LCA, not insured AOS\n",
    "- 2020, 2021 : No insurance AT ALL\n",
    "\n",
    "By elimination, we can define that rows with gp = NaN are the ones with no insurance that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi[df_all_uuid_years_combi.gp == 'No insurance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi.loc[df_all_uuid_years_combi.gp.isnull(), 'gp'] = 'No insurance'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275",
   "metadata": {},
   "source": [
    "The first building block is the insurance coverage data, which should include everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of Swiss cantons and their abbreviations\n",
    "swiss_cantons = {\n",
    "    \"Aargau\": \"AG\",\n",
    "    \"Appenzell Ausserrhoden\": \"AR\",\n",
    "    \"Appenzell Innerrhoden\": \"AI\",\n",
    "    \"Basel-Landschaft\": \"BL\",\n",
    "    \"Basel-Stadt\": \"BS\",\n",
    "    \"Bern\": \"BE\",\n",
    "    \"Fribourg\": \"FR\",\n",
    "    \"GenÃ¨ve\": \"GE\",\n",
    "    \"Glarus\": \"GL\",\n",
    "    \"GraubÃ¼nden\": \"GR\",\n",
    "    \"Jura\": \"JU\",\n",
    "    \"Luzern\": \"LU\",\n",
    "    \"NeuchÃ¢tel\": \"NE\",\n",
    "    \"Nidwalden\": \"NW\",\n",
    "    \"Obwalden\": \"OW\",\n",
    "    \"St. Gallen\": \"SG\",\n",
    "    \"Schaffhausen\": \"SH\",\n",
    "    \"Schwyz\": \"SZ\",\n",
    "    \"Solothurn\": \"SO\",\n",
    "    \"Thurgau\": \"TG\",\n",
    "    \"Ticino\": \"TI\",\n",
    "    \"Uri\": \"UR\",\n",
    "    \"Vaud\": \"VD\",\n",
    "    \"Valais\":\"VS\",\n",
    "    \"Zug\": \"ZG\",\n",
    "    \"ZÃ¼rich\": \"ZH\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverage_aos = df_couverture_aos[['uuid','NOANNEE','NBAGE','CDPHYSSEXE','CDLANGUE','MODELE','MTFRANCHISECOUV','CANTON_NAME']].drop_duplicates()\n",
    "df_coverage_lca = df_couverture_lca[['uuid','NOANNEE','NBAGE','CDPHYSSEXE','CDLANGUE','CANTON_NAME']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate df_lca and df_aos\n",
    "df_coverage = pd.concat([df_coverage_aos, df_coverage_lca])\n",
    "df_coverage = df_coverage.sort_values(['uuid','NOANNEE','MODELE']).drop_duplicates(subset = ['uuid','NOANNEE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverage['CANTON_ACRONYM'] = df_coverage['CANTON_NAME'].map(swiss_cantons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverage = pd.concat([df_coverage,\n",
    "                              pd.get_dummies(df_coverage.CDPHYSSEXE, prefix = 'SEX'),\n",
    "                              pd.get_dummies(df_coverage.CDLANGUE, prefix = 'LANG'),\n",
    "                              pd.get_dummies(df_coverage.MODELE, prefix = 'MODEL'),\n",
    "                              pd.get_dummies(df_coverage.CANTON_ACRONYM, prefix = 'CANTON_ACRONYM'),\n",
    "                              pd.get_dummies(df_coverage.MTFRANCHISECOUV, prefix = 'DEDUCTIBLE',dtype=int)],axis = 1).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_coverage = pd.concat([df_coverage,\n",
    "#                               pd.get_dummies(df_coverage.MTFRANCHISECOUV, prefix = 'DEDUCTIBLE_',dtype=int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage = pd.merge(df_all_uuid_years_combi, df_coverage, on = ['uuid','NOANNEE'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage_prestations = pd.merge(df_all_uuid_years_combi_coverage, df_outcomes_prestation_temp.drop(['NOANNEE','gp'], axis = 1), left_on = ['uuid','NOANNEE'], right_on = ['uuid',\"ANNEE_TRAITEMENT\"], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage_prestations['PRESTATIONS_BRUTES_AOS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage_prestations['PRESTATIONS_BRUTES_LCA'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286",
   "metadata": {},
   "source": [
    "ALL GOOD !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage_prestations_drugs = pd.merge(df_all_uuid_years_combi_coverage_prestations, patient_drugs, left_on = ['uuid','NOANNEE'], right_on=['uuid','ANNEE_TRAITEMENT'], suffixes = ('_prestation','_drug'), how = 'left')\n",
    "# df_all_uuid_years_combi_coverage_prestations_drugs = pd.merge(df_all_uuid_years_combi_coverage_prestations, patient_drugs_light, left_on = ['uuid','NOANNEE'], right_on=['uuid','ANNEE_TRAITEMENT'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage_prestations_drugs.PRESTATIONS_BRUTES_AOS.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_uuid_years_combi_coverage_prestations_drugs.PRESTATIONS_BRUTES_LCA.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290",
   "metadata": {},
   "source": [
    "### Check on memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:20]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_prestation_lca_1spe, df_ostheo, df_prestation_lca_1spe_1session_notax, df_prestation_lca_1spe_1session, df_n_by_lca_therapy, df_amount_by_lca_therapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293",
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_df, df_outcomes_prestation_temp, df_prestation_aos, df_couverture_aos, df_couverture_lca, df_prestation_lca, df_all_uuid_years_combi_coverage_prestations, df_amount_by_souscat_disp, df_all_uuid_years_combi_coverage, amount_year_dispensateur_onehot, df_grouped_month_outpatient, df_grouped_month_inpatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_drugs = optimize_memory_df(patient_drugs)\n",
    "df_all_uuid_years_combi_coverage_prestations_drugs = optimize_memory_df(df_all_uuid_years_combi_coverage_prestations_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295",
   "metadata": {},
   "source": [
    "## Combine patient data with address data\n",
    "\n",
    "- **Done** : Handling people who moved within a year -> creates duplicates\n",
    "\n",
    "**Strategies**\n",
    "\n",
    "*1. Averaging*: You could take an average of the environmental variables for individuals who have moved during the year. This assumes the time spent at each address is roughly equal and that the environmental variables have a linear relationship with health outcomes. However, this approach may not fully capture the effects if the environmental differences between the addresses are significant or if the time spent at each location was highly unequal.\n",
    "\n",
    "*2. Weighted Averaging*: If you have information about the duration of stay at each address within the year, you could assign weights to the environmental variables based on the proportion of time spent at each location. This would provide a more accurate reflection of the individual's environmental exposure over the year.\n",
    "\n",
    "*3. Use the Most Recent Address*: Another approach might be to use the environmental variables from the most recent address, assuming that this is the most relevant data. This might be appropriate if you believe recent environmental exposure is more relevant to the health outcomes you're studying.\n",
    "\n",
    "*4. Separate Rows for Each Address*: If the relationship between the environment and health is complex, it might make sense to treat each change of address as a separate observation. This will complicate your analysis, as you'll need to account for repeated measures of the same individuals, but it will allow you to examine the effect of environment in more detail.\n",
    "\n",
    "*5. Data Stratification*: Stratify the data into multiple categories such as \"Never moved\", \"Moved once\", \"Moved more than once\" and then perform the analysis. This approach could bring out interesting insights, however it could also limit the statistical power of your analysis due to the reduction in sample size within each stratum.\n",
    "\n",
    "\n",
    "**06.07.2023 : Chose option 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_with_env_variables = pd.merge(df_all_uuid_years_combi_coverage_prestations_drugs, df_full_address, on = ['uuid','NOANNEE'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addresses_w_access_pollution_ndvi_lst_sep.loc[df_addresses_w_access_pollution_ndvi_lst_sep.NOANNEE.isnull(), 'NOANNEE'] = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of all unique ID and YEAR combinations\n",
    "id_years = pd.DataFrame({'uuid': df_addresses_w_access_pollution_ndvi_lst_sep['uuid'].unique().tolist() * len([2017, 2018, 2019, 2020, 2021]),\n",
    "                         'NOANNEE': [2017, 2018, 2019, 2020, 2021] * len(df_addresses_w_access_pollution_ndvi_lst_sep['uuid'].unique())})\n",
    "# id_years['first_move_date'] = id_years.NOANNEE.apply(lambda x: pd.Timestamp(year=x, month=1, day=10))\n",
    "# Cross join the ID/YEAR dataframe with the DF_ADDRESS dataframe\n",
    "df_address_complete = pd.merge(id_years, df_addresses_w_access_pollution_ndvi_lst_sep[['uuid','NOANNEE','date','address_id']], on =['uuid','NOANNEE'], how='left')\n",
    "\n",
    "# Forward fill the missing addresses\n",
    "df_address_complete['address_id'] = df_address_complete.groupby('uuid')['address_id'].ffill()\n",
    "\n",
    "# Backward fill any remaining missing addresses\n",
    "df_address_complete['address_id'] = df_address_complete.groupby('uuid')['address_id'].bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299",
   "metadata": {},
   "source": [
    "### Create weighted average of env variables for people that moved within a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with a move within a year\n",
    "df_move = df_address_complete[df_address_complete['date'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extra rows for each move within a year\n",
    "df_extra = df_move.copy()\n",
    "df_extra['address_id'] = np.nan\n",
    "df_extra['date'] = pd.to_datetime(df_extra['NOANNEE'].astype(str) + '-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append these extra rows to our original DataFrame and sort the rows\n",
    "df_address_complete = pd.concat([df_address_complete, df_extra])\n",
    "df_address_complete.sort_values(['uuid', 'NOANNEE', 'date'], inplace=True)\n",
    "df_address_complete = df_address_complete.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address_complete['address_id'] = df_address_complete.groupby(['uuid'])['address_id'].ffill()\n",
    "df_address_complete['address_id'] = df_address_complete.groupby(['uuid'])['address_id'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the month of move in\n",
    "df_address_complete['month_moved_in'] = df_address_complete['date'].dt.month -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The month of move out would be the month in which the next move happened\n",
    "df_address_complete['month_moved_out'] = df_address_complete.groupby(['uuid', 'NOANNEE'])['month_moved_in'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no next move in the same year, then month of move out would be December\n",
    "df_address_complete.loc[df_address_complete['month_moved_in'].isna(), 'month_moved_in'] = 0\n",
    "df_address_complete.loc[df_address_complete['month_moved_out'].isna(), 'month_moved_out'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the months at each address\n",
    "df_address_complete['months_at_address'] = df_address_complete['month_moved_out'] - df_address_complete['month_moved_in']\n",
    "\n",
    "# Calculate the weight\n",
    "df_address_complete['weight'] = df_address_complete['months_at_address'] / 12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by 'uuid' and 'NOANNEE', sum the weights, and reset the index\n",
    "weight_check = df_address_complete.groupby(['uuid', 'NOANNEE'])['weight'].sum().reset_index()\n",
    "\n",
    "# Check if any weight sum for each individual per year is not close to 1 (considering a small numerical tolerance)\n",
    "incorrect_weights = weight_check[~np.isclose(weight_check['weight'], 1, atol=0.01)]\n",
    "\n",
    "# Print the result\n",
    "if incorrect_weights.empty:\n",
    "    print(\"All individuals have weights summing to approximately 1 for each year.\")\n",
    "else:\n",
    "    print(f\"There are {len(incorrect_weights)} individuals-years with weights not summing to approximately 1.\")\n",
    "    print(incorrect_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309",
   "metadata": {},
   "source": [
    "### Merge all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address_complete_w_env = pd.merge(df_address_complete, df_addresses_w_access_pollution_ndvi_lst_sep.drop_duplicates('address_id').drop(['uuid','ID_LAMAL','ID_LCA','NOANNEE','date','distance','doubl','MIN_of_Date_adress','distance_join_ndvi_lst'], axis = 1), on = 'address_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_columns = ['D_BAKERY', 'D_BOOK', 'D_GARAGE', 'D_GROCERY',\n",
    "       'D_HMARKET', 'D_KIOSK', 'D_PHARMA', 'D_SMARKET', 'D_STORE', 'D_RESTO',\n",
    "       'D_BANK', 'D_ADMIN', 'D_RETIRE', 'D_SECURITY', 'D_EDUC', 'D_SCHOOL_O',\n",
    "       'D_SCHOOL_S', 'D_HAIR', 'D_SPORT', 'D_DENTIST', 'D_MEDIC', 'D_MEDIC_B',\n",
    "       'D_MEDIC_S', 'D_STOP_0', 'D_STOP_1', 'D_STOP_2', 'D_STOP_3', 'D_STOP_4',\n",
    "       'D_STOP_5', 'D_STOP_TOT', 'D_MUSEUM', 'D_FOREST', 'D_LAKE', 'D_SWIM',\n",
    "       'D_ZOO', 'distance_join_access', 'mean_pm10', 'median_pm10',\n",
    "       'mean_pm25', 'median_pm25', 'mean_no2', 'median_no2', 'mean_carday',\n",
    "       'median_carday', 'mean_carnight', 'median_carnight',\n",
    "       'distance_join_pollution', 'min_ndvi', 'max_ndvi', 'mean_ndvi',\n",
    "       'median_ndvi', 'min_lst', 'max_lst', 'mean_lst', 'median_lst', 'ssep2','ssep3']\n",
    "first_columns = ['address_id', 'lon_masked', 'lat_masked','geometry','ssep2_d', 'ssep2_t', 'ssep2_q', 'ssep3_d', 'ssep3_t', 'ssep3_q']\n",
    "# Prepare dictionary for aggregation\n",
    "aggregations = {col: 'sum' for col in env_columns}\n",
    "aggregations.update({col: 'last' for col in first_columns})\n",
    "\n",
    "for col in env_columns:\n",
    "     df_address_complete_w_env[col] = df_address_complete_w_env[col] * df_address_complete_w_env['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312",
   "metadata": {},
   "source": [
    "#### Weight env variables by addresses within a year\n",
    "\n",
    "If a person lived at two addresses within the same year, we weight the env values associated with each address based on the number of months spent at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address_complete_w_env_weighted = df_address_complete_w_env.sort_values(['uuid','NOANNEE','weight']).groupby(['uuid','NOANNEE']).agg(aggregations).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_address_complete_w_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315",
   "metadata": {},
   "source": [
    "#### Merge with addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.merge(df_all_uuid_years_combi_coverage_prestations_drugs, df_address_complete_w_env_weighted, on = ['uuid','NOANNEE'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all_uuid_years_combi_coverage_prestations_drugs, df_address_complete_w_env_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.PRESTATIONS_BRUTES_AOS.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.PRESTATIONS_BRUTES_LCA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset[full_dataset.ssep3.isnull() == True].PRESTATIONS_BRUTES_AOS.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321",
   "metadata": {},
   "source": [
    "#### Delete the few NA values for the SES index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull = full_dataset[full_dataset.ssep3.isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.PRESTATIONS_BRUTES_LCA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.PRESTATIONS_BRUTES_AOS.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325",
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.loc[:, 'A01A_ATC_N':'V10X_ATC_N'] = full_dataset_nonull.loc[:, 'A01A_ATC_N':'V10X_ATC_N'].fillna(0)\n",
    "full_dataset_nonull.loc[:, 'A01A_ATC_AMOUNT':'V10X_ATC_AMOUNT'] = full_dataset_nonull.loc[:, 'A01A_ATC_AMOUNT':'V10X_ATC_AMOUNT'].fillna(0)\n",
    "full_dataset_nonull.loc[:, 'Allergologie et immunologie clinique_prestation':'Urologie_prestation'] = full_dataset_nonull.loc[:, 'Allergologie et immunologie clinique_prestation':'Urologie_prestation'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull['n_atc'] = full_dataset_nonull['n_atc'].fillna(0)\n",
    "full_dataset_nonull['PRESTATIONS_BRUTES_ATC'] = full_dataset_nonull['PRESTATIONS_BRUTES_ATC'].fillna(0)\n",
    "full_dataset_nonull['n_month_lca_by_patient'] = full_dataset_nonull['n_month_lca_by_patient'].fillna(0)\n",
    "full_dataset_nonull = full_dataset_nonull.drop('ANNEE_TRAITEMENT_prestation', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull = gpd.GeoDataFrame(full_dataset_nonull, geometry = full_dataset_nonull['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_w_gis_nonull['lon'], data_w_gis_nonull['lat'] = data_w_gis_nonull['geometry'].x, data_w_gis_nonull['geometry'].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_w_gis_nonull.drop('geometry', axis = 1).to_parquet('../Data/processed/data_w_gis_nonull.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.gp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.PRESTATIONS_BRUTES_AOS.sum()/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333",
   "metadata": {},
   "source": [
    "## Create a Chronic disease score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cds = pd.read_csv('/Users/david/Dropbox/PhD/GitHub/SanteIntegra/Data/ATC - Chronic disease score')\n",
    "\n",
    "df_cds['Chronic diseases'] = df_cds['Chronic diseases'].ffill()\n",
    "\n",
    "df_atc = pd.read_csv('/Users/david/Dropbox/PhD/GitHub/SanteIntegra/Data/atc_index_clean.csv')\n",
    "\n",
    "dict_atc = dict(zip(df_atc.atc, df_atc.nameen))\n",
    "\n",
    "dict_atc_inv = {v: k for k, v in dict_atc.items()}\n",
    "\n",
    "df_cds['ATC'] = df_cds['Medication classes'].str.lower().map(dict_atc_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335",
   "metadata": {},
   "source": [
    "#### Modification to the CDS ATC categories\n",
    "\n",
    "- Some ATC listed in the categories of the CDS are on the ATC level 2 and some on level 4. Thus, for level 2, we replaced the level 2 code (ex. M10) to the level 3 categories existing for that ATC. \n",
    "\n",
    "- For level 4 ATC, it is less simple, we don't have the granularity to select the specific ATC of interest. We could either : be less specific and take all the ATC level 4 corresponding sharing the same ATC level 3. Or we could just remove the level 4 ATC altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cds.loc[df_cds.ATC == 'M05','ATC'] = 'M05B'\n",
    "df_cds = df_cds[df_cds.ATC != 'A02X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['NBAGE','DEDUCTIBLE_0.0', 'DEDUCTIBLE_100.0',\n",
    "       'DEDUCTIBLE_200.0', 'DEDUCTIBLE_300.0', 'DEDUCTIBLE_400.0',\n",
    "       'DEDUCTIBLE_500.0', 'DEDUCTIBLE_600.0', 'DEDUCTIBLE_1000.0',\n",
    "       'DEDUCTIBLE_1500.0', 'DEDUCTIBLE_2000.0', 'DEDUCTIBLE_2500.0','SEX_F',\n",
    "              'CANTON_ACRONYM_AG',\n",
    " 'CANTON_ACRONYM_AI',\n",
    " 'CANTON_ACRONYM_AR',\n",
    " 'CANTON_ACRONYM_BE',\n",
    " 'CANTON_ACRONYM_BL',\n",
    " 'CANTON_ACRONYM_BS',\n",
    " 'CANTON_ACRONYM_FR',\n",
    " 'CANTON_ACRONYM_GE',\n",
    " 'CANTON_ACRONYM_GL',\n",
    " 'CANTON_ACRONYM_GR',\n",
    " 'CANTON_ACRONYM_JU',\n",
    " 'CANTON_ACRONYM_LU',\n",
    " 'CANTON_ACRONYM_NE',\n",
    " 'CANTON_ACRONYM_NW',\n",
    " 'CANTON_ACRONYM_OW',\n",
    " 'CANTON_ACRONYM_SG',\n",
    " 'CANTON_ACRONYM_SH',\n",
    " 'CANTON_ACRONYM_SO',\n",
    " 'CANTON_ACRONYM_SZ',\n",
    " 'CANTON_ACRONYM_TG',\n",
    " 'CANTON_ACRONYM_TI',\n",
    " 'CANTON_ACRONYM_UR',\n",
    " 'CANTON_ACRONYM_VD',\n",
    " 'CANTON_ACRONYM_VS',\n",
    " 'CANTON_ACRONYM_ZG',\n",
    " 'CANTON_ACRONYM_ZH','ssep2']\n",
    "chronic_conditions = [i+ \"_ATC_N\" for i in df_cds.ATC.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339",
   "metadata": {},
   "outputs": [],
   "source": [
    "chronic_conditions = ['A02A_ATC_N',\n",
    " 'A02B_ATC_N', \n",
    " 'M05B_ATC_N',\n",
    " 'L01A_ATC_N',\n",
    " 'L01B_ATC_N',\n",
    " 'L01C_ATC_N',\n",
    " 'L01D_ATC_N',\n",
    " 'L01E_ATC_N',\n",
    " 'L01F_ATC_N',\n",
    " 'L01X_ATC_N',\n",
    " 'C09A_ATC_N',\n",
    " 'C09B_ATC_N',\n",
    " 'C09C_ATC_N',\n",
    " 'C09D_ATC_N',\n",
    " 'C09X_ATC_N',\n",
    " 'C02A_ATC_N',\n",
    "# 'C02B_ATC_N',\n",
    " 'C02C_ATC_N',\n",
    " 'C02D_ATC_N',\n",
    " 'C02K_ATC_N',\n",
    "# 'C02L_ATC_N',\n",
    "# 'C02N_ATC_N',\n",
    " 'C04A_ATC_N',\n",
    " 'C07A_ATC_N',\n",
    " 'C08C_ATC_N',\n",
    " 'C08D_ATC_N',\n",
    "# 'C08E_ATC_N',\n",
    "# 'C08G_ATC_N',\n",
    " 'B01A_ATC_N',\n",
    " 'N06D_ATC_N',\n",
    " 'A10A_ATC_N',\n",
    " 'A10B_ATC_N',\n",
    "# 'A10X_ATC_N',\n",
    " 'N03A_ATC_N',\n",
    " 'S01E_ATC_N',\n",
    " 'M04A_ATC_N',\n",
    " 'J05A_ATC_N',\n",
    " 'C10A_ATC_N',\n",
    " 'C10B_ATC_N',\n",
    " 'A07E_ATC_N',\n",
    " 'B03A_ATC_N',\n",
    " 'N02C_ATC_N',\n",
    " 'N02A_ATC_N',\n",
    " 'N02B_ATC_N',\n",
    " 'N04A_ATC_N',\n",
    " 'N04B_ATC_N',\n",
    "# 'N04C_ATC_N',\n",
    " 'N05B_ATC_N',\n",
    " 'N05C_ATC_N',\n",
    " 'N06A_ATC_N',\n",
    " 'N05A_ATC_N',\n",
    " 'R03A_ATC_N',\n",
    " 'R03B_ATC_N',\n",
    " 'R03C_ATC_N',\n",
    " 'R03D_ATC_N',\n",
    " 'M01A_ATC_N',\n",
    "# 'M01B_ATC_N',\n",
    " 'M01C_ATC_N',\n",
    " 'M02A_ATC_N',\n",
    " 'L04A_ATC_N',\n",
    " 'H03A_ATC_N',\n",
    " 'J04A_ATC_N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_chronic_diseases_atc = {\n",
    "    \"A02A_ATC_N\":'Acid related disorders',\n",
    "    \"A02B_ATC_N\":'Acid related disorders',\n",
    "    'M05B_ATC_N':'Osteoporosis',\n",
    "    'A10A_ATC_N':'Diabetes mellitus',\n",
    "    'A10B_ATC_N':'Diabetes mellitus',\n",
    "    'B03A_ATC_N':'Iron deficiency anemia',\n",
    "    'N03A_ATC_N': 'Epilepsy',\n",
    "    'C02A_ATC_N':'Cardiovascular diseases',\n",
    "    'C02C_ATC_N':'Cardiovascular diseases',\n",
    "    'C02D_ATC_N':'Cardiovascular diseases',\n",
    "    'C02K_ATC_N':'Cardiovascular diseases',\n",
    "    'C04A_ATC_N':'Cardiovascular diseases',\n",
    "    'C07A_ATC_N':'Cardiovascular diseases',\n",
    "    'C08C_ATC_N':'Cardiovascular diseases',\n",
    "    'C08D_ATC_N':'Cardiovascular diseases',\n",
    "    'C09A_ATC_N':'Cardiovascular diseases',\n",
    "    'C09B_ATC_N':'Cardiovascular diseases',\n",
    "    'C09C_ATC_N':'Cardiovascular diseases',\n",
    "    'C09D_ATC_N':'Cardiovascular diseases',\n",
    "    \"C10A_ATC_N\":\"Hyperlipidemia\",\n",
    "    \"C10B_ATC_N\":\"Hyperlipidemia\",\n",
    "    'L01A_ATC_N':'Cancer',\n",
    "    'L01B_ATC_N':'Cancer',\n",
    "    'L01C_ATC_N':'Cancer',\n",
    "    'L01D_ATC_N':'Cancer',\n",
    "    'L01E_ATC_N':'Cancer',\n",
    "    'L01F_ATC_N':'Cancer',\n",
    "    'L01X_ATC_N':'Cancer',\n",
    "    \"M01A_ATC_N\":'Rheumatologic conditions',\n",
    "    \"M01C_ATC_N\":'Rheumatologic conditions',\n",
    "    \"M02A_ATC_N\":'Rheumatologic conditions',\n",
    "    \"M04A_ATC_N\":'Gout and hyperuricemia',\n",
    "    'N02A_ATC_N':'Pain',\n",
    "    'N02B_ATC_N':\"Pain\",\n",
    "    \"N02C_ATC_N\":'Migraines',\n",
    "    \"N04A_ATC_N\":\"Parkinson's disease\",\n",
    "    \"N04B_ATC_N\":\"Parkinson's disease\",\n",
    "    'N05A_ATC_N':'Psychoses',\n",
    "\n",
    "    'N05B_ATC_N':'Psychological disorders',\n",
    "    'N05C_ATC_N':'Psychological disorders',\n",
    "    'N06A_ATC_N':'Psychological disorders',\n",
    "\n",
    "    \"N06D_ATC_N\":'Dementia',\n",
    "    \"L04A_ATC_N\":'Rheumatologic conditions',\n",
    "    \"H03A_ATC_N\":'Thyroid disorders',\n",
    "    \"J04A_ATC_N\":'Tuberculosis',\n",
    "    'J05A_ATC_N':'HIV',\n",
    "    \"R03A_ATC_N\":'Respiratory illness',\n",
    "    \"S01E_ATC_N\":'Glaucoma'\n",
    "}\n",
    "\n",
    "dict_chronic_diseases_atc_amount = {\n",
    "    \"A02A_ATC_AMOUNT\":'Acid related disorders',\n",
    "    \"A02B_ATC_AMOUNT\":'Acid related disorders',\n",
    "    'M05B_ATC_AMOUNT':'Osteoporosis',\n",
    "    'A10A_ATC_AMOUNT':'Diabetes mellitus',\n",
    "    'A10B_ATC_AMOUNT':'Diabetes mellitus',\n",
    "    'B03A_ATC_AMOUNT':'Iron deficiency anemia',\n",
    "    'N03A_ATC_AMOUNT': 'Epilepsy',\n",
    "    'C02A_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C02C_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C02D_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C02K_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C04A_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C07A_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C08C_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C08D_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C09A_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C09B_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C09C_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    'C09D_ATC_AMOUNT':'Cardiovascular diseases',\n",
    "    \"C10A_ATC_AMOUNT\":\"Hyperlipidemia\",\n",
    "    \"C10B_ATC_AMOUNT\":\"Hyperlipidemia\",\n",
    "    'L01A_ATC_AMOUNT':'Cancer',\n",
    "    'L01B_ATC_AMOUNT':'Cancer',\n",
    "    'L01C_ATC_AMOUNT':'Cancer',\n",
    "    'L01D_ATC_AMOUNT':'Cancer',\n",
    "    'L01E_ATC_AMOUNT':'Cancer',\n",
    "    'L01F_ATC_AMOUNT':'Cancer',\n",
    "    'L01X_ATC_AMOUNT':'Cancer',\n",
    "    \"M01A_ATC_AMOUNT\":'Rheumatologic condÂ«itions',\n",
    "    \"M01C_ATC_AMOUNT\":'Rheumatologic conditions',\n",
    "    \"M02A_ATC_AMOUNT\":'Rheumatologic conditions',\n",
    "    \"M04A_ATC_AMOUNT\":'Gout and hyperuricemia',\n",
    "    'N02A_ATC_AMOUNT':'Pain',\n",
    "    'N02B_ATC_AMOUNT':\"Pain\",\n",
    "    \"N02C_ATC_AMOUNT\":'Migraines',\n",
    "    \"N04A_ATC_AMOUNT\":\"Parkinson's disease\",\n",
    "    \"N04B_ATC_AMOUNT\":\"Parkinson's disease\",\n",
    "    'N05A_ATC_AMOUNT':'Psychoses',\n",
    "    'N05B_ATC_AMOUNT':'Psychological disorders',\n",
    "    'N05C_ATC_AMOUNT':'Psychological disorders',\n",
    "    'N06A_ATC_AMOUNT':'Psychological disorders',\n",
    "    \"N06D_ATC_AMOUNT\":'Dementia',\n",
    "    \"L04A_ATC_AMOUNT\":'Rheumatologic conditions',\n",
    "    \"H03A_ATC_AMOUNT\":'Thyroid disorders',\n",
    "    \"J04A_ATC_AMOUNT\":'Tuberculosis',\n",
    "    'J05A_ATC_AMOUNT':'HIV',\n",
    "    \"R03A_ATC_AMOUNT\":'Respiratory illness',\n",
    "\n",
    "    \"S01E_ATC_AMOUNT\":'Glaucoma',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the dictionary for grouping by disease\n",
    "disease_to_atc = {}\n",
    "for atc, disease in dict_chronic_diseases_atc_amount.items():\n",
    "    if disease in disease_to_atc:\n",
    "        disease_to_atc[disease].append(atc)\n",
    "    else:\n",
    "        disease_to_atc[disease] = [atc]\n",
    "\n",
    "# For each disease, create a new column and check if any ATC columns are 1\n",
    "for disease, atcs in disease_to_atc.items():\n",
    "    full_dataset_nonull[disease] = full_dataset_nonull[atcs].sum(axis=1)\n",
    "\n",
    "# If you want binary 0/1 values\n",
    "# full_dataset_nonull = full_dataset_nonull.replace({disease: {2: 1 for disease in disease_to_atc.keys()}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342",
   "metadata": {},
   "source": [
    "## Define treated and control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.loc[full_dataset_nonull.gp.isin(['LCA & AOS','LCA only']), 'treatment'] = 1\n",
    "full_dataset_nonull.loc[full_dataset_nonull.gp.isin(['AOS only','No usage']), 'treatment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset_nonull.loc[(full_dataset_nonull.PRESTATIONS_BRUTES_AOS > 0) &(full_dataset_nonull.PRESTATIONS_BRUTES_LCA > 0)&(full_dataset_nonull.PRESTATIONS_BRUTES_CAM > 0), 'treatment_lca_cam'] = 1\n",
    "# full_dataset_nonull.loc[(full_dataset_nonull.PRESTATIONS_BRUTES_AOS > 0) &(full_dataset_nonull.PRESTATIONS_BRUTES_LCA == 0)&(full_dataset_nonull.PRESTATIONS_BRUTES_CAM == 0), 'treatment_lca_cam'] = 0\n",
    "\n",
    "\n",
    "full_dataset_nonull['treatment_lca_cam'] = full_dataset_nonull['treatment'].copy()\n",
    "full_dataset_nonull.loc[full_dataset_nonull.PRESTATIONS_BRUTES_CAM > 0, 'treatment_lca_cam'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.loc[(full_dataset_nonull.PRESTATIONS_BRUTES_AOS > 0) &(full_dataset_nonull.PRESTATIONS_BRUTES_LCA == 0)&(full_dataset_nonull.PRESTATIONS_BRUTES_CAM > 0), 'treatment_cam'] = 1\n",
    "full_dataset_nonull.loc[(full_dataset_nonull.PRESTATIONS_BRUTES_AOS > 0) &(full_dataset_nonull.PRESTATIONS_BRUTES_LCA == 0)&(full_dataset_nonull.PRESTATIONS_BRUTES_CAM == 0), 'treatment_cam'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:25]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347",
   "metadata": {},
   "source": [
    "## Calculate chronic disease score (CDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull_with_cds = full_dataset_nonull[full_dataset_nonull.gp.isin(['AOS only','LCA & AOS','LCA only','No usage'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349",
   "metadata": {},
   "outputs": [],
   "source": [
    "chronic_diseases = list(set(dict_chronic_diseases_atc.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a thresholding function\n",
    "def threshold(value, threshold=0):\n",
    "    return 1 if value > threshold else 0\n",
    "\n",
    "# Apply thresholding to multiple columns\n",
    "thresholded_df = full_dataset_nonull[chronic_diseases].applymap(lambda x: threshold(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the original DataFrame with thresholded columns\n",
    "full_dataset_nonull_with_cds[chronic_diseases] = thresholded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_df = thresholded_df.add_suffix('_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull[thresholded_df.columns] = thresholded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354",
   "metadata": {},
   "outputs": [],
   "source": [
    "del thresholded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_predicted_costs = {}\n",
    "for year in full_dataset_nonull_with_cds.NOANNEE.unique():\n",
    "    print(year)\n",
    "    df_cds_year = full_dataset_nonull_with_cds[full_dataset_nonull_with_cds.NOANNEE == year][predictors + chronic_diseases + ['PRESTATIONS_TOTAL']]\n",
    "    \n",
    "    # Create two-part regression models WITHOUT TRAIN AND TEST SETS\n",
    "    X = df_cds_year[predictors + chronic_diseases]\n",
    "    y = df_cds_year['PRESTATIONS_TOTAL']\n",
    "    # Part 1: Logistic regression to determine the probability of incurring health care costs per patient/year\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data_2017[predictors + chronic_conditions], data_2017['PRESTATIONS_TOTAL'], test_size=0.2, random_state=42)\n",
    "    log_reg.fit(X, y > 0)\n",
    "    print(log_reg.intercept_, log_reg.coef_, log_reg.score(X, y>0))\n",
    "\n",
    "    prob_incurring_costs = log_reg.predict_proba(X)[:, 1]\n",
    "#     df_cds_year['prob_cost'] = prob_incurring_costs\n",
    "    # Part 2: Generalized linear regression with a gamma error distribution and linear link function\n",
    "    # to estimate annual health care expenditures for patients incurring costs higher than 0\n",
    "    df_cds_year['const'] = 1\n",
    "    df_cds_year[predictors + chronic_diseases + ['const']]\n",
    "    X_costs = X[y > 0]\n",
    "    y_costs = y[y > 0]\n",
    "    glm_gamma = sm.GLM(endog = y_costs, exog=X_costs, family=sm.families.Gamma(link=sm.families.links.identity()))\n",
    "    glm_gamma_results = glm_gamma.fit()\n",
    "    predicted_costs = glm_gamma_results.predict(X)\n",
    "    expected_total_costs = prob_incurring_costs * predicted_costs\n",
    "    glm_gamma_results.params[8:]\n",
    "\n",
    "    chronic_disease_coef_dict = glm_gamma_results.params[40:].to_dict()\n",
    "\n",
    "    weighted_sum = df_cds_year.apply(lambda x: x * chronic_disease_coef_dict[x.name] if x.name in chronic_disease_coef_dict.keys() else x * 0).sum(axis=1)\n",
    "\n",
    "    yearly_predicted_costs[year] = weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_gamma_results.params[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glm_gamma_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = pd.DataFrame(pd.DataFrame.from_dict(yearly_predicted_costs).stack(), columns = ['CDS']).reset_index().drop('level_1', axis = 1).set_index('level_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull['cds'] = cds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull[['PRESTATIONS_BRUTES_LCA','PRESTATIONS_BRUTES_AOS','PRESTATIONS_NETTES_AOS','PRESTATIONS_BRUTES_CAM']].isna().sum().sort_values().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull[(full_dataset_nonull.PRESTATIONS_BRUTES_LCA.isnull())].groupby('gp').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.gp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which can also be obtained through\n",
    "# weights = data_2017[predictors + chronic_conditions + ['const']] * glm_gamma_results.params\n",
    "# predicted_costs = weights.sum(axis = 1)\n",
    "# expected_total_costs = prob_incurring_costs * predicted_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365",
   "metadata": {},
   "source": [
    "#### Export final dataset\n",
    "\n",
    "- Features still missing:\n",
    "    - Spike profile\n",
    "    - Average monthly drug cost\n",
    "    - Last three months cost (drug)\n",
    "    - Last three months cost (prestation)\n",
    "    - Number of months above mean (drug)\n",
    "    - Number of months above mean (prestation)\n",
    "    - Max monthly cost (drug)\n",
    "    - Max monthly cost (prestation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull = full_dataset_nonull.rename(columns = {'PRESTATIONS_BRUTES':\"DRUGAMOUNT_BRUT\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367",
   "metadata": {},
   "source": [
    "#### Add age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins for the age groups\n",
    "bins = [0, 2, 6, 13, 19, 25, 35, 45, 65, 80, np.inf]\n",
    "# Define labels for the age groups\n",
    "labels = ['0-1', '2-5', '6-12', '13-18', '19-24', '25-34', '35-44', '45-64', '65-79', '80+']\n",
    "# Create new column 'age_group' using pd.cut()\n",
    "full_dataset_nonull['age_group'] = pd.cut(full_dataset_nonull['NBAGE'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_nonull.to_parquet(data_folder/'processed'/'full_dataset_nonull.parquet.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370",
   "metadata": {},
   "source": [
    "## Prevalence of state transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_outcomes_prestation[df_outcomes_prestation.ANNEE_TRAITEMENT == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_df = df_outcomes_prestation.pivot(columns = 'ANNEE_TRAITEMENT',index = 'uuid', values = 'gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcomes_prestation[df_outcomes_prestation.gp.isnull()].uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_df['dummy'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = (\n",
    "    sankey_df.groupby([2017, 2018, 2019, 2020, 2021], observed = True)\n",
    "    .agg({\"dummy\": \"sum\"})\n",
    "    .dropna()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_intervals = [2017, 2018, 2019, 2020, 2021]\n",
    "flows_full = pd.DataFrame()\n",
    "for i in range(len(t_intervals) - 1):\n",
    "    _ = (\n",
    "        sankey_df.groupby([t_intervals[i],t_intervals[i+1]])\n",
    "        .agg({\"dummy\": \"sum\"})\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "    ).rename(\n",
    "            columns={\n",
    "                \"dummy\": \"value\",\n",
    "                t_intervals[i]:'source',\n",
    "                t_intervals[i+1]:'target'\n",
    "            })\n",
    "    _['year'] = t_intervals[i]\n",
    "\n",
    "    flows_full = pd.concat([flows_full, _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_full[[\"source\",'target']] = flows_full[[\"source\",'target']].astype('category')\n",
    "\n",
    "flows_full = flows_full.sort_values(['year','target','source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0\n",
    "for year in t_intervals:\n",
    "    flows_full.loc[flows_full.year == year, 'source_code'] = flows_full[flows_full.year == year].source.cat.codes + eps\n",
    "    flows_full.loc[flows_full.year == year, 'target_code'] = flows_full[flows_full.year == year].target.cat.codes + eps + 5\n",
    "    eps+=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_fulls_labels = list(flows_full['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_full.loc[flows_full['target'].str.contains('LCA only'),'color'] = 'rgba(222,45,38, 0.4)'\n",
    "flows_full.loc[flows_full['target'].str.contains('AOS only'),'color'] = 'rgba(49,130,189, 0.4)'\n",
    "flows_full.loc[flows_full['target'].str.contains('LCA & AOS'),'color'] = 'rgba(173,221,142, 0.4)'\n",
    "flows_full.loc[flows_full['target'].str.contains('No usage'),'color'] = 'rgba(189,189,189, 0.4)'\n",
    "flows_full.loc[flows_full['target'].str.contains('Not insured LCA, AOS'),'color'] = 'rgba(189,189,189, 0.4)'\n",
    "flows_full.loc[flows_full['target'].str.contains('Not insured AOS, LCA'),'color'] = 'rgba(189,189,189, 0.4)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "for i in flows_fulls_labels:\n",
    "    if 'LCA only' in i:\n",
    "        colors.append('rgba(222,45,38, 0.4)')\n",
    "    elif 'AOS only' in i:\n",
    "        colors.append('rgba(49,130,189, 0.4)')\n",
    "    elif 'LCA & AOS' in i:\n",
    "        colors.append('rgba(173,221,142, 0.4)')\n",
    "    else:\n",
    "        colors.append('rgba(189,189,189, 0.4)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import urllib, json\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    valueformat = \".0f\",\n",
    "    valuesuffix = \" Individuals\",\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 15,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label =  flows_fulls_labels,\n",
    "      color = colors\n",
    "    ),\n",
    "    link = dict(\n",
    "      source =  flows_full['source_code'],\n",
    "      target =  flows_full['target_code'],\n",
    "      value =  flows_full['value'],\n",
    "      color = flows_full['color']))])\n",
    "\n",
    "fig.update_layout(\n",
    "    hovermode = 'x',\n",
    "    title=\"Trajectoire des individus assurÃ©s entre 2017 et 2021\",\n",
    "    font=dict(size = 12, color = 'black'),\n",
    "    plot_bgcolor='black',height = 500, width = 900,\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "fig.write_html(\"../Results/fig1.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384",
   "metadata": {},
   "source": [
    "## Seasonality and periodicity\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Problem Statement</b> \n",
    "\n",
    "1. Identify trends, periods and seasons in the monthly aggregated data\n",
    "    \n",
    "2. Given the monthly total LCA consumption from 2017 to 2020, forecast the monthly load in 2021. In general, the model shall be able to produce one-year-ahead forecasts.\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386",
   "metadata": {},
   "source": [
    "### 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_prestation_brutes_aos_by_patient_by_month = sum_prestation_brutes_aos_by_patient_by_month.groupby(['uuid','ANNEE_TRAITEMENT','MOIS_TRAITEMENT'])['PRESTATIONS_BRUTES'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_outcomes_by_month = pd.concat([n_prestation_aos_by_patient_by_month,\n",
    "                                                 sum_prestation_brutes_aos_by_patient_by_month,\n",
    "                                                 sum_prestation_nettes_aos_by_patient_by_month,\n",
    "                                                 n_bill_prestation_aos_by_patient_by_month], axis = 1).reset_index().rename(columns = {0:'NBROWS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_outcomes_by_month['treatmentdate'] = pd.to_datetime(df_prestation_aos_outcomes_by_month['ANNEE_TRAITEMENT'].astype('string') + '-' + df_prestation_aos_outcomes_by_month['MOIS_TRAITEMENT'].astype('string'))\n",
    "df_prestation_aos_outcomes_by_month['treatmentmonth'] = df_prestation_aos_outcomes_by_month['treatmentdate'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_outcomes_sums = df_prestation_aos_outcomes_by_month.groupby('treatmentdate', observed = True)[['NBRE_FACTURES','PRESTATIONS_BRUTES','PRESTATIONS_NETTES','NBROWS']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prestation_aos_outcomes_sums = df_prestation_aos_outcomes_sums.asfreq('M', method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time-series of the PRESTATIONS_BRUTES variable\n",
    "df_prestation_aos_outcomes_sums.PRESTATIONS_BRUTES.plot(ylim = (0, 100000000), figsize = (6,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393",
   "metadata": {},
   "source": [
    "Some features are visible:\n",
    "\n",
    "- There was a big drop in the prestations during the 2020 lockdown\n",
    "- The first months of each year seem to be the highest each time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394",
   "metadata": {},
   "source": [
    "We can further explore the trend with a moving average filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 months rolling window\n",
    "df_prestation_aos_outcomes_sums.rolling(3).mean().PRESTATIONS_BRUTES.plot(ylim = (0, 100000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396",
   "metadata": {},
   "source": [
    "We can also have a look at the autocorrelation and partial autocorrelation function to check for the yearly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the time series data\n",
    "plt.plot(df_prestation_aos_outcomes_sums)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rolling mean and standard deviation\n",
    "rolling_mean = df_prestation_aos_outcomes_sums.rolling(window=12).mean()\n",
    "rolling_std = df_prestation_aos_outcomes_sums.rolling(window=12).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling mean and standard deviation\n",
    "plt.plot(rolling_mean, label=['Rolling Mean - Nbre factures','Rolling Mean - Montant Brut','Rolling Mean - Montant Net','Rolling Mean - QuantitÃ©'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rolling_std, label=['Rolling Std - Nbre factures','Rolling Std - Montant Brut','Rolling Mean - Montant Net','Rolling Std - QuantitÃ©'])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401",
   "metadata": {},
   "source": [
    "The `seasonal_decompose()` function from the `statsmodels.tsa.seasonal` library is used to decompose a time series into its trend, seasonal, and residual components. This function returns a `seasonal_decompose()` object, which includes the following attributes:\n",
    "\n",
    "`trend`: the estimated trend component of the time series. <br/>\n",
    "`seasonal`: the estimated seasonal component of the time series.<br/>\n",
    "`resid`: the residuals of the time series after removing the trend and seasonal components.<br/>\n",
    "`observed`: the original time series.<br/>\n",
    "\n",
    "When interpreting the results from the `seasonal_decompose()` function, you should consider the following:\n",
    "\n",
    "**Trend**: The trend component represents the long-term changes in the time series data. It can be used to identify whether the time series is increasing, decreasing, or staying relatively constant over time.\n",
    "\n",
    "**Seasonality**: The seasonal component represents the repeating patterns in the time series data. It can be used to identify whether the time series has a regular seasonality, such as daily, weekly, or yearly patterns.\n",
    "\n",
    "**Residuals**: The residuals represent the random or irregular variations in the time series data that are not explained by the trend and seasonal components.\n",
    "\n",
    "**Plotting the decomposition**: The function also provides a plot of the decomposition, which allows you to visualize the trend, seasonal, and residual components of the time series. The trend component is represented by a solid line, the seasonal component is represented by a dotted line, and the residuals are represented by a dashed line. The original time series is also plotted for comparison.\n",
    "\n",
    "**Model selection**: The function allows you to select a model between additive and multiplicative, the additive model is used when the seasonal component is constant over time and the multiplicative model is used when the seasonal component is proportional to the trend component.\n",
    "\n",
    "It's important to note that the decomposition might not always work properly, in some cases, the decomposition may not be able to separate the trend and seasonal components cleanly, or the residuals may not be random. In these cases, you may need to try different methods or pre-process the data before decomposing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose the time series into its trend, seasonal, and residual components\n",
    "result = seasonal_decompose(df_prestation_aos_outcomes_sums['PRESTATIONS_BRUTES'], model='multiplicative')\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose the time series into its trend, seasonal, and residual components\n",
    "result = seasonal_decompose(df_prestation_aos_outcomes_sums['NBRE_FACTURES'], model='multiplicative')\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405",
   "metadata": {},
   "source": [
    "The plot_acf() function from the statsmodels.graphics.tsaplots library is used to plot the autocorrelation function (ACF) of a time series. The ACF is a measure of the similarity between a time series and a lagged version of itself.\n",
    "\n",
    "When interpreting the results of the plot_acf() function, you should look for patterns in the plot that indicate how strongly the time series is correlated with lagged versions of itself. Here are some things to consider when interpreting the plot:\n",
    "\n",
    "Autocorrelation at lag 0: The value at lag 0 represents the correlation of the time series with itself, which is always 1.\n",
    "\n",
    "Autocorrelation at positive lags: Positive lags represent the correlation of the time series with lagged versions of itself. Positive autocorrelation values indicate that the time series is positively correlated with lagged versions of itself.\n",
    "\n",
    "Autocorrelation at negative lags: Negative lags represent the correlation of the time series with lagged versions of itself, but with the time series reversed. Negative autocorrelation values indicate that the time series is negatively correlated with lagged versions of itself.\n",
    "\n",
    "Confidence intervals: The plot also includes the confidence intervals represented by the blue shaded area. This area represents the range of values that the autocorrelation would be expected to fall in if the true autocorrelation was zero. If the autocorrelation values fall outside this area, it indicates that the autocorrelation is statistically significant.\n",
    "\n",
    "Cutoff point: A cutoff point is represented by a horizontal line on the plot, it indicates the level of significance. If the autocorrelation values fall above this line, it means that they are statistically significant.\n",
    "\n",
    "A decaying or an increasing trend: A decaying trend in the plot indicates that the correlation between the time series and its lagged versions decreases as the lag increases. An increasing trend would indicate that the correlation increases as the lag increases.\n",
    "\n",
    "Partial Autocorrelation: The plot_acf() also plot the partial autocorrelation function (PACF) on the same plot, the PACF is a measure of the correlation between a time series and a lagged version of itself, with the effects of intermediate lags removed. The PACF can help you identify which lag values are most important in explaining the correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the autocorrelation and partial autocorrelation\n",
    "plot_acf(df_prestation_aos_outcomes_sums['PRESTATIONS_BRUTES'])\n",
    "plot_pacf(df_prestation_aos_outcomes_sums['PRESTATIONS_BRUTES'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the time series data into a numpy array\n",
    "time_series = [df_prestation_aos_outcomes_sums['PRESTATIONS_BRUTES']]\n",
    "\n",
    "# calculate the periodogram\n",
    "f, Pxx_den = signal.periodogram(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the periodogram\n",
    "plt.semilogy(f, Pxx_den[0])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Power Spectral Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410",
   "metadata": {},
   "source": [
    "A periodogram is a graphical representation of the frequency components of a time series. It shows the power of the signal at different frequencies, which allows you to identify any patterns that repeat at regular intervals.\n",
    "\n",
    "When interpreting a periodogram, you should look for peaks or troughs in the power spectral density (PSD) plot. These peaks or troughs indicate that certain frequencies are present in the time series. The height of the peak indicates the strength of the frequency component, and the width of the peak indicates how broad the frequency component is.\n",
    "\n",
    "Here are some things to consider when interpreting a periodogram:\n",
    "\n",
    "High frequency peaks: High frequency peaks indicate that there are rapid fluctuations in the time series data. These fluctuations are usually caused by noise or random variations in the data.\n",
    "\n",
    "Low frequency peaks: Low frequency peaks indicate that there are slow trends or patterns in the time series data. These trends or patterns are usually caused by long-term changes or cyclical patterns in the data.\n",
    "\n",
    "Multiple peaks: If there are multiple peaks in the periodogram, it indicates that there are multiple frequency components in the time series data. The presence of multiple peaks can also indicate that there are multiple underlying processes that are generating the data.\n",
    "\n",
    "Sharp and narrow peaks: Sharp and narrow peaks indicate that the frequency component is well-defined and consistent.\n",
    "\n",
    "Broad and low peaks: Broad and low peaks indicate that the frequency component is not well-defined and consistent.\n",
    "\n",
    "It's important to note that the interpretation of the periodogram is highly dependent on the nature of the data, the sampling rate and the window applied. It's also important to consider if the data has been pre-processed in any way, as different pre-processing steps can affect the periodogram."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
